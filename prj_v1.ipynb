{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrfanESD/SE_Detection/blob/main/prj_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Rq2E5-DB1T"
      },
      "outputs": [],
      "source": [
        " !pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SNIPPING IMAGES FROM VIDEO.."
      ],
      "metadata": {
        "id": "296rTq1nPh5U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm7djEzwFP8i"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# === üîß Input: Set video path ===\n",
        "video_path = '/content/drive/MyDrive/Clips/C0016.MP4'\n",
        "output_folder = '/content/drive/MyDrive/clear_student_frames/MainSet14'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# === üßÆ Parameters ===\n",
        "sharpness_threshold = 100.0  # Higher = only clearer frames\n",
        "sampling_interval = 30      # Sample every 30 frames\n",
        "\n",
        "# === üé¨ Read and Process the Video ===\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"‚ùå Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Get and print video FPS (optional, for info)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(f\"üé• Video FPS: {fps}\")\n",
        "\n",
        "frame_count = 0\n",
        "saved_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # Only sample every 120 frames\n",
        "    if frame_count % sampling_interval != 0:\n",
        "        continue\n",
        "\n",
        "    # Convert frame to grayscale for sharpness detection\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "    # Save only sharp frames\n",
        "    if sharpness > sharpness_threshold:\n",
        "        filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "        cv2.imwrite(filename, frame)\n",
        "        saved_count += 1\n",
        "        print(f\"‚úÖ Saved frame {frame_count} | Sharpness: {sharpness:.2f}\")\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(f\"\\n‚úÖ Done: {saved_count} sharp frames saved to ‚ûú '{output_folder}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RENAME IMAGES IN ASCENDING ORDER.."
      ],
      "metadata": {
        "id": "E0O0KoSjQPrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Set path to the parent folder containing 10 folders\n",
        "parent_dir = '/content/drive/MyDrive/clear_student_frames'  # ‚¨ÖÔ∏è Change this\n",
        "\n",
        "# Step 3: Get list of all image paths from all subfolders\n",
        "image_extensions = ('*.jpg', '*.jpeg', '*.png')  # Extend if needed\n",
        "all_images = []\n",
        "\n",
        "for ext in image_extensions:\n",
        "    all_images.extend(glob.glob(os.path.join(parent_dir, '*', ext)))\n",
        "\n",
        "# Optional: Sort for consistent ordering\n",
        "all_images.sort()\n",
        "\n",
        "# Step 4: Rename all images serially and print progress\n",
        "start_serial = 1  # ‚¨ÖÔ∏è Change this if you want to start from a different number\n",
        "renamed_count = 0\n",
        "\n",
        "for idx, img_path in enumerate(all_images, start_serial):\n",
        "    folder = os.path.dirname(img_path)\n",
        "    ext = os.path.splitext(img_path)[1]\n",
        "    new_name = f\"{idx}{ext}\"\n",
        "    new_path = os.path.join(folder, new_name)\n",
        "\n",
        "    try:\n",
        "        os.rename(img_path, new_path)\n",
        "        folder_name = os.path.basename(folder)\n",
        "        print(f\"{idx}: Renamed in '{folder_name}' ‚Üí {new_name}\")\n",
        "        renamed_count += 1\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error renaming '{img_path}': {e}\")\n",
        "\n",
        "# Step 5: Output total renamed images\n",
        "print(f\"\\n‚úÖ Total images renamed: {renamed_count}\")\n"
      ],
      "metadata": {
        "id": "HCO3kYpWzdxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MERGING IN A SINGLE FOLDER.."
      ],
      "metadata": {
        "id": "2UE2GzEcQsUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# üîÅ Replace these with the actual 6 folder paths\n",
        "source_folders = [\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET01',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET02',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET03',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET04',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET05',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET06'\n",
        "]\n",
        "\n",
        "# üóÇÔ∏è Target folder where all images will be copied\n",
        "target_folder = '/content/drive/MyDrive/clear_student_frames/merged_set'\n",
        "os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "# üì¶ Copy files from each folder\n",
        "for folder in source_folders:\n",
        "    for file in os.listdir(folder):\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            src = os.path.join(folder, file)\n",
        "            dst = os.path.join(target_folder, file)\n",
        "            if not os.path.exists(dst):  # Avoid overwriting duplicates\n",
        "                shutil.copy(src, dst)\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Skipped duplicate: {file}\")\n",
        "\n",
        "print(\"‚úÖ All images merged into:\", target_folder)\n",
        "#Total copied images//TOTAL - 2038 IMAGES: Copied from 'MainSet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22TbrNLKlSV",
        "outputId": "d32e3ada-c15b-420d-8574-8bc0b90a9e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All images merged into: /content/drive/MyDrive/clear_student_frames/merged_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT ULTRALYTICS.."
      ],
      "metadata": {
        "id": "lh9j6wKFUdGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics mediapipe opencv-python"
      ],
      "metadata": {
        "id": "K-SLNVytu5ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLIT IMG TO TRAIN, VAL, TEST.."
      ],
      "metadata": {
        "id": "t6NFB7ItTnHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "image_dir = '/content/drive/MyDrive/MMimages'\n",
        "output_base = '/content/drive/MyDrive/image_split'\n",
        "\n",
        "# Create output folders\n",
        "splits = ['train', 'val', 'test']\n",
        "for split in splits:\n",
        "    os.makedirs(os.path.join(output_base, split), exist_ok=True)\n",
        "\n",
        "# Get and shuffle image files\n",
        "all_images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "random.seed(42)  # For reproducibility\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Define splits\n",
        "train_imgs = all_images[:1500]\n",
        "val_imgs = all_images[1500:1900]\n",
        "test_imgs = all_images[1900:]  # all remaining images\n",
        "\n",
        "# Function to move images\n",
        "def move_images(file_list, split_name):\n",
        "    for file in file_list:\n",
        "        src = os.path.join(image_dir, file)\n",
        "        dst = os.path.join(output_base, split_name, file)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Move images to folders\n",
        "move_images(train_imgs, 'train')\n",
        "move_images(val_imgs, 'val')\n",
        "move_images(test_imgs, 'test')\n",
        "\n",
        "# Report\n",
        "print(f\"‚úÖ Done: {len(train_imgs)} train, {len(val_imgs)} val, {len(test_imgs)} test images MOVED to '{output_base}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_OkJpCMbJ8",
        "outputId": "f1c045b1-21aa-4c6f-fbef-449a52944d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done: 1500 train, 400 val, 142 test images MOVED to '/content/drive/MyDrive/image_split'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELING IMAGES = v1"
      ],
      "metadata": {
        "id": "QKO_qx3rTTQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "\n",
        "# Paths\n",
        "image_folder = '/content/drive/MyDrive/Saif/images'\n",
        "label_folder = '/content/drive/MyDrive/Saif/labels'\n",
        "visual_folder = '/content/drive/MyDrive/Saif/labeled_images'\n",
        "\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "os.makedirs(visual_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv8 and MediaPipe\n",
        "model = YOLO('yolov8n.pt')\n",
        "pose = mp.solutions.pose.Pose(static_image_mode=True, model_complexity=2)\n",
        "\n",
        "# Class names: 0 = Engaged, 1 = Distracted\n",
        "class_names = ['Engaged', 'Distracted']\n",
        "\n",
        "# Estimate head direction based on eyes\n",
        "def estimate_head_direction(landmarks):\n",
        "    try:\n",
        "        left_eye = landmarks[2]\n",
        "        right_eye = landmarks[5]\n",
        "        dx = left_eye.x - right_eye.x\n",
        "        if dx > 0.04:\n",
        "            return 'left'\n",
        "        elif dx < -0.04:\n",
        "            return 'right'\n",
        "        else:\n",
        "            return 'front'\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "# Classify using head direction compared to majority (teacher_dir)\n",
        "def classify_posture_binary(landmarks, teacher_dir):\n",
        "    direction = estimate_head_direction(landmarks)\n",
        "    if direction == teacher_dir:\n",
        "        return 0  # Engaged\n",
        "    else:\n",
        "        return 1  # Distracted\n",
        "\n",
        "# Process images\n",
        "for file in os.listdir(image_folder):\n",
        "    if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(image_folder, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    img_h, img_w = image.shape[:2]\n",
        "    results = model(image_path)[0]\n",
        "    boxes = results.boxes.data\n",
        "\n",
        "    all_directions = []\n",
        "    temp_landmarks = []\n",
        "    temp_boxes = []\n",
        "\n",
        "    for box in boxes:\n",
        "        cls = int(box[5])\n",
        "        if cls != 0:\n",
        "            continue  # only person class\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
        "\n",
        "        person_crop = image[y1:y2, x1:x2]\n",
        "        if person_crop.size == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
        "            pose_result = pose.process(crop_rgb)\n",
        "        except:\n",
        "            pose_result = None\n",
        "\n",
        "        if pose_result and pose_result.pose_landmarks:\n",
        "            landmarks = pose_result.pose_landmarks.landmark\n",
        "            dir = estimate_head_direction(landmarks)\n",
        "            all_directions.append(dir)\n",
        "            temp_landmarks.append(landmarks)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "        else:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    # Decide teacher direction (majority vote)\n",
        "    teacher_dir = 'front'\n",
        "    if all_directions:\n",
        "        teacher_dir = Counter(all_directions).most_common(1)[0][0]\n",
        "\n",
        "    label_lines = []\n",
        "    engaged_count = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for i, landmarks in enumerate(temp_landmarks):\n",
        "        x1, y1, x2, y2 = temp_boxes[i]\n",
        "\n",
        "        if landmarks:\n",
        "            posture_class = classify_posture_binary(landmarks, teacher_dir)\n",
        "\n",
        "            if posture_class == 0:\n",
        "                engaged_count += 1\n",
        "            total_count += 1\n",
        "\n",
        "            x_center = ((x1 + x2) / 2) / img_w\n",
        "            y_center = ((y1 + y2) / 2) / img_h\n",
        "            w = (x2 - x1) / img_w\n",
        "            h = (y2 - y1) / img_h\n",
        "\n",
        "            label_line = f\"{posture_class} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\"\n",
        "            label_lines.append(label_line)\n",
        "\n",
        "            # Draw bounding box with label\n",
        "            color = (0, 255, 0) if posture_class == 0 else (0, 0, 255)\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(image, class_names[posture_class], (x1, y1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "        else:\n",
        "            # Pose not detected\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (128, 128, 128), 2)\n",
        "            cv2.putText(image, 'no pose', (x1, y1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)\n",
        "\n",
        "    # Save YOLO-format label file\n",
        "    label_file = os.path.join(label_folder, file.rsplit('.', 1)[0] + '.txt')\n",
        "    with open(label_file, 'w') as f:\n",
        "        for line in label_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    # Save annotated image\n",
        "    visual_path = os.path.join(visual_folder, file)\n",
        "    cv2.imwrite(visual_path, image)\n",
        "\n",
        "    # Print engagement stats\n",
        "    engagement_percent = (engaged_count / total_count * 100) if total_count > 0 else 0\n",
        "    print(f\"{file}: {engaged_count}/{total_count} engaged ({engagement_percent:.1f}%) - Teacher direction: {teacher_dir}\")\n"
      ],
      "metadata": {
        "id": "uC84XBBJVmQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELING IMAGES = v2"
      ],
      "metadata": {
        "id": "KT_h1q3RUy1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "\n",
        "# Paths\n",
        "image_folder = '/content/drive/MyDrive/Dataset/images/val'\n",
        "label_folder = '/content/drive/MyDrive/Dataset/labels/val'\n",
        "\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv8 and MediaPipe\n",
        "model = YOLO('yolov8n.pt')\n",
        "pose = mp.solutions.pose.Pose(static_image_mode=True, model_complexity=2)\n",
        "\n",
        "# Estimate head direction based on eyes\n",
        "def estimate_head_direction(landmarks):\n",
        "    try:\n",
        "        left_eye = landmarks[2]\n",
        "        right_eye = landmarks[5]\n",
        "        dx = left_eye.x - right_eye.x\n",
        "        if dx > 0.04:\n",
        "            return 'left'\n",
        "        elif dx < -0.04:\n",
        "            return 'right'\n",
        "        else:\n",
        "            return 'front'\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "# Classify using head direction compared to majority (teacher_dir)\n",
        "def classify_posture_binary(landmarks, teacher_dir):\n",
        "    direction = estimate_head_direction(landmarks)\n",
        "    return 0 if direction == teacher_dir else 1  # 0: Engaged, 1: Distracted\n",
        "\n",
        "# Process images\n",
        "for file in os.listdir(image_folder):\n",
        "    if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(image_folder, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    img_h, img_w = image.shape[:2]\n",
        "    results = model(image_path)[0]\n",
        "    boxes = results.boxes.data\n",
        "\n",
        "    all_directions = []\n",
        "    temp_landmarks = []\n",
        "    temp_boxes = []\n",
        "\n",
        "    for box in boxes:\n",
        "        cls = int(box[5])\n",
        "        if cls != 0:\n",
        "            continue  # only person class\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
        "\n",
        "        person_crop = image[y1:y2, x1:x2]\n",
        "        if person_crop.size == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
        "            pose_result = pose.process(crop_rgb)\n",
        "        except:\n",
        "            pose_result = None\n",
        "\n",
        "        if pose_result and pose_result.pose_landmarks:\n",
        "            landmarks = pose_result.pose_landmarks.landmark\n",
        "            dir = estimate_head_direction(landmarks)\n",
        "            all_directions.append(dir)\n",
        "            temp_landmarks.append(landmarks)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "        else:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    # Determine teacher direction by majority\n",
        "    teacher_dir = 'front'\n",
        "    if all_directions:\n",
        "        teacher_dir = Counter(all_directions).most_common(1)[0][0]\n",
        "\n",
        "    label_lines = []\n",
        "\n",
        "    for i, landmarks in enumerate(temp_landmarks):\n",
        "        x1, y1, x2, y2 = temp_boxes[i]\n",
        "\n",
        "        if landmarks:\n",
        "            posture_class = classify_posture_binary(landmarks, teacher_dir)\n",
        "\n",
        "            x_center = ((x1 + x2) / 2) / img_w\n",
        "            y_center = ((y1 + y2) / 2) / img_h\n",
        "            w = (x2 - x1) / img_w\n",
        "            h = (y2 - y1) / img_h\n",
        "\n",
        "            label_line = f\"{posture_class} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\"\n",
        "            label_lines.append(label_line)\n",
        "\n",
        "    # Save YOLO-format label file\n",
        "    label_file = os.path.join(label_folder, file.rsplit('.', 1)[0] + '.txt')\n",
        "    with open(label_file, 'w') as f:\n",
        "        for line in label_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    print(f\"{file}: {len(label_lines)} labels saved (Teacher direction: {teacher_dir})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3koiqVSuUfp8",
        "outputId": "960808c0-d076-4b70-ab52-b22e840a24ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1044.jpg: 384x640 12 persons, 15 chairs, 3 dining tables, 288.1ms\n",
            "Speed: 5.6ms preprocess, 288.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1044.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1047.jpg: 384x640 12 persons, 17 chairs, 3 dining tables, 158.6ms\n",
            "Speed: 3.5ms preprocess, 158.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1047.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1049.jpg: 384x640 14 persons, 16 chairs, 3 dining tables, 145.4ms\n",
            "Speed: 3.4ms preprocess, 145.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1049.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1050.jpg: 384x640 11 persons, 17 chairs, 3 dining tables, 142.7ms\n",
            "Speed: 3.1ms preprocess, 142.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1050.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1057.jpg: 384x640 13 persons, 15 chairs, 3 dining tables, 225.0ms\n",
            "Speed: 5.4ms preprocess, 225.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1057.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1059.jpg: 384x640 12 persons, 4 chairs, 225.7ms\n",
            "Speed: 5.2ms preprocess, 225.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1059.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1062.jpg: 384x640 11 persons, 3 chairs, 159.1ms\n",
            "Speed: 5.2ms preprocess, 159.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1062.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1066.jpg: 384x640 12 persons, 4 chairs, 157.8ms\n",
            "Speed: 3.3ms preprocess, 157.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1066.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1073.jpg: 384x640 10 persons, 6 chairs, 143.2ms\n",
            "Speed: 3.5ms preprocess, 143.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1073.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1082.jpg: 384x640 11 persons, 6 chairs, 137.1ms\n",
            "Speed: 3.3ms preprocess, 137.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1082.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1086.jpg: 384x640 10 persons, 3 chairs, 145.7ms\n",
            "Speed: 3.3ms preprocess, 145.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1086.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1107.jpg: 384x640 11 persons, 1 pizza, 3 chairs, 126.7ms\n",
            "Speed: 3.1ms preprocess, 126.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1107.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1116.jpg: 384x640 13 persons, 4 chairs, 210.0ms\n",
            "Speed: 5.1ms preprocess, 210.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1116.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1124.jpg: 384x640 12 persons, 215.6ms\n",
            "Speed: 4.8ms preprocess, 215.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1124.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1128.jpg: 384x640 13 persons, 1 chair, 154.7ms\n",
            "Speed: 3.4ms preprocess, 154.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1128.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1133.jpg: 384x640 11 persons, 3 chairs, 136.9ms\n",
            "Speed: 4.3ms preprocess, 136.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1133.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1139.jpg: 384x640 12 persons, 2 chairs, 125.9ms\n",
            "Speed: 3.0ms preprocess, 125.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1139.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1145.jpg: 384x640 10 persons, 3 chairs, 140.0ms\n",
            "Speed: 3.3ms preprocess, 140.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1145.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1146.jpg: 384x640 12 persons, 3 chairs, 132.7ms\n",
            "Speed: 3.3ms preprocess, 132.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1146.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1147.jpg: 384x640 12 persons, 1 chair, 125.7ms\n",
            "Speed: 2.9ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1147.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1153.jpg: 384x640 13 persons, 2 chairs, 214.0ms\n",
            "Speed: 5.1ms preprocess, 214.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1153.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1159.jpg: 384x640 11 persons, 4 chairs, 211.2ms\n",
            "Speed: 4.8ms preprocess, 211.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1159.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1160.jpg: 384x640 10 persons, 1 chair, 129.9ms\n",
            "Speed: 3.0ms preprocess, 129.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1160.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1161.jpg: 384x640 12 persons, 1 chair, 127.8ms\n",
            "Speed: 3.0ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1161.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1162.jpg: 384x640 12 persons, 3 chairs, 1 laptop, 1 book, 145.8ms\n",
            "Speed: 5.8ms preprocess, 145.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1162.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1163.jpg: 384x640 11 persons, 1 chair, 1 laptop, 1 book, 139.5ms\n",
            "Speed: 3.6ms preprocess, 139.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1163.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1167.jpg: 384x640 9 persons, 1 chair, 2 remotes, 154.2ms\n",
            "Speed: 3.4ms preprocess, 154.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1167.jpg: 8 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1173.jpg: 384x640 12 persons, 2 chairs, 142.8ms\n",
            "Speed: 3.7ms preprocess, 142.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1173.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1174.jpg: 384x640 12 persons, 1 chair, 211.1ms\n",
            "Speed: 5.9ms preprocess, 211.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1174.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1181.jpg: 384x640 11 persons, 1 handbag, 2 chairs, 232.0ms\n",
            "Speed: 7.0ms preprocess, 232.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1181.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1182.jpg: 384x640 10 persons, 1 chair, 144.9ms\n",
            "Speed: 3.6ms preprocess, 144.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1182.jpg: 10 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1183.jpg: 384x640 11 persons, 3 chairs, 163.8ms\n",
            "Speed: 3.5ms preprocess, 163.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1183.jpg: 11 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1184.jpg: 384x640 10 persons, 1 chair, 129.1ms\n",
            "Speed: 3.1ms preprocess, 129.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1184.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1188.jpg: 384x640 11 persons, 1 wine glass, 2 chairs, 128.8ms\n",
            "Speed: 3.1ms preprocess, 128.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1188.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1191.jpg: 384x640 13 persons, 2 chairs, 135.5ms\n",
            "Speed: 2.8ms preprocess, 135.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1191.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1193.jpg: 384x640 11 persons, 2 chairs, 163.8ms\n",
            "Speed: 3.6ms preprocess, 163.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1193.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1197.jpg: 384x640 12 persons, 3 chairs, 219.7ms\n",
            "Speed: 4.9ms preprocess, 219.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1197.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1207.jpg: 384x640 12 persons, 3 chairs, 2 remotes, 229.7ms\n",
            "Speed: 5.0ms preprocess, 229.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1207.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1210.jpg: 384x640 13 persons, 1 cup, 3 chairs, 144.7ms\n",
            "Speed: 3.3ms preprocess, 144.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1210.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1218.jpg: 384x640 10 persons, 3 chairs, 140.7ms\n",
            "Speed: 3.4ms preprocess, 140.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1218.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1229.jpg: 384x640 13 persons, 1 bench, 2 chairs, 128.4ms\n",
            "Speed: 3.0ms preprocess, 128.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1229.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1236.jpg: 384x640 10 persons, 2 chairs, 131.5ms\n",
            "Speed: 2.9ms preprocess, 131.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1236.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1243.jpg: 384x640 10 persons, 1 chair, 132.8ms\n",
            "Speed: 2.9ms preprocess, 132.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1243.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1244.jpg: 384x640 12 persons, 3 chairs, 139.1ms\n",
            "Speed: 3.4ms preprocess, 139.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1244.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1247.jpg: 384x640 10 persons, 2 chairs, 200.4ms\n",
            "Speed: 4.5ms preprocess, 200.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1247.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1253.jpg: 384x640 11 persons, 1 chair, 193.2ms\n",
            "Speed: 4.4ms preprocess, 193.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1253.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1255.jpg: 384x640 13 persons, 3 chairs, 1 remote, 136.3ms\n",
            "Speed: 3.2ms preprocess, 136.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1255.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1260.jpg: 384x640 13 persons, 4 chairs, 1 remote, 142.0ms\n",
            "Speed: 2.9ms preprocess, 142.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1260.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1262.jpg: 384x640 11 persons, 1 chair, 1 remote, 131.4ms\n",
            "Speed: 3.0ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1262.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1266.jpg: 384x640 11 persons, 142.3ms\n",
            "Speed: 3.4ms preprocess, 142.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1266.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1267.jpg: 384x640 14 persons, 2 chairs, 1 remote, 131.5ms\n",
            "Speed: 3.1ms preprocess, 131.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1267.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1272.jpg: 384x640 12 persons, 1 chair, 141.6ms\n",
            "Speed: 3.4ms preprocess, 141.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1272.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1277.jpg: 384x640 11 persons, 2 chairs, 211.2ms\n",
            "Speed: 5.2ms preprocess, 211.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1277.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1279.jpg: 384x640 12 persons, 1 chair, 229.4ms\n",
            "Speed: 6.0ms preprocess, 229.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1279.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1288.jpg: 384x640 14 persons, 1 chair, 131.3ms\n",
            "Speed: 2.9ms preprocess, 131.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1288.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1290.jpg: 384x640 13 persons, 153.2ms\n",
            "Speed: 3.0ms preprocess, 153.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1290.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1300.jpg: 384x640 12 persons, 4 chairs, 138.5ms\n",
            "Speed: 5.2ms preprocess, 138.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1300.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1304.jpg: 384x640 12 persons, 3 chairs, 136.8ms\n",
            "Speed: 3.3ms preprocess, 136.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1304.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1305.jpg: 384x640 13 persons, 2 chairs, 127.7ms\n",
            "Speed: 4.0ms preprocess, 127.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1305.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1310.jpg: 384x640 10 persons, 4 chairs, 136.6ms\n",
            "Speed: 3.4ms preprocess, 136.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1310.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1311.jpg: 384x640 9 persons, 2 chairs, 220.7ms\n",
            "Speed: 5.0ms preprocess, 220.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1311.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1313.jpg: 384x640 10 persons, 229.5ms\n",
            "Speed: 5.6ms preprocess, 229.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1313.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1314.jpg: 384x640 11 persons, 136.1ms\n",
            "Speed: 3.7ms preprocess, 136.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1314.jpg: 10 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1318.jpg: 384x640 12 persons, 140.1ms\n",
            "Speed: 5.7ms preprocess, 140.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1318.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1326.jpg: 384x640 13 persons, 6 chairs, 159.0ms\n",
            "Speed: 3.8ms preprocess, 159.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1326.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1330.jpg: 384x640 10 persons, 10 chairs, 143.4ms\n",
            "Speed: 3.4ms preprocess, 143.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1330.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1335.jpg: 384x640 11 persons, 8 chairs, 144.2ms\n",
            "Speed: 3.4ms preprocess, 144.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1335.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1346.jpg: 384x640 11 persons, 5 chairs, 142.5ms\n",
            "Speed: 3.5ms preprocess, 142.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1346.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1348.jpg: 384x640 10 persons, 5 chairs, 223.9ms\n",
            "Speed: 5.1ms preprocess, 223.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1348.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1356.jpg: 384x640 11 persons, 5 chairs, 208.8ms\n",
            "Speed: 5.1ms preprocess, 208.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1356.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1359.jpg: 384x640 11 persons, 7 chairs, 158.6ms\n",
            "Speed: 3.4ms preprocess, 158.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1359.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1360.jpg: 384x640 11 persons, 10 chairs, 143.4ms\n",
            "Speed: 2.9ms preprocess, 143.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1360.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1365.jpg: 384x640 12 persons, 10 chairs, 132.1ms\n",
            "Speed: 2.9ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1365.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1367.jpg: 384x640 12 persons, 4 chairs, 142.6ms\n",
            "Speed: 3.0ms preprocess, 142.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1367.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1371.jpg: 384x640 11 persons, 8 chairs, 131.1ms\n",
            "Speed: 3.2ms preprocess, 131.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1371.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1374.jpg: 384x640 11 persons, 6 chairs, 147.3ms\n",
            "Speed: 5.0ms preprocess, 147.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1374.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1381.jpg: 384x640 11 persons, 9 chairs, 204.4ms\n",
            "Speed: 4.9ms preprocess, 204.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1381.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1382.jpg: 384x640 12 persons, 9 chairs, 1 book, 219.1ms\n",
            "Speed: 4.9ms preprocess, 219.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1382.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1384.jpg: 384x640 12 persons, 7 chairs, 2 books, 140.7ms\n",
            "Speed: 3.4ms preprocess, 140.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1384.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1409.jpg: 384x640 12 persons, 1 backpack, 9 chairs, 1 book, 130.4ms\n",
            "Speed: 3.3ms preprocess, 130.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1409.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1419.jpg: 384x640 11 persons, 1 backpack, 1 tie, 9 chairs, 128.5ms\n",
            "Speed: 2.9ms preprocess, 128.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1419.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1424.jpg: 384x640 12 persons, 1 backpack, 1 tie, 10 chairs, 137.5ms\n",
            "Speed: 3.3ms preprocess, 137.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1424.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1432.jpg: 384x640 12 persons, 1 backpack, 9 chairs, 138.8ms\n",
            "Speed: 3.4ms preprocess, 138.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1432.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1433.jpg: 384x640 13 persons, 1 backpack, 8 chairs, 137.8ms\n",
            "Speed: 3.2ms preprocess, 137.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1433.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1436.jpg: 384x640 12 persons, 8 chairs, 228.9ms\n",
            "Speed: 5.0ms preprocess, 228.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1436.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1455.jpg: 384x640 13 persons, 1 cup, 1 chair, 216.0ms\n",
            "Speed: 5.0ms preprocess, 216.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1455.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1460.jpg: 384x640 12 persons, 3 chairs, 1 bed, 3 books, 154.6ms\n",
            "Speed: 3.2ms preprocess, 154.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1460.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1462.jpg: 384x640 9 persons, 2 chairs, 3 books, 150.8ms\n",
            "Speed: 3.0ms preprocess, 150.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1462.jpg: 7 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1474.jpg: 384x640 17 persons, 4 chairs, 127.3ms\n",
            "Speed: 2.9ms preprocess, 127.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1474.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1475.jpg: 384x640 17 persons, 4 chairs, 134.5ms\n",
            "Speed: 3.0ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1475.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1477.jpg: 384x640 16 persons, 1 suitcase, 4 chairs, 144.1ms\n",
            "Speed: 2.9ms preprocess, 144.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1477.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1479.jpg: 384x640 17 persons, 5 chairs, 196.4ms\n",
            "Speed: 4.5ms preprocess, 196.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1479.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1480.jpg: 384x640 17 persons, 1 suitcase, 5 chairs, 241.9ms\n",
            "Speed: 5.3ms preprocess, 241.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1480.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1481.jpg: 384x640 23 persons, 1 suitcase, 4 chairs, 131.8ms\n",
            "Speed: 3.1ms preprocess, 131.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1481.jpg: 23 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1482.jpg: 384x640 18 persons, 1 suitcase, 4 chairs, 135.9ms\n",
            "Speed: 3.4ms preprocess, 135.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1482.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1489.jpg: 384x640 15 persons, 3 chairs, 144.0ms\n",
            "Speed: 3.4ms preprocess, 144.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1489.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1504.jpg: 384x640 12 persons, 4 chairs, 132.0ms\n",
            "Speed: 3.1ms preprocess, 132.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1504.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1512.jpg: 384x640 13 persons, 1 suitcase, 4 chairs, 231.6ms\n",
            "Speed: 5.2ms preprocess, 231.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1512.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1515.jpg: 384x640 14 persons, 1 suitcase, 6 chairs, 200.8ms\n",
            "Speed: 4.7ms preprocess, 200.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1515.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1525.jpg: 384x640 14 persons, 1 handbag, 8 chairs, 135.0ms\n",
            "Speed: 2.9ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1525.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1528.jpg: 384x640 14 persons, 1 suitcase, 5 chairs, 155.5ms\n",
            "Speed: 5.0ms preprocess, 155.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1528.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1531.jpg: 384x640 16 persons, 1 suitcase, 7 chairs, 158.7ms\n",
            "Speed: 3.1ms preprocess, 158.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1531.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1532.jpg: 384x640 15 persons, 1 suitcase, 5 chairs, 145.5ms\n",
            "Speed: 3.0ms preprocess, 145.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1532.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1534.jpg: 384x640 12 persons, 1 backpack, 1 suitcase, 7 chairs, 135.2ms\n",
            "Speed: 2.8ms preprocess, 135.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1534.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1537.jpg: 384x640 13 persons, 4 chairs, 217.7ms\n",
            "Speed: 5.1ms preprocess, 217.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1537.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1541.jpg: 384x640 15 persons, 1 backpack, 5 chairs, 132.3ms\n",
            "Speed: 3.4ms preprocess, 132.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1541.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1544.jpg: 384x640 10 persons, 1 backpack, 1 suitcase, 7 chairs, 127.3ms\n",
            "Speed: 2.9ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1544.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1548.jpg: 384x640 18 persons, 1 backpack, 1 suitcase, 6 chairs, 156.3ms\n",
            "Speed: 5.1ms preprocess, 156.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1548.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1549.jpg: 384x640 17 persons, 8 chairs, 1 book, 140.6ms\n",
            "Speed: 3.4ms preprocess, 140.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1549.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1551.jpg: 384x640 18 persons, 1 backpack, 2 suitcases, 7 chairs, 138.6ms\n",
            "Speed: 3.8ms preprocess, 138.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1551.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1553.jpg: 384x640 17 persons, 1 backpack, 7 chairs, 269.8ms\n",
            "Speed: 5.1ms preprocess, 269.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1553.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1555.jpg: 384x640 17 persons, 1 backpack, 5 chairs, 139.6ms\n",
            "Speed: 3.4ms preprocess, 139.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1555.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1558.jpg: 384x640 17 persons, 1 backpack, 1 suitcase, 6 chairs, 127.1ms\n",
            "Speed: 3.2ms preprocess, 127.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1558.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1578.jpg: 384x640 19 persons, 7 chairs, 137.9ms\n",
            "Speed: 2.9ms preprocess, 137.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1578.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1580.jpg: 384x640 16 persons, 1 handbag, 1 suitcase, 1 chair, 168.1ms\n",
            "Speed: 3.8ms preprocess, 168.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1580.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1582.jpg: 384x640 18 persons, 1 handbag, 1 suitcase, 4 chairs, 129.5ms\n",
            "Speed: 2.9ms preprocess, 129.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1582.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1583.jpg: 384x640 20 persons, 1 handbag, 1 suitcase, 5 chairs, 213.8ms\n",
            "Speed: 5.2ms preprocess, 213.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1583.jpg: 20 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1584.jpg: 384x640 15 persons, 2 suitcases, 5 chairs, 135.7ms\n",
            "Speed: 3.3ms preprocess, 135.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1584.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1586.jpg: 384x640 18 persons, 1 handbag, 1 suitcase, 8 chairs, 131.1ms\n",
            "Speed: 3.1ms preprocess, 131.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1586.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1587.jpg: 384x640 18 persons, 1 handbag, 1 suitcase, 6 chairs, 140.8ms\n",
            "Speed: 3.4ms preprocess, 140.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1587.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1601.jpg: 384x640 18 persons, 1 suitcase, 6 chairs, 132.3ms\n",
            "Speed: 3.1ms preprocess, 132.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1601.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1610.jpg: 384x640 18 persons, 1 suitcase, 6 chairs, 206.0ms\n",
            "Speed: 4.4ms preprocess, 206.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1610.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1614.jpg: 384x640 18 persons, 8 chairs, 134.5ms\n",
            "Speed: 3.2ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1614.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1621.jpg: 384x640 18 persons, 1 suitcase, 4 chairs, 146.4ms\n",
            "Speed: 3.6ms preprocess, 146.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1621.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1627.jpg: 384x640 18 persons, 6 chairs, 140.5ms\n",
            "Speed: 3.3ms preprocess, 140.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1627.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1628.jpg: 384x640 17 persons, 8 chairs, 150.9ms\n",
            "Speed: 3.4ms preprocess, 150.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1628.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1645.jpg: 384x640 17 persons, 1 suitcase, 10 chairs, 1 book, 210.0ms\n",
            "Speed: 4.5ms preprocess, 210.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1645.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1651.jpg: 384x640 17 persons, 1 handbag, 1 suitcase, 5 chairs, 200.3ms\n",
            "Speed: 4.5ms preprocess, 200.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1651.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1655.jpg: 384x640 16 persons, 1 suitcase, 5 chairs, 129.6ms\n",
            "Speed: 3.0ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1655.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1657.jpg: 384x640 19 persons, 1 suitcase, 9 chairs, 127.2ms\n",
            "Speed: 3.0ms preprocess, 127.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1657.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1658.jpg: 384x640 21 persons, 1 suitcase, 9 chairs, 140.6ms\n",
            "Speed: 4.0ms preprocess, 140.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1658.jpg: 21 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1663.jpg: 384x640 17 persons, 1 suitcase, 5 chairs, 133.6ms\n",
            "Speed: 3.6ms preprocess, 133.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1663.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1673.jpg: 384x640 13 persons, 11 chairs, 1 laptop, 221.6ms\n",
            "Speed: 5.1ms preprocess, 221.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1673.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1675.jpg: 384x640 13 persons, 1 bench, 12 chairs, 1 laptop, 160.5ms\n",
            "Speed: 3.6ms preprocess, 160.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1675.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1682.jpg: 384x640 14 persons, 11 chairs, 129.6ms\n",
            "Speed: 3.2ms preprocess, 129.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1682.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1686.jpg: 384x640 15 persons, 8 chairs, 138.7ms\n",
            "Speed: 3.3ms preprocess, 138.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1686.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1687.jpg: 384x640 17 persons, 13 chairs, 128.6ms\n",
            "Speed: 2.8ms preprocess, 128.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1687.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1688.jpg: 384x640 15 persons, 11 chairs, 127.6ms\n",
            "Speed: 3.0ms preprocess, 127.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1688.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1691.jpg: 384x640 15 persons, 14 chairs, 1 laptop, 236.1ms\n",
            "Speed: 6.7ms preprocess, 236.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1691.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1707.jpg: 384x640 15 persons, 13 chairs, 1 laptop, 229.4ms\n",
            "Speed: 5.5ms preprocess, 229.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1707.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1720.jpg: 384x640 14 persons, 11 chairs, 1 laptop, 146.8ms\n",
            "Speed: 3.1ms preprocess, 146.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1720.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1727.jpg: 384x640 12 persons, 17 chairs, 1 dining table, 136.4ms\n",
            "Speed: 3.4ms preprocess, 136.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1727.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1736.jpg: 384x640 11 persons, 11 chairs, 1 dining table, 1 laptop, 137.5ms\n",
            "Speed: 3.4ms preprocess, 137.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1736.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1738.jpg: 384x640 12 persons, 1 bench, 15 chairs, 1 laptop, 128.3ms\n",
            "Speed: 3.0ms preprocess, 128.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1738.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1746.jpg: 384x640 10 persons, 1 bench, 13 chairs, 128.0ms\n",
            "Speed: 3.0ms preprocess, 128.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1746.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1758.jpg: 384x640 14 persons, 15 chairs, 130.5ms\n",
            "Speed: 3.0ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1758.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1768.jpg: 384x640 13 persons, 15 chairs, 1 laptop, 237.3ms\n",
            "Speed: 5.2ms preprocess, 237.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1768.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1769.jpg: 384x640 13 persons, 12 chairs, 1 laptop, 138.4ms\n",
            "Speed: 3.5ms preprocess, 138.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1769.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1776.jpg: 384x640 13 persons, 13 chairs, 1 laptop, 161.7ms\n",
            "Speed: 3.7ms preprocess, 161.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1776.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1785.jpg: 384x640 13 persons, 10 chairs, 2 laptops, 136.6ms\n",
            "Speed: 3.8ms preprocess, 136.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1785.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1787.jpg: 384x640 13 persons, 12 chairs, 1 laptop, 130.3ms\n",
            "Speed: 2.9ms preprocess, 130.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1787.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1790.jpg: 384x640 13 persons, 12 chairs, 1 laptop, 142.7ms\n",
            "Speed: 2.9ms preprocess, 142.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1790.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1800.jpg: 384x640 12 persons, 10 chairs, 2 laptops, 128.7ms\n",
            "Speed: 3.0ms preprocess, 128.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1800.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1808.jpg: 384x640 13 persons, 8 chairs, 2 laptops, 243.4ms\n",
            "Speed: 5.1ms preprocess, 243.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1808.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1809.jpg: 384x640 12 persons, 11 chairs, 2 laptops, 152.1ms\n",
            "Speed: 5.1ms preprocess, 152.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1809.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1820.jpg: 384x640 16 persons, 5 chairs, 139.2ms\n",
            "Speed: 3.0ms preprocess, 139.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1820.jpg: 14 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1825.jpg: 384x640 18 persons, 5 chairs, 1 book, 159.2ms\n",
            "Speed: 6.5ms preprocess, 159.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1825.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1832.jpg: 384x640 14 persons, 6 chairs, 135.3ms\n",
            "Speed: 3.1ms preprocess, 135.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1832.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1843.jpg: 384x640 18 persons, 5 chairs, 138.2ms\n",
            "Speed: 3.5ms preprocess, 138.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1843.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1854.jpg: 384x640 19 persons, 5 chairs, 208.7ms\n",
            "Speed: 5.2ms preprocess, 208.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1854.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1861.jpg: 384x640 17 persons, 6 chairs, 2 books, 223.1ms\n",
            "Speed: 6.1ms preprocess, 223.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1861.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1868.jpg: 384x640 18 persons, 1 backpack, 6 chairs, 1 book, 130.8ms\n",
            "Speed: 2.9ms preprocess, 130.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1868.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1870.jpg: 384x640 17 persons, 1 backpack, 7 chairs, 1 book, 140.3ms\n",
            "Speed: 3.3ms preprocess, 140.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1870.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1876.jpg: 384x640 15 persons, 6 chairs, 1 laptop, 156.2ms\n",
            "Speed: 3.5ms preprocess, 156.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1876.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1877.jpg: 384x640 17 persons, 4 chairs, 1 book, 128.2ms\n",
            "Speed: 2.9ms preprocess, 128.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1877.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1885.jpg: 384x640 15 persons, 5 chairs, 1 laptop, 224.1ms\n",
            "Speed: 5.1ms preprocess, 224.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1885.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1902.jpg: 384x640 15 persons, 6 chairs, 1 laptop, 221.0ms\n",
            "Speed: 5.0ms preprocess, 221.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1902.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1910.jpg: 384x640 16 persons, 3 chairs, 1 laptop, 1 book, 132.1ms\n",
            "Speed: 3.1ms preprocess, 132.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1910.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1911.jpg: 384x640 16 persons, 5 chairs, 144.0ms\n",
            "Speed: 3.3ms preprocess, 144.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1911.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1919.jpg: 384x640 17 persons, 3 chairs, 1 laptop, 1 book, 128.9ms\n",
            "Speed: 2.9ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1919.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1921.jpg: 384x640 16 persons, 1 frisbee, 2 chairs, 1 laptop, 129.5ms\n",
            "Speed: 3.0ms preprocess, 129.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1921.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1924.jpg: 384x640 17 persons, 2 chairs, 1 laptop, 214.4ms\n",
            "Speed: 4.5ms preprocess, 214.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1924.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1926.jpg: 384x640 20 persons, 5 chairs, 238.1ms\n",
            "Speed: 5.0ms preprocess, 238.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1926.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1934.jpg: 384x640 17 persons, 3 chairs, 1 laptop, 129.2ms\n",
            "Speed: 3.1ms preprocess, 129.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1934.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1941.jpg: 384x640 18 persons, 2 chairs, 1 laptop, 1 book, 132.8ms\n",
            "Speed: 2.8ms preprocess, 132.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1941.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1948.jpg: 384x640 19 persons, 2 chairs, 1 laptop, 132.9ms\n",
            "Speed: 3.1ms preprocess, 132.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1948.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1951.jpg: 384x640 19 persons, 2 chairs, 1 laptop, 155.5ms\n",
            "Speed: 3.5ms preprocess, 155.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1951.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1962.jpg: 384x640 19 persons, 2 chairs, 222.7ms\n",
            "Speed: 5.1ms preprocess, 222.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1962.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1968.jpg: 384x640 17 persons, 2 chairs, 1 laptop, 152.6ms\n",
            "Speed: 3.3ms preprocess, 152.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1968.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1973.jpg: 384x640 17 persons, 3 chairs, 136.2ms\n",
            "Speed: 3.1ms preprocess, 136.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1973.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1975.jpg: 384x640 14 persons, 3 chairs, 160.1ms\n",
            "Speed: 3.3ms preprocess, 160.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1975.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1980.jpg: 384x640 16 persons, 1 backpack, 1 handbag, 2 chairs, 140.4ms\n",
            "Speed: 3.4ms preprocess, 140.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1980.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1982.jpg: 384x640 18 persons, 1 chair, 1 laptop, 130.3ms\n",
            "Speed: 3.0ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1982.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1983.jpg: 384x640 16 persons, 1 chair, 224.7ms\n",
            "Speed: 5.5ms preprocess, 224.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1983.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1991.jpg: 384x640 16 persons, 3 chairs, 1 laptop, 144.0ms\n",
            "Speed: 3.5ms preprocess, 144.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1991.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2000.jpg: 384x640 18 persons, 1 chair, 141.4ms\n",
            "Speed: 3.4ms preprocess, 141.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2000.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2002.jpg: 384x640 17 persons, 1 chair, 141.7ms\n",
            "Speed: 3.4ms preprocess, 141.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2002.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2012.jpg: 384x640 17 persons, 3 chairs, 128.8ms\n",
            "Speed: 3.1ms preprocess, 128.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2012.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2017.jpg: 384x640 17 persons, 1 handbag, 4 chairs, 1 laptop, 127.3ms\n",
            "Speed: 2.8ms preprocess, 127.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2017.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2020.jpg: 384x640 18 persons, 1 handbag, 4 chairs, 1 laptop, 203.5ms\n",
            "Speed: 5.1ms preprocess, 203.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2020.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2029.jpg: 384x640 15 persons, 1 bench, 1 handbag, 2 chairs, 143.1ms\n",
            "Speed: 4.9ms preprocess, 143.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2029.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2038.jpg: 384x640 16 persons, 1 bench, 3 chairs, 1 laptop, 145.7ms\n",
            "Speed: 5.0ms preprocess, 145.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2038.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2040.jpg: 384x640 12 persons, 7 chairs, 135.3ms\n",
            "Speed: 3.2ms preprocess, 135.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2040.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2039.jpg: 384x640 10 persons, 8 chairs, 137.0ms\n",
            "Speed: 2.9ms preprocess, 137.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2039.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/43.jpg: 384x640 11 persons, 7 chairs, 146.7ms\n",
            "Speed: 4.2ms preprocess, 146.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "43.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/53.jpg: 384x640 9 persons, 8 chairs, 132.1ms\n",
            "Speed: 2.8ms preprocess, 132.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "53.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/65.jpg: 384x640 14 persons, 9 chairs, 200.2ms\n",
            "Speed: 4.5ms preprocess, 200.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "65.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/68.jpg: 384x640 10 persons, 6 chairs, 239.4ms\n",
            "Speed: 5.0ms preprocess, 239.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "68.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/72.jpg: 384x640 14 persons, 10 chairs, 139.1ms\n",
            "Speed: 3.5ms preprocess, 139.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "72.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/78.jpg: 384x640 12 persons, 7 chairs, 142.5ms\n",
            "Speed: 3.5ms preprocess, 142.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "78.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/79.jpg: 384x640 13 persons, 6 chairs, 135.2ms\n",
            "Speed: 2.8ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "79.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/82.jpg: 384x640 10 persons, 9 chairs, 155.0ms\n",
            "Speed: 5.0ms preprocess, 155.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "82.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/83.jpg: 384x640 11 persons, 7 chairs, 127.6ms\n",
            "Speed: 4.7ms preprocess, 127.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "83.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/86.jpg: 384x640 11 persons, 8 chairs, 143.6ms\n",
            "Speed: 3.4ms preprocess, 143.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "86.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/95.jpg: 384x640 11 persons, 10 chairs, 224.8ms\n",
            "Speed: 5.0ms preprocess, 224.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "95.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/102.jpg: 384x640 13 persons, 7 chairs, 239.1ms\n",
            "Speed: 5.4ms preprocess, 239.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "102.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/113.jpg: 384x640 13 persons, 7 chairs, 2 books, 141.3ms\n",
            "Speed: 3.3ms preprocess, 141.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "113.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/123.jpg: 384x640 13 persons, 7 chairs, 141.2ms\n",
            "Speed: 3.4ms preprocess, 141.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "123.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/126.jpg: 384x640 12 persons, 7 chairs, 1 book, 141.0ms\n",
            "Speed: 3.3ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "126.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/129.jpg: 384x640 10 persons, 6 chairs, 1 book, 161.0ms\n",
            "Speed: 3.4ms preprocess, 161.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "129.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/130.jpg: 384x640 10 persons, 8 chairs, 2 books, 127.6ms\n",
            "Speed: 3.0ms preprocess, 127.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "130.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/133.jpg: 384x640 11 persons, 8 chairs, 1 book, 135.4ms\n",
            "Speed: 2.9ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "133.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/142.jpg: 384x640 12 persons, 6 chairs, 1 book, 238.2ms\n",
            "Speed: 5.1ms preprocess, 238.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "142.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/144.jpg: 384x640 12 persons, 10 chairs, 227.2ms\n",
            "Speed: 4.8ms preprocess, 227.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "144.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/146.jpg: 384x640 12 persons, 10 chairs, 135.6ms\n",
            "Speed: 3.1ms preprocess, 135.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "146.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/147.jpg: 384x640 10 persons, 6 chairs, 144.4ms\n",
            "Speed: 3.4ms preprocess, 144.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "147.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/150.jpg: 384x640 9 persons, 10 chairs, 139.8ms\n",
            "Speed: 3.4ms preprocess, 139.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "150.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/153.jpg: 384x640 11 persons, 9 chairs, 152.5ms\n",
            "Speed: 2.9ms preprocess, 152.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "153.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/155.jpg: 384x640 12 persons, 7 chairs, 138.7ms\n",
            "Speed: 3.4ms preprocess, 138.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "155.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/160.jpg: 384x640 10 persons, 7 chairs, 1 book, 129.7ms\n",
            "Speed: 3.0ms preprocess, 129.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "160.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/168.jpg: 384x640 11 persons, 9 chairs, 223.5ms\n",
            "Speed: 5.5ms preprocess, 223.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "168.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/170.jpg: 384x640 11 persons, 10 chairs, 210.8ms\n",
            "Speed: 4.5ms preprocess, 210.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "170.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/172.jpg: 384x640 10 persons, 9 chairs, 140.5ms\n",
            "Speed: 3.2ms preprocess, 140.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "172.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/174.jpg: 384x640 11 persons, 5 chairs, 156.5ms\n",
            "Speed: 3.3ms preprocess, 156.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "174.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/176.jpg: 384x640 15 persons, 5 chairs, 131.4ms\n",
            "Speed: 2.8ms preprocess, 131.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "176.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/177.jpg: 384x640 12 persons, 6 chairs, 141.2ms\n",
            "Speed: 3.4ms preprocess, 141.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "177.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/178.jpg: 384x640 12 persons, 4 chairs, 1 book, 157.7ms\n",
            "Speed: 3.2ms preprocess, 157.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "178.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/181.jpg: 384x640 10 persons, 4 chairs, 1 book, 145.5ms\n",
            "Speed: 3.2ms preprocess, 145.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "181.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/189.jpg: 384x640 12 persons, 6 chairs, 189.1ms\n",
            "Speed: 3.3ms preprocess, 189.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "189.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/191.jpg: 384x640 11 persons, 5 chairs, 204.2ms\n",
            "Speed: 4.5ms preprocess, 204.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "191.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/196.jpg: 384x640 10 persons, 5 chairs, 136.7ms\n",
            "Speed: 3.6ms preprocess, 136.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "196.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/200.jpg: 384x640 11 persons, 6 chairs, 135.8ms\n",
            "Speed: 2.9ms preprocess, 135.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "200.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/209.jpg: 384x640 10 persons, 7 chairs, 151.2ms\n",
            "Speed: 3.0ms preprocess, 151.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "209.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/212.jpg: 384x640 12 persons, 5 chairs, 143.8ms\n",
            "Speed: 3.3ms preprocess, 143.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "212.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/223.jpg: 384x640 16 persons, 5 chairs, 2 tvs, 11 laptops, 145.8ms\n",
            "Speed: 2.9ms preprocess, 145.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "223.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/228.jpg: 384x640 19 persons, 5 chairs, 1 tv, 11 laptops, 141.9ms\n",
            "Speed: 3.0ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "228.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/229.jpg: 384x640 16 persons, 7 chairs, 2 tvs, 11 laptops, 130.3ms\n",
            "Speed: 2.8ms preprocess, 130.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "229.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/235.jpg: 384x640 17 persons, 4 chairs, 11 laptops, 211.4ms\n",
            "Speed: 4.9ms preprocess, 211.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "235.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/238.jpg: 384x640 18 persons, 4 chairs, 10 laptops, 144.8ms\n",
            "Speed: 3.3ms preprocess, 144.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "238.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/239.jpg: 384x640 15 persons, 5 chairs, 12 laptops, 142.9ms\n",
            "Speed: 4.0ms preprocess, 142.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "239.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/240.jpg: 384x640 17 persons, 5 chairs, 12 laptops, 156.4ms\n",
            "Speed: 3.3ms preprocess, 156.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "240.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/247.jpg: 384x640 19 persons, 5 chairs, 12 laptops, 127.8ms\n",
            "Speed: 3.0ms preprocess, 127.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "247.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/248.jpg: 384x640 19 persons, 6 chairs, 1 tv, 12 laptops, 131.7ms\n",
            "Speed: 3.0ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "248.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/260.jpg: 384x640 17 persons, 6 chairs, 1 tv, 13 laptops, 234.6ms\n",
            "Speed: 5.1ms preprocess, 234.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "260.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/261.jpg: 384x640 17 persons, 6 chairs, 15 laptops, 231.0ms\n",
            "Speed: 4.9ms preprocess, 231.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "261.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/263.jpg: 384x640 16 persons, 3 chairs, 13 laptops, 134.4ms\n",
            "Speed: 3.2ms preprocess, 134.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "263.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/264.jpg: 384x640 16 persons, 5 chairs, 13 laptops, 134.4ms\n",
            "Speed: 3.3ms preprocess, 134.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "264.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/269.jpg: 384x640 16 persons, 5 chairs, 2 tvs, 15 laptops, 134.3ms\n",
            "Speed: 3.7ms preprocess, 134.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "269.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/281.jpg: 384x640 20 persons, 2 chairs, 14 laptops, 130.8ms\n",
            "Speed: 2.8ms preprocess, 130.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "281.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/285.jpg: 384x640 21 persons, 6 chairs, 1 tv, 10 laptops, 144.4ms\n",
            "Speed: 3.7ms preprocess, 144.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "285.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/295.jpg: 384x640 18 persons, 6 chairs, 1 tv, 10 laptops, 224.9ms\n",
            "Speed: 5.3ms preprocess, 224.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "295.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/311.jpg: 384x640 16 persons, 4 chairs, 12 laptops, 144.3ms\n",
            "Speed: 3.7ms preprocess, 144.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "311.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/314.jpg: 384x640 15 persons, 5 chairs, 8 laptops, 129.4ms\n",
            "Speed: 3.3ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "314.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/315.jpg: 384x640 18 persons, 4 chairs, 2 tvs, 13 laptops, 132.8ms\n",
            "Speed: 3.1ms preprocess, 132.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "315.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/323.jpg: 384x640 19 persons, 5 chairs, 1 tv, 13 laptops, 144.6ms\n",
            "Speed: 3.3ms preprocess, 144.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "323.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/328.jpg: 384x640 19 persons, 4 chairs, 12 laptops, 143.8ms\n",
            "Speed: 5.2ms preprocess, 143.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "328.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/335.jpg: 384x640 18 persons, 8 chairs, 11 laptops, 129.5ms\n",
            "Speed: 3.0ms preprocess, 129.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "335.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/341.jpg: 384x640 19 persons, 7 chairs, 1 dining table, 1 tv, 9 laptops, 222.4ms\n",
            "Speed: 4.7ms preprocess, 222.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "341.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/342.jpg: 384x640 19 persons, 5 chairs, 10 laptops, 152.5ms\n",
            "Speed: 3.5ms preprocess, 152.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "342.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/347.jpg: 384x640 21 persons, 5 chairs, 8 laptops, 140.1ms\n",
            "Speed: 3.3ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "347.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/351.jpg: 384x640 18 persons, 3 chairs, 11 laptops, 163.9ms\n",
            "Speed: 3.4ms preprocess, 163.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "351.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/355.jpg: 384x640 21 persons, 2 chairs, 1 tv, 11 laptops, 138.8ms\n",
            "Speed: 3.3ms preprocess, 138.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "355.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/359.jpg: 384x640 18 persons, 3 chairs, 1 tv, 10 laptops, 144.1ms\n",
            "Speed: 3.6ms preprocess, 144.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "359.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/364.jpg: 384x640 18 persons, 2 chairs, 2 tvs, 8 laptops, 1 cell phone, 225.7ms\n",
            "Speed: 4.8ms preprocess, 225.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "364.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/366.jpg: 384x640 15 persons, 2 chairs, 1 tv, 9 laptops, 1 mouse, 1 cell phone, 219.8ms\n",
            "Speed: 5.6ms preprocess, 219.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "366.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/378.jpg: 384x640 19 persons, 3 chairs, 10 laptops, 1 cell phone, 146.8ms\n",
            "Speed: 3.3ms preprocess, 146.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "378.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/381.jpg: 384x640 17 persons, 4 chairs, 1 tv, 9 laptops, 1 cell phone, 143.3ms\n",
            "Speed: 3.7ms preprocess, 143.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "381.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/382.jpg: 384x640 16 persons, 5 chairs, 2 tvs, 8 laptops, 1 cell phone, 132.1ms\n",
            "Speed: 3.0ms preprocess, 132.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "382.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/385.jpg: 384x640 16 persons, 4 chairs, 1 tv, 8 laptops, 1 cell phone, 141.7ms\n",
            "Speed: 3.4ms preprocess, 141.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "385.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/389.jpg: 384x640 17 persons, 4 chairs, 9 laptops, 1 cell phone, 209.5ms\n",
            "Speed: 4.6ms preprocess, 209.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "389.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/392.jpg: 384x640 18 persons, 5 chairs, 8 laptops, 1 cell phone, 207.3ms\n",
            "Speed: 4.5ms preprocess, 207.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "392.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/394.jpg: 384x640 18 persons, 6 chairs, 6 laptops, 1 cell phone, 131.8ms\n",
            "Speed: 3.2ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "394.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/398.jpg: 384x640 20 persons, 5 chairs, 2 tvs, 7 laptops, 1 cell phone, 127.5ms\n",
            "Speed: 2.9ms preprocess, 127.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "398.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/401.jpg: 384x640 16 persons, 4 chairs, 1 tv, 7 laptops, 1 cell phone, 137.6ms\n",
            "Speed: 3.3ms preprocess, 137.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "401.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/408.jpg: 384x640 15 persons, 3 chairs, 5 laptops, 1 cell phone, 131.0ms\n",
            "Speed: 3.1ms preprocess, 131.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "408.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/410.jpg: 384x640 16 persons, 1 umbrella, 1 cup, 4 chairs, 2 tvs, 5 laptops, 1 cell phone, 227.8ms\n",
            "Speed: 3.4ms preprocess, 227.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "410.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/413.jpg: 384x640 12 persons, 3 chairs, 1 bed, 2 tvs, 7 laptops, 1 cell phone, 216.8ms\n",
            "Speed: 5.2ms preprocess, 216.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "413.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/414.jpg: 384x640 12 persons, 2 chairs, 1 bed, 5 laptops, 1 mouse, 1 cell phone, 151.4ms\n",
            "Speed: 3.5ms preprocess, 151.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "414.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/418.jpg: 384x640 17 persons, 1 chair, 1 bed, 1 tv, 7 laptops, 1 mouse, 1 cell phone, 138.2ms\n",
            "Speed: 3.3ms preprocess, 138.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "418.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/422.jpg: 384x640 18 persons, 2 chairs, 1 bed, 1 tv, 4 laptops, 134.7ms\n",
            "Speed: 2.9ms preprocess, 134.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "422.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/425.jpg: 384x640 14 persons, 2 chairs, 1 tv, 8 laptops, 1 cell phone, 132.8ms\n",
            "Speed: 3.0ms preprocess, 132.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "425.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/436.jpg: 384x640 14 persons, 1 wine glass, 2 chairs, 2 tvs, 7 laptops, 1 mouse, 1 cell phone, 130.2ms\n",
            "Speed: 2.8ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "436.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/439.jpg: 384x640 14 persons, 3 chairs, 3 tvs, 12 laptops, 1 cell phone, 151.2ms\n",
            "Speed: 2.9ms preprocess, 151.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "439.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/450.jpg: 384x640 15 persons, 6 chairs, 1 tv, 9 laptops, 1 cell phone, 212.4ms\n",
            "Speed: 4.8ms preprocess, 212.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "450.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/455.jpg: 384x640 18 persons, 6 chairs, 1 tv, 7 laptops, 1 cell phone, 143.5ms\n",
            "Speed: 3.3ms preprocess, 143.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "455.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/458.jpg: 384x640 14 persons, 2 chairs, 1 tv, 11 laptops, 1 cell phone, 139.9ms\n",
            "Speed: 3.3ms preprocess, 139.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "458.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/469.jpg: 384x640 15 persons, 3 chairs, 2 tvs, 9 laptops, 1 cell phone, 133.8ms\n",
            "Speed: 2.9ms preprocess, 133.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "469.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/483.jpg: 384x640 15 persons, 1 tie, 5 chairs, 1 tv, 8 laptops, 1 cell phone, 141.1ms\n",
            "Speed: 3.2ms preprocess, 141.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "483.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/488.jpg: 384x640 14 persons, 4 chairs, 8 laptops, 1 mouse, 1 cell phone, 141.6ms\n",
            "Speed: 3.5ms preprocess, 141.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "488.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/492.jpg: 384x640 16 persons, 4 chairs, 3 tvs, 9 laptops, 1 cell phone, 180.9ms\n",
            "Speed: 2.9ms preprocess, 180.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "492.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/503.jpg: 384x640 8 persons, 4 tvs, 10 laptops, 3 mouses, 1 keyboard, 1 clock, 219.6ms\n",
            "Speed: 5.1ms preprocess, 219.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "503.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/512.jpg: 384x640 12 persons, 1 chair, 6 tvs, 5 laptops, 2 mouses, 1 clock, 164.3ms\n",
            "Speed: 5.0ms preprocess, 164.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "512.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/514.jpg: 384x640 9 persons, 1 chair, 4 tvs, 7 laptops, 2 mouses, 1 clock, 140.8ms\n",
            "Speed: 3.4ms preprocess, 140.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "514.jpg: 2 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/516.jpg: 384x640 9 persons, 2 chairs, 4 tvs, 7 laptops, 3 mouses, 1 clock, 139.9ms\n",
            "Speed: 3.4ms preprocess, 139.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "516.jpg: 3 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/519.jpg: 384x640 9 persons, 1 chair, 4 tvs, 8 laptops, 3 mouses, 1 keyboard, 1 clock, 152.2ms\n",
            "Speed: 3.5ms preprocess, 152.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "519.jpg: 6 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/521.jpg: 384x640 9 persons, 4 tvs, 7 laptops, 3 mouses, 1 clock, 152.4ms\n",
            "Speed: 3.0ms preprocess, 152.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "521.jpg: 3 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/524.jpg: 384x640 10 persons, 5 tvs, 7 laptops, 2 mouses, 1 clock, 140.2ms\n",
            "Speed: 2.9ms preprocess, 140.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "524.jpg: 3 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/534.jpg: 384x640 10 persons, 3 tvs, 5 laptops, 3 mouses, 1 clock, 148.2ms\n",
            "Speed: 3.4ms preprocess, 148.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "534.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/539.jpg: 384x640 10 persons, 4 tvs, 5 laptops, 1 mouse, 1 cell phone, 1 clock, 145.8ms\n",
            "Speed: 3.6ms preprocess, 145.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "539.jpg: 4 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/541.jpg: 384x640 11 persons, 3 tvs, 11 laptops, 1 mouse, 1 clock, 147.6ms\n",
            "Speed: 3.3ms preprocess, 147.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "541.jpg: 4 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/549.jpg: 384x640 9 persons, 1 chair, 3 tvs, 10 laptops, 3 mouses, 1 keyboard, 1 clock, 129.7ms\n",
            "Speed: 3.0ms preprocess, 129.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "549.jpg: 6 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/563.jpg: 384x640 7 persons, 4 tvs, 7 laptops, 3 mouses, 1 clock, 143.0ms\n",
            "Speed: 3.5ms preprocess, 143.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "563.jpg: 4 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/568.jpg: 384x640 9 persons, 1 chair, 1 dining table, 6 tvs, 8 laptops, 3 mouses, 1 cell phone, 1 clock, 142.7ms\n",
            "Speed: 3.4ms preprocess, 142.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "568.jpg: 7 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/572.jpg: 384x640 11 persons, 1 chair, 4 tvs, 12 laptops, 2 mouses, 1 clock, 205.7ms\n",
            "Speed: 4.4ms preprocess, 205.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "572.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/574.jpg: 384x640 12 persons, 1 chair, 4 tvs, 10 laptops, 2 mouses, 1 clock, 198.5ms\n",
            "Speed: 4.5ms preprocess, 198.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "574.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/580.jpg: 384x640 8 persons, 1 chair, 4 tvs, 9 laptops, 3 mouses, 1 cell phone, 1 clock, 260.9ms\n",
            "Speed: 5.3ms preprocess, 260.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "580.jpg: 6 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/582.jpg: 384x640 9 persons, 1 chair, 4 tvs, 11 laptops, 3 mouses, 1 keyboard, 1 clock, 138.1ms\n",
            "Speed: 3.6ms preprocess, 138.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "582.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/586.jpg: 384x640 9 persons, 1 chair, 4 tvs, 8 laptops, 3 mouses, 1 keyboard, 1 clock, 156.8ms\n",
            "Speed: 3.6ms preprocess, 156.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "586.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/589.jpg: 384x640 8 persons, 1 chair, 1 dining table, 4 tvs, 8 laptops, 3 mouses, 1 keyboard, 1 clock, 160.0ms\n",
            "Speed: 3.4ms preprocess, 160.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "589.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/590.jpg: 384x640 8 persons, 1 chair, 4 tvs, 7 laptops, 3 mouses, 1 clock, 138.1ms\n",
            "Speed: 3.5ms preprocess, 138.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "590.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/600.jpg: 384x640 13 persons, 1 chair, 4 tvs, 11 laptops, 3 mouses, 1 keyboard, 1 clock, 130.8ms\n",
            "Speed: 3.8ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "600.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/603.jpg: 384x640 10 persons, 4 chairs, 4 tvs, 9 laptops, 2 mouses, 1 clock, 125.5ms\n",
            "Speed: 2.9ms preprocess, 125.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "603.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/604.jpg: 384x640 12 persons, 1 chair, 4 tvs, 6 laptops, 2 mouses, 1 keyboard, 1 clock, 137.2ms\n",
            "Speed: 3.5ms preprocess, 137.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "604.jpg: 8 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/611.jpg: 384x640 12 persons, 1 chair, 5 tvs, 5 laptops, 3 mouses, 1 clock, 126.3ms\n",
            "Speed: 3.0ms preprocess, 126.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "611.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/617.jpg: 384x640 19 persons, 3 bottles, 6 chairs, 1 dining table, 3 laptops, 138.2ms\n",
            "Speed: 3.4ms preprocess, 138.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "617.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/624.jpg: 384x640 20 persons, 2 bottles, 11 chairs, 1 dining table, 206.0ms\n",
            "Speed: 4.8ms preprocess, 206.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "624.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/637.jpg: 384x640 20 persons, 2 bottles, 4 chairs, 1 laptop, 131.8ms\n",
            "Speed: 3.0ms preprocess, 131.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "637.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/638.jpg: 384x640 20 persons, 1 bottle, 7 chairs, 1 laptop, 141.7ms\n",
            "Speed: 3.4ms preprocess, 141.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "638.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/647.jpg: 384x640 19 persons, 3 bottles, 7 chairs, 1 dining table, 160.3ms\n",
            "Speed: 3.6ms preprocess, 160.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "647.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/648.jpg: 384x640 18 persons, 2 bottles, 7 chairs, 141.5ms\n",
            "Speed: 3.5ms preprocess, 141.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "648.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/649.jpg: 384x640 21 persons, 2 bottles, 5 chairs, 3 laptops, 127.3ms\n",
            "Speed: 3.0ms preprocess, 127.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "649.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/650.jpg: 384x640 16 persons, 1 bottle, 5 chairs, 222.0ms\n",
            "Speed: 5.0ms preprocess, 222.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "650.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/655.jpg: 384x640 17 persons, 3 bottles, 6 chairs, 2 laptops, 143.0ms\n",
            "Speed: 3.5ms preprocess, 143.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "655.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/663.jpg: 384x640 18 persons, 3 bottles, 6 chairs, 2 laptops, 151.0ms\n",
            "Speed: 3.4ms preprocess, 151.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "663.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/665.jpg: 384x640 19 persons, 3 bottles, 7 chairs, 2 laptops, 136.7ms\n",
            "Speed: 4.5ms preprocess, 136.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "665.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/674.jpg: 384x640 15 persons, 3 bottles, 1 bowl, 7 chairs, 159.2ms\n",
            "Speed: 3.5ms preprocess, 159.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "674.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/682.jpg: 384x640 16 persons, 2 bottles, 5 chairs, 1 laptop, 129.4ms\n",
            "Speed: 3.2ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "682.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/696.jpg: 384x640 17 persons, 1 handbag, 1 bottle, 1 cup, 8 chairs, 1 dining table, 1 laptop, 152.2ms\n",
            "Speed: 2.9ms preprocess, 152.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "696.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/697.jpg: 384x640 17 persons, 2 bottles, 1 cup, 7 chairs, 1 laptop, 214.9ms\n",
            "Speed: 5.4ms preprocess, 214.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "697.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/708.jpg: 384x640 19 persons, 2 bottles, 1 cup, 7 chairs, 144.8ms\n",
            "Speed: 3.3ms preprocess, 144.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "708.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/709.jpg: 384x640 19 persons, 1 bottle, 1 cup, 6 chairs, 148.0ms\n",
            "Speed: 3.2ms preprocess, 148.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "709.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/714.jpg: 384x640 18 persons, 3 bottles, 8 chairs, 140.0ms\n",
            "Speed: 3.5ms preprocess, 140.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "714.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/719.jpg: 384x640 17 persons, 2 bottles, 6 chairs, 1 dining table, 135.3ms\n",
            "Speed: 3.7ms preprocess, 135.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "719.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/732.jpg: 384x640 18 persons, 3 bottles, 9 chairs, 208.5ms\n",
            "Speed: 4.5ms preprocess, 208.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "732.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/733.jpg: 384x640 16 persons, 3 bottles, 7 chairs, 204.4ms\n",
            "Speed: 4.4ms preprocess, 204.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "733.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/746.jpg: 384x640 16 persons, 3 bottles, 6 chairs, 128.0ms\n",
            "Speed: 3.0ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "746.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/749.jpg: 384x640 20 persons, 2 bottles, 7 chairs, 1 laptop, 137.3ms\n",
            "Speed: 3.4ms preprocess, 137.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "749.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/758.jpg: 384x640 20 persons, 2 bottles, 7 chairs, 141.6ms\n",
            "Speed: 5.1ms preprocess, 141.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "758.jpg: 20 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/764.jpg: 384x640 16 persons, 3 bottles, 5 chairs, 128.7ms\n",
            "Speed: 3.1ms preprocess, 128.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "764.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/766.jpg: 384x640 17 persons, 2 bottles, 5 chairs, 1 laptop, 226.5ms\n",
            "Speed: 5.0ms preprocess, 226.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "766.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/770.jpg: 384x640 15 persons, 3 bottles, 9 chairs, 1 dining table, 232.3ms\n",
            "Speed: 5.7ms preprocess, 232.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "770.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/777.jpg: 384x640 19 persons, 3 bottles, 5 chairs, 1 dining table, 2 laptops, 141.1ms\n",
            "Speed: 3.6ms preprocess, 141.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "777.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/779.jpg: 384x640 16 persons, 1 bottle, 6 chairs, 2 laptops, 137.8ms\n",
            "Speed: 3.1ms preprocess, 137.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "779.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/787.jpg: 384x640 17 persons, 4 bottles, 5 chairs, 4 laptops, 134.2ms\n",
            "Speed: 3.6ms preprocess, 134.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "787.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/790.jpg: 384x640 20 persons, 2 bottles, 2 chairs, 1 laptop, 128.6ms\n",
            "Speed: 3.7ms preprocess, 128.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "790.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/805.jpg: 384x640 17 persons, 3 bottles, 7 chairs, 3 laptops, 195.6ms\n",
            "Speed: 3.4ms preprocess, 195.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "805.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/806.jpg: 384x640 18 persons, 2 bottles, 8 chairs, 2 laptops, 230.4ms\n",
            "Speed: 4.8ms preprocess, 230.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "806.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/808.jpg: 384x640 21 persons, 3 bottles, 5 chairs, 1 laptop, 149.2ms\n",
            "Speed: 5.3ms preprocess, 149.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "808.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/816.jpg: 384x640 17 persons, 2 bottles, 9 chairs, 1 dining table, 2 laptops, 135.4ms\n",
            "Speed: 3.4ms preprocess, 135.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "816.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/818.jpg: 384x640 17 persons, 2 bottles, 8 chairs, 1 dining table, 1 laptop, 130.9ms\n",
            "Speed: 3.0ms preprocess, 130.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "818.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/825.jpg: 384x640 14 persons, 2 bottles, 6 chairs, 1 laptop, 145.2ms\n",
            "Speed: 3.5ms preprocess, 145.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "825.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/836.jpg: 384x640 13 persons, 16 chairs, 3 dining tables, 133.7ms\n",
            "Speed: 3.0ms preprocess, 133.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "836.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/842.jpg: 384x640 15 persons, 13 chairs, 3 dining tables, 196.4ms\n",
            "Speed: 4.6ms preprocess, 196.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "842.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/846.jpg: 384x640 15 persons, 17 chairs, 3 dining tables, 211.6ms\n",
            "Speed: 4.9ms preprocess, 211.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "846.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/848.jpg: 384x640 14 persons, 16 chairs, 3 dining tables, 146.1ms\n",
            "Speed: 4.5ms preprocess, 146.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "848.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/854.jpg: 384x640 13 persons, 17 chairs, 3 dining tables, 154.2ms\n",
            "Speed: 3.4ms preprocess, 154.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "854.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/855.jpg: 384x640 14 persons, 18 chairs, 2 dining tables, 132.6ms\n",
            "Speed: 3.1ms preprocess, 132.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "855.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/868.jpg: 384x640 13 persons, 1 bottle, 11 chairs, 3 dining tables, 1 book, 126.7ms\n",
            "Speed: 3.7ms preprocess, 126.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "868.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/878.jpg: 384x640 13 persons, 13 chairs, 3 dining tables, 1 laptop, 142.2ms\n",
            "Speed: 3.5ms preprocess, 142.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "878.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/881.jpg: 384x640 16 persons, 16 chairs, 3 dining tables, 1 laptop, 139.9ms\n",
            "Speed: 3.5ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "881.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/888.jpg: 384x640 11 persons, 10 chairs, 6 dining tables, 201.6ms\n",
            "Speed: 4.8ms preprocess, 201.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "888.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/889.jpg: 384x640 12 persons, 13 chairs, 3 dining tables, 1 laptop, 1 book, 143.6ms\n",
            "Speed: 3.1ms preprocess, 143.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "889.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/894.jpg: 384x640 12 persons, 16 chairs, 4 dining tables, 1 laptop, 1 book, 130.7ms\n",
            "Speed: 3.0ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "894.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/895.jpg: 384x640 16 persons, 16 chairs, 4 dining tables, 1 book, 151.8ms\n",
            "Speed: 2.8ms preprocess, 151.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "895.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/896.jpg: 384x640 14 persons, 14 chairs, 4 dining tables, 1 book, 255.7ms\n",
            "Speed: 7.9ms preprocess, 255.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "896.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/897.jpg: 384x640 11 persons, 14 chairs, 4 dining tables, 1 laptop, 1 book, 138.4ms\n",
            "Speed: 3.1ms preprocess, 138.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "897.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/904.jpg: 384x640 15 persons, 16 chairs, 5 dining tables, 1 laptop, 1 book, 142.7ms\n",
            "Speed: 3.5ms preprocess, 142.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "904.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/905.jpg: 384x640 14 persons, 13 chairs, 5 dining tables, 1 laptop, 1 book, 226.4ms\n",
            "Speed: 5.8ms preprocess, 226.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "905.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/909.jpg: 384x640 15 persons, 16 chairs, 4 dining tables, 2 laptops, 1 book, 165.1ms\n",
            "Speed: 4.9ms preprocess, 165.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "909.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/915.jpg: 384x640 16 persons, 13 chairs, 4 dining tables, 1 laptop, 142.6ms\n",
            "Speed: 3.3ms preprocess, 142.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "915.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/920.jpg: 384x640 15 persons, 16 chairs, 2 dining tables, 163.2ms\n",
            "Speed: 4.3ms preprocess, 163.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "920.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/921.jpg: 384x640 16 persons, 15 chairs, 2 dining tables, 1 book, 142.1ms\n",
            "Speed: 3.5ms preprocess, 142.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "921.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/932.jpg: 384x640 17 persons, 10 chairs, 2 dining tables, 3 laptops, 1 book, 133.9ms\n",
            "Speed: 3.1ms preprocess, 133.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "932.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/937.jpg: 384x640 15 persons, 12 chairs, 2 dining tables, 1 book, 230.6ms\n",
            "Speed: 4.7ms preprocess, 230.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "937.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/945.jpg: 384x640 12 persons, 14 chairs, 3 dining tables, 1 laptop, 1 book, 213.9ms\n",
            "Speed: 4.6ms preprocess, 213.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "945.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/950.jpg: 384x640 11 persons, 12 chairs, 4 dining tables, 1 book, 134.3ms\n",
            "Speed: 3.3ms preprocess, 134.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "950.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/962.jpg: 384x640 11 persons, 17 chairs, 4 dining tables, 1 laptop, 142.9ms\n",
            "Speed: 3.5ms preprocess, 142.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "962.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/966.jpg: 384x640 11 persons, 14 chairs, 6 dining tables, 1 laptop, 140.4ms\n",
            "Speed: 5.3ms preprocess, 140.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "966.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/972.jpg: 384x640 11 persons, 14 chairs, 4 dining tables, 1 laptop, 138.8ms\n",
            "Speed: 3.4ms preprocess, 138.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "972.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/976.jpg: 384x640 15 persons, 11 chairs, 4 dining tables, 1 book, 145.8ms\n",
            "Speed: 3.3ms preprocess, 145.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "976.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/982.jpg: 384x640 13 persons, 14 chairs, 7 dining tables, 132.3ms\n",
            "Speed: 3.3ms preprocess, 132.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "982.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1016.jpg: 384x640 17 persons, 14 chairs, 2 dining tables, 151.5ms\n",
            "Speed: 3.4ms preprocess, 151.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1016.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1020.jpg: 384x640 13 persons, 14 chairs, 3 dining tables, 205.8ms\n",
            "Speed: 4.4ms preprocess, 205.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1020.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1022.jpg: 384x640 16 persons, 16 chairs, 3 dining tables, 1 laptop, 127.1ms\n",
            "Speed: 2.9ms preprocess, 127.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1022.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1024.jpg: 384x640 14 persons, 17 chairs, 3 dining tables, 130.2ms\n",
            "Speed: 3.2ms preprocess, 130.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1024.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1025.jpg: 384x640 14 persons, 15 chairs, 3 dining tables, 138.3ms\n",
            "Speed: 3.3ms preprocess, 138.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1025.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1030.jpg: 384x640 13 persons, 13 chairs, 3 dining tables, 1 laptop, 126.9ms\n",
            "Speed: 3.0ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1030.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1032.jpg: 384x640 12 persons, 13 chairs, 2 dining tables, 1 laptop, 142.2ms\n",
            "Speed: 3.3ms preprocess, 142.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1032.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1038.jpg: 384x640 13 persons, 17 chairs, 2 dining tables, 1 laptop, 1 book, 144.3ms\n",
            "Speed: 5.0ms preprocess, 144.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1038.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1040.jpg: 384x640 12 persons, 12 chairs, 3 dining tables, 1 laptop, 1 book, 216.6ms\n",
            "Speed: 4.9ms preprocess, 216.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1040.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/10.jpg: 384x640 10 persons, 8 chairs, 143.4ms\n",
            "Speed: 3.7ms preprocess, 143.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "10.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/14.jpg: 384x640 11 persons, 7 chairs, 143.4ms\n",
            "Speed: 3.5ms preprocess, 143.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "14.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/15.jpg: 384x640 12 persons, 8 chairs, 144.1ms\n",
            "Speed: 3.6ms preprocess, 144.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "15.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/16.jpg: 384x640 12 persons, 7 chairs, 150.9ms\n",
            "Speed: 3.1ms preprocess, 150.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "16.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/17.jpg: 384x640 11 persons, 7 chairs, 129.3ms\n",
            "Speed: 2.9ms preprocess, 129.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "17.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/23.jpg: 384x640 11 persons, 8 chairs, 156.7ms\n",
            "Speed: 5.4ms preprocess, 156.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "23.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/26.jpg: 384x640 10 persons, 10 chairs, 150.8ms\n",
            "Speed: 3.6ms preprocess, 150.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "26.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/35.jpg: 384x640 13 persons, 4 chairs, 1 book, 216.0ms\n",
            "Speed: 5.6ms preprocess, 216.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "35.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/39.jpg: 384x640 11 persons, 8 chairs, 1 book, 136.0ms\n",
            "Speed: 3.3ms preprocess, 136.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "39.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/41.jpg: 384x640 12 persons, 7 chairs, 2 books, 132.4ms\n",
            "Speed: 3.0ms preprocess, 132.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "41.jpg: 12 labels saved (Teacher direction: left)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELING IMAGES = v3\n",
        "\n",
        "FaceMesh 1"
      ],
      "metadata": {
        "id": "DyhUulNwuRaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "\n",
        "# Paths\n",
        "image_folder = '/content/drive/MyDrive/Saif/img'\n",
        "label_folder = '/content/drive/MyDrive/Saif/labels'\n",
        "visualized_folder = '/content/drive/MyDrive/Saif/visual'\n",
        "\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "os.makedirs(visualized_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv8 model for person detection\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Initialize MediaPipe FaceMesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
        "\n",
        "def estimate_head_direction(landmarks):\n",
        "    try:\n",
        "        left_eye = landmarks[33]\n",
        "        right_eye = landmarks[263]\n",
        "        dx = left_eye.x - right_eye.x\n",
        "        if dx > 0.04:\n",
        "            return 'left'\n",
        "        elif dx < -0.04:\n",
        "            return 'right'\n",
        "        else:\n",
        "            return 'front'\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "def classify_posture_binary(landmarks, teacher_dir):\n",
        "    direction = estimate_head_direction(landmarks)\n",
        "    return 0 if direction == teacher_dir else 1  # 0: Engaged, 1: Distracted\n",
        "\n",
        "# Process all images\n",
        "for file in os.listdir(image_folder):\n",
        "    if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(image_folder, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    img_h, img_w = image.shape[:2]\n",
        "\n",
        "    results = model(image_path)[0]\n",
        "    boxes = results.boxes.data\n",
        "\n",
        "    all_directions = []\n",
        "    temp_landmarks = []\n",
        "    temp_boxes = []\n",
        "\n",
        "    for box in boxes:\n",
        "        cls = int(box[5])\n",
        "        if cls != 0:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
        "\n",
        "        person_crop = image[y1:y2, x1:x2]\n",
        "        if person_crop.size == 0:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
        "            face_result = face_mesh.process(crop_rgb)\n",
        "        except:\n",
        "            face_result = None\n",
        "\n",
        "        if face_result and face_result.multi_face_landmarks:\n",
        "            landmarks = face_result.multi_face_landmarks[0].landmark\n",
        "            direction = estimate_head_direction(landmarks)\n",
        "            all_directions.append(direction)\n",
        "            temp_landmarks.append(landmarks)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "        else:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    teacher_dir = 'front'\n",
        "    if all_directions:\n",
        "        teacher_dir = Counter(all_directions).most_common(1)[0][0]\n",
        "\n",
        "    label_lines = []\n",
        "\n",
        "    for i, landmarks in enumerate(temp_landmarks):\n",
        "        x1, y1, x2, y2 = temp_boxes[i]\n",
        "        box_color = (0, 255, 0)\n",
        "        label_text = 'unknown'\n",
        "\n",
        "        if landmarks:\n",
        "            posture_class = classify_posture_binary(landmarks, teacher_dir)\n",
        "            direction = estimate_head_direction(landmarks)\n",
        "            label_text = f\"{direction}, {'Engaged' if posture_class == 0 else 'Distracted'}\"\n",
        "            box_color = (0, 255, 0) if posture_class == 0 else (0, 0, 255)\n",
        "\n",
        "            x_center = ((x1 + x2) / 2) / img_w\n",
        "            y_center = ((y1 + y2) / 2) / img_h\n",
        "            w = (x2 - x1) / img_w\n",
        "            h = (y2 - y1) / img_h\n",
        "            label_line = f\"{posture_class} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\"\n",
        "            label_lines.append(label_line)\n",
        "\n",
        "            # Get landmarks in absolute coordinates\n",
        "            def to_abs(lm):\n",
        "                return (int(x1 + lm.x * (x2 - x1)), int(y1 + lm.y * (y2 - y1)))\n",
        "\n",
        "            left_eye = to_abs(landmarks[33])\n",
        "            right_eye = to_abs(landmarks[263])\n",
        "            nose = to_abs(landmarks[1])\n",
        "            chin = to_abs(landmarks[152])\n",
        "            forehead = to_abs(landmarks[10])  # Forehead landmark\n",
        "\n",
        "            # Calculate midpoints for reference\n",
        "            eye_mid = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
        "            head_mid = ((nose[0] + chin[0]) // 2, (nose[1] + chin[1]) // 2)\n",
        "\n",
        "            vx = head_mid[0] - eye_mid[0]\n",
        "            vy = head_mid[1] - eye_mid[1]\n",
        "\n",
        "            poi_dist = 150\n",
        "            norm = (vx ** 2 + vy ** 2) ** 0.5\n",
        "            if norm == 0:\n",
        "                norm = 1\n",
        "            vx_norm = vx / norm\n",
        "            vy_norm = vy / norm\n",
        "\n",
        "            poi_x = int(eye_mid[0] + vx_norm * poi_dist)\n",
        "            poi_y = int(eye_mid[1] + vy_norm * poi_dist)\n",
        "\n",
        "            # Draw bounding box and label\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), box_color, 2)\n",
        "            cv2.putText(image, label_text, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "            # Draw gaze lines from left_eye, right_eye, nose, chin, forehead to POI\n",
        "            for pt in [left_eye, right_eye, nose, chin, forehead]:\n",
        "                cv2.line(image, pt, (poi_x, poi_y), (0, 0, 255), 2)\n",
        "                cv2.circle(image, pt, 4, (0, 255, 255), -1)  # mark landmarks in yellow\n",
        "\n",
        "            # Draw POI\n",
        "            cv2.circle(image, (poi_x, poi_y), 6, (0, 0, 255), -1)\n",
        "\n",
        "        else:\n",
        "            label_text = \"No face\"\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (128, 128, 128), 2)\n",
        "            cv2.putText(image, label_text, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "    # Save labels\n",
        "    label_file = os.path.join(label_folder, file.rsplit('.', 1)[0] + '.txt')\n",
        "    with open(label_file, 'w') as f:\n",
        "        for line in label_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    # Save visualized image\n",
        "    out_path = os.path.join(visualized_folder, file)\n",
        "    cv2.imwrite(out_path, image)\n",
        "\n",
        "    print(f\"{file}: {len(label_lines)} labels saved (Teacher direction: {teacher_dir})\")\n"
      ],
      "metadata": {
        "id": "4pq35YVwuQVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELING IMAGES = v4\n",
        "\n",
        "FaceMesh 2"
      ],
      "metadata": {
        "id": "OxAb6eXX71D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "# --- Paths ---\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "output_folder = '/content/drive/MyDrive/Saif/vvsual'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# --- Load YOLOv8 face detector ---\n",
        "model = YOLO('/content/drive/MyDrive/Saif/yolov8l-face-lindevs.pt')  # Make sure this path is correct!\n",
        "\n",
        "# --- Setup MediaPipe Face Mesh ---\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True,\n",
        "                                  max_num_faces=10,\n",
        "                                  refine_landmarks=True,\n",
        "                                  min_detection_confidence=0.5)\n",
        "\n",
        "# --- Helper function: convert normalized landmarks to image coords ---\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "# --- Process images ---\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "\n",
        "    # --- Detect faces ---\n",
        "    results = model(image)[0]\n",
        "    boxes = results.boxes.xyxy.cpu().numpy()  # (x1, y1, x2, y2)\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        # Add margin around face crop for better landmark detection\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "\n",
        "        # Convert BGR to RGB for MediaPipe\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # --- MediaPipe Face Mesh detection ---\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            continue\n",
        "        landmarks = mp_results.multi_face_landmarks[0]\n",
        "\n",
        "        # --- Map key landmarks ---\n",
        "        # Nose tip: 1\n",
        "        # Chin: 152\n",
        "        # Left eye left corner: 33\n",
        "        # Right eye right corner: 263\n",
        "        # Left forehead (approx): 10\n",
        "        # Mouth left corner: 61\n",
        "        # Mouth right corner: 291\n",
        "\n",
        "        points_ids = {\n",
        "            'nose_tip': 1,\n",
        "            'chin': 152,\n",
        "            'left_eye_outer': 33,\n",
        "            'right_eye_outer': 263,\n",
        "            'left_forehead': 10,\n",
        "            'mouth_left': 61,\n",
        "            'mouth_right': 291\n",
        "        }\n",
        "\n",
        "        pts = {}\n",
        "        for name, idx in points_ids.items():\n",
        "            pt = landmark_to_point(landmarks.landmark[idx], face_crop.shape)\n",
        "            pts[name] = (pt[0] + x1m, pt[1] + y1m)  # Map back to original image coords\n",
        "\n",
        "        # --- Draw face bounding box ---\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "        # --- Draw gaze lines ---\n",
        "        # For simplicity, draw lines from nose tip to forehead, chin, and eyes\n",
        "\n",
        "        # Nose tip point\n",
        "        p_nose = pts['nose_tip']\n",
        "\n",
        "        # Forehead\n",
        "        p_forehead = pts['left_forehead']\n",
        "        cv2.line(image, p_nose, p_forehead, (255, 0, 0), 2)\n",
        "\n",
        "        # Chin\n",
        "        p_chin = pts['chin']\n",
        "        cv2.line(image, p_nose, p_chin, (0, 255, 255), 2)\n",
        "\n",
        "        # Left eye\n",
        "        p_left_eye = pts['left_eye_outer']\n",
        "        cv2.line(image, p_nose, p_left_eye, (0, 0, 255), 2)\n",
        "\n",
        "        # Right eye\n",
        "        p_right_eye = pts['right_eye_outer']\n",
        "        cv2.line(image, p_nose, p_right_eye, (0, 0, 255), 2)\n",
        "\n",
        "        # Draw points for visibility\n",
        "        for p in pts.values():\n",
        "            cv2.circle(image, p, 3, (0,0,255), -1)\n",
        "\n",
        "    # --- Save result ---\n",
        "    cv2.imwrite(os.path.join(output_folder, filename), image)\n",
        "\n",
        "print(\"Done processing all images.\")\n"
      ],
      "metadata": {
        "id": "H_7esAh374OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELING IMAGES = v5"
      ],
      "metadata": {
        "id": "_DLZYhVnfErD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics mediapipe opencv-python"
      ],
      "metadata": {
        "id": "Yc83NS8DXh1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "# --- Paths ---\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "output_folder = '/content/drive/MyDrive/Saif/visuuualll'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# --- Load YOLOv8 face detector ---\n",
        "model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt')\n",
        "\n",
        "# --- Setup MediaPipe Face Mesh ---\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=10,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "# --- Helper: Convert landmark to image point ---\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "# --- Process each image ---\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    results = model(image)[0]\n",
        "    boxes = results.boxes.xyxy.cpu().numpy()\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                # Define landmark indices\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1,\n",
        "                    'chin': 152,\n",
        "                    'left_eye_outer': 33,\n",
        "                    'right_eye_outer': 263,\n",
        "                    'left_forehead': 10,\n",
        "                    'mouth_left': 61,\n",
        "                    'mouth_right': 291\n",
        "                }\n",
        "\n",
        "                # Get landmark coordinates\n",
        "                pts = {}\n",
        "                for name, idx in points_ids.items():\n",
        "                    pt = landmark_to_point(landmarks.landmark[idx], face_crop.shape)\n",
        "                    pts[name] = (pt[0] + x1m, pt[1] + y1m)\n",
        "\n",
        "                # Compute average direction to nose\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                if norm < 1e-6:\n",
        "                    continue\n",
        "                avg_dir /= norm\n",
        "\n",
        "                # Extended nose point\n",
        "                nose_extended = (p_nose + avg_dir * 190).astype(int) #############################################################################\n",
        "\n",
        "                # Define unique line colors per landmark\n",
        "                line_colors = {\n",
        "                    'left_forehead': (0, 255, 255),     # Yellow\n",
        "                    'chin': (255, 0, 0),              # Blue\n",
        "                    'left_eye_outer': (0, 0, 255),    # Red\n",
        "                    'right_eye_outer': (255, 255, 0), # Cyan\n",
        "                    'mouth_left': (255, 0, 255),      # Magenta\n",
        "                    'mouth_right': (0, 165, 255)      # Orange\n",
        "                }\n",
        "\n",
        "\n",
        "                # Draw colored gaze lines\n",
        "                for key, color in line_colors.items():\n",
        "                    cv2.line(image, pts[key], tuple(nose_extended), color, 2)\n",
        "\n",
        "                # Draw landmark points (without names)\n",
        "                for pt in pts.values():\n",
        "                    cv2.circle(image, pt, 3, (0, 0, 255), -1)\n",
        "\n",
        "                # Highlight extended nose point\n",
        "                cv2.circle(image, tuple(nose_extended), 4, (0, 0, 255), -1)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error processing landmarks in {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Save processed image\n",
        "    output_path = os.path.join(output_folder, filename)\n",
        "    cv2.imwrite(output_path, image)\n",
        "\n",
        "print(\"‚úÖ Done. Keypoint labels removed and multicolor gaze lines applied.\")\n"
      ],
      "metadata": {
        "id": "_ZXqmk__Vv4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELING IMAGES = v6"
      ],
      "metadata": {
        "id": "9aIlEGZ305qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "output_folder = '/content/drive/MyDrive/Saif/yyy'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "face_model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt', verbose=False)\n",
        "body_model = YOLO('yolov8n-pose.pt', verbose=False)\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=30,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    if v1 is None or v2 is None:\n",
        "        return 0.0\n",
        "    dot = np.dot(v1, v2)\n",
        "    norm_prod = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "    return dot / norm_prod if norm_prod > 1e-6 else 0.0\n",
        "\n",
        "MIN_FACE_HEIGHT_FOR_DETAILED = 70\n",
        "MIN_FACE_WIDTH_FOR_DETAILED = 50\n",
        "SLEEPY_EYE_RATIO_THRESH = 0.01\n",
        "TALKING_MOUTH_RATIO_THRESH = 2.8\n",
        "GAZE_SIMILARITY_THRESH = 0.4\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    body_results = body_model(image)[0]\n",
        "    person_boxes = [b for b in body_results.boxes.data.cpu().numpy() if int(b[5]) == 0]\n",
        "\n",
        "    face_results = face_model(image)[0]\n",
        "    boxes = face_results.boxes.xyxy.cpu().numpy().astype(int)\n",
        "    face_data = []\n",
        "\n",
        "    for (x1, y1, x2, y2) in boxes:\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "        face_w, face_h = x2 - x1, y2 - y1\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1, 'chin': 152,\n",
        "                    'left_eye_outer': 33, 'right_eye_outer': 263,\n",
        "                    'left_forehead': 10, 'mouth_left': 61,\n",
        "                    'mouth_right': 291, 'left_eye_top': 159,\n",
        "                    'left_eye_bottom': 145, 'right_eye_top': 386,\n",
        "                    'right_eye_bottom': 374\n",
        "                }\n",
        "\n",
        "                pts = {\n",
        "                    name: (landmark_to_point(landmarks.landmark[idx], face_crop.shape)[0] + x1m,\n",
        "                           landmark_to_point(landmarks.landmark[idx], face_crop.shape)[1] + y1m)\n",
        "                    for name, idx in points_ids.items()\n",
        "                }\n",
        "\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in\n",
        "                                     ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                gaze_vec = avg_dir / norm if norm > 1e-6 else None\n",
        "                nose_extended = (p_nose + gaze_vec * 190).astype(int) if gaze_vec is not None else p_nose\n",
        "\n",
        "                for key, color in {\n",
        "                    'left_forehead': (0, 255, 255),\n",
        "                    'chin': (255, 0, 0),\n",
        "                    'left_eye_outer': (0, 0, 255),\n",
        "                    'right_eye_outer': (255, 255, 0),\n",
        "                    'mouth_left': (255, 0, 255),\n",
        "                    'mouth_right': (0, 165, 255)\n",
        "                }.items():\n",
        "                    if gaze_vec is not None:\n",
        "                        cv2.line(image, pts[key], tuple(nose_extended), color, 2)\n",
        "\n",
        "                def eye_ratio_calc():\n",
        "                    left_eye_h = np.linalg.norm(np.array(pts['left_eye_top']) - np.array(pts['left_eye_bottom']))\n",
        "                    left_eye_w = np.linalg.norm(np.array(pts['left_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    right_eye_h = np.linalg.norm(np.array(pts['right_eye_top']) - np.array(pts['right_eye_bottom']))\n",
        "                    right_eye_w = np.linalg.norm(np.array(pts['right_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    left_ratio = left_eye_h / left_eye_w if left_eye_w > 1e-6 else 0\n",
        "                    right_ratio = right_eye_h / right_eye_w if right_eye_w > 1e-6 else 0\n",
        "                    return (left_ratio + right_ratio) / 2\n",
        "\n",
        "                eye_ratio = eye_ratio_calc()\n",
        "                mouth_w = np.linalg.norm(np.array(pts['mouth_right']) - np.array(pts['mouth_left']))\n",
        "                mouth_h = np.linalg.norm(np.array(pts['chin']) - np.array(pts['nose_tip']))\n",
        "                mouth_ratio = mouth_h / mouth_w if mouth_w > 1e-6 else 0\n",
        "\n",
        "                face_data.append({\n",
        "                    'center': face_center, 'label': 'Unknown', 'gaze_vector': gaze_vec,\n",
        "                    'engagement_percent': None,\n",
        "                    'eye_ratio': eye_ratio, 'mouth_ratio': mouth_ratio,\n",
        "                    'face_w': face_w, 'face_h': face_h\n",
        "                })\n",
        "\n",
        "            except:\n",
        "                face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "                continue\n",
        "\n",
        "    valid_gaze_vectors = [f['gaze_vector'] for f in face_data if f['gaze_vector'] is not None]\n",
        "    if valid_gaze_vectors:\n",
        "        mean_gaze = np.mean(valid_gaze_vectors, axis=0)\n",
        "        mean_gaze /= np.linalg.norm(mean_gaze)\n",
        "\n",
        "        for f in face_data:\n",
        "            gv = f['gaze_vector']\n",
        "            if gv is not None:\n",
        "                similarity = cosine_similarity(gv, mean_gaze)\n",
        "                percent = int(similarity * 100)\n",
        "                f['engagement_percent'] = percent\n",
        "\n",
        "                if f['face_w'] < MIN_FACE_WIDTH_FOR_DETAILED or f['face_h'] < MIN_FACE_HEIGHT_FOR_DETAILED:\n",
        "                    f['label'] = 'Engaged' if similarity >= GAZE_SIMILARITY_THRESH else 'Distracted'\n",
        "                else:\n",
        "                    if f['eye_ratio'] < SLEEPY_EYE_RATIO_THRESH:\n",
        "                        f['label'] = 'Sleepy'\n",
        "                    elif f['mouth_ratio'] > TALKING_MOUTH_RATIO_THRESH:\n",
        "                        f['label'] = 'Talking'\n",
        "                    elif similarity < GAZE_SIMILARITY_THRESH:\n",
        "                        f['label'] = 'Distracted'\n",
        "                    else:\n",
        "                        f['label'] = 'Engaged'\n",
        "            else:\n",
        "                f['engagement_percent'] = None\n",
        "                f['label'] = 'Turned'\n",
        "    else:\n",
        "        for f in face_data:\n",
        "            f['engagement_percent'] = None\n",
        "            f['label'] = 'Turned'\n",
        "\n",
        "    for body in person_boxes:\n",
        "        x1, y1, x2, y2, _, _ = map(int, body[:6])\n",
        "        body_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "\n",
        "        closest_face = None\n",
        "        min_dist = float('inf')\n",
        "        for face in face_data:\n",
        "            fx, fy = face['center']\n",
        "            dist = np.linalg.norm(np.array([fx, fy]) - np.array(body_center))\n",
        "            if dist < min_dist and dist < 150:\n",
        "                min_dist = dist\n",
        "                closest_face = face\n",
        "\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (100, 200, 100), 2)\n",
        "\n",
        "        if closest_face:\n",
        "            label = closest_face['label']\n",
        "            percent = closest_face.get('engagement_percent', None)\n",
        "            text = f\"{label} {percent}%\" if percent is not None else label\n",
        "\n",
        "            if label.lower() == 'engaged':\n",
        "                color = (0, 255, 255)  # Yellow\n",
        "            elif label.lower() == 'distracted':\n",
        "                color = (0, 0, 255)    # Red\n",
        "            else:\n",
        "                color = (100, 200, 100)\n",
        "\n",
        "            cv2.putText(image, text, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "    # ‚úÖ Save labeled image for this file\n",
        "    cv2.imwrite(os.path.join(output_folder, filename), image)\n",
        "\n",
        "print(\"‚úÖ All done. Check output folder for labeled images.\")\n"
      ],
      "metadata": {
        "id": "aLjU6FZNldmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABELING IMAGES = v7"
      ],
      "metadata": {
        "id": "NGoTsejQ1CqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "\n",
        "output_folder = '/content/drive/MyDrive/Saif/percenttt'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "face_model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt')\n",
        "body_model = YOLO('yolov8n-pose.pt')  # body detection model\n",
        "\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=30,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "def unit_vector(v):\n",
        "    norm = np.linalg.norm(v)\n",
        "    if norm < 1e-6:\n",
        "        return None\n",
        "    return v / norm\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    dot = np.dot(v1, v2)\n",
        "    norm_prod = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "    if norm_prod < 1e-6:\n",
        "        return 0.0\n",
        "    return dot / norm_prod\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "\n",
        "    # Detect bodies\n",
        "    body_results = body_model(image)[0]\n",
        "    person_boxes = [b for b in body_results.boxes.data.cpu().numpy() if int(b[5]) == 0]\n",
        "\n",
        "    # Detect faces\n",
        "    face_results = face_model(image)[0]\n",
        "    boxes = face_results.boxes.xyxy.cpu().numpy().astype(int)\n",
        "\n",
        "    face_data = []\n",
        "\n",
        "    for (x1, y1, x2, y2) in boxes:\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "            # If no face landmarks detected, mark as Turned\n",
        "            face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1,\n",
        "                    'chin': 152,\n",
        "                    'left_eye_outer': 33,\n",
        "                    'right_eye_outer': 263,\n",
        "                    'left_forehead': 10,\n",
        "                    'mouth_left': 61,\n",
        "                    'mouth_right': 291\n",
        "                }\n",
        "\n",
        "                pts = {\n",
        "                    name: (landmark_to_point(landmarks.landmark[idx], face_crop.shape)[0] + x1m,\n",
        "                           landmark_to_point(landmarks.landmark[idx], face_crop.shape)[1] + y1m)\n",
        "                    for name, idx in points_ids.items()\n",
        "                }\n",
        "\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                if norm < 1e-6:\n",
        "                    # Unable to calculate gaze vector - consider engaged by default\n",
        "                    gaze_vec = None\n",
        "                else:\n",
        "                    gaze_vec = avg_dir / norm\n",
        "\n",
        "                nose_extended = (p_nose + gaze_vec * 190).astype(int) if gaze_vec is not None else p_nose\n",
        "\n",
        "                line_colors = {\n",
        "                    'left_forehead': (0, 255, 255),\n",
        "                    'chin': (255, 0, 0),\n",
        "                    'left_eye_outer': (0, 0, 255),\n",
        "                    'right_eye_outer': (255, 255, 0),\n",
        "                    'mouth_left': (255, 0, 255),\n",
        "                    'mouth_right': (0, 165, 255)\n",
        "                }\n",
        "                for key, color in line_colors.items():\n",
        "                    if gaze_vec is not None:\n",
        "                        cv2.line(image, pts[key], tuple(nose_extended), color, 2)\n",
        "                for pt in pts.values():\n",
        "                    cv2.circle(image, pt, 3, (0, 0, 255), -1)\n",
        "                if gaze_vec is not None:\n",
        "                    cv2.circle(image, tuple(nose_extended), 4, (0, 0, 255), -1)\n",
        "\n",
        "                face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "                face_data.append({'center': face_center, 'label': 'Engaged', 'gaze_vector': gaze_vec, 'engagement_percent': None})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error in {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Calculate consensus gaze vector using average of non-None gaze vectors\n",
        "    valid_gaze_vectors = [f['gaze_vector'] for f in face_data if f['gaze_vector'] is not None]\n",
        "\n",
        "    if valid_gaze_vectors:\n",
        "        # Calculate mean gaze vector\n",
        "        mean_gaze = np.mean(valid_gaze_vectors, axis=0)\n",
        "        mean_gaze /= np.linalg.norm(mean_gaze)\n",
        "\n",
        "        # Compute cosine similarity of each gaze to mean gaze\n",
        "        for f in face_data:\n",
        "            gv = f['gaze_vector']\n",
        "            if gv is not None:\n",
        "                similarity = cosine_similarity(gv, mean_gaze)\n",
        "                percent = int(similarity * 100)\n",
        "                f['engagement_percent'] = percent\n",
        "                # Threshold for engaged vs distracted\n",
        "                if similarity < 0.5:\n",
        "                    f['label'] = 'Distracted'\n",
        "                else:\n",
        "                    f['label'] = 'Engaged'\n",
        "            else:\n",
        "                f['engagement_percent'] = None\n",
        "    else:\n",
        "        # No valid gaze vectors: mark all as None\n",
        "        for f in face_data:\n",
        "            f['engagement_percent'] = None\n",
        "\n",
        "    # Draw body boxes and labels (only if label != 'Unknown')\n",
        "    for body in person_boxes:\n",
        "        x1, y1, x2, y2, _, _ = map(int, body[:6])\n",
        "        body_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "\n",
        "        closest_face = None\n",
        "        min_dist = float('inf')\n",
        "        for face in face_data:\n",
        "            fx, fy = face['center']\n",
        "            dist = np.linalg.norm(np.array([fx, fy]) - np.array(body_center))\n",
        "            if dist < min_dist and dist < 150:\n",
        "                min_dist = dist\n",
        "                closest_face = face\n",
        "\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (100, 200, 100), 2)\n",
        "\n",
        "        if closest_face is not None:\n",
        "            label = closest_face['label']\n",
        "            percent = closest_face.get('engagement_percent', None)\n",
        "            if percent is not None:\n",
        "                text = f\"{label}: {percent}%\"\n",
        "            else:\n",
        "                text = f\"{label}: .\"\n",
        "\n",
        "            if label != \"Unknown\":\n",
        "                cv2.putText(image, text, (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 200, 100), 2)\n",
        "\n",
        "    cv2.imwrite(os.path.join(output_folder, filename), image)\n",
        "\n",
        "print(\"‚úÖ Done. Improved gaze detection with cosine similarity, thresholding, and engagement percentages.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3FTLL401Gil",
        "outputId": "2374382f-2bd3-4d4e-c83c-ed6afc4cf6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 12 persons, 253.0ms\n",
            "Speed: 12.0ms preprocess, 253.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 19 faces, 512.6ms\n",
            "Speed: 5.4ms preprocess, 512.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 persons, 200.2ms\n",
            "Speed: 5.8ms preprocess, 200.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 faces, 471.1ms\n",
            "Speed: 5.4ms preprocess, 471.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 6 persons, 203.7ms\n",
            "Speed: 5.5ms preprocess, 203.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 7 faces, 478.3ms\n",
            "Speed: 5.9ms preprocess, 478.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 persons, 198.4ms\n",
            "Speed: 6.3ms preprocess, 198.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 21 faces, 500.1ms\n",
            "Speed: 4.9ms preprocess, 500.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 persons, 199.5ms\n",
            "Speed: 5.4ms preprocess, 199.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 faces, 491.4ms\n",
            "Speed: 7.1ms preprocess, 491.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 6 persons, 213.6ms\n",
            "Speed: 5.6ms preprocess, 213.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 faces, 542.6ms\n",
            "Speed: 4.8ms preprocess, 542.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 384x640 8 persons, 329.6ms\n",
            "Speed: 4.6ms preprocess, 329.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 faces, 665.0ms\n",
            "Speed: 4.8ms preprocess, 665.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 246.4ms\n",
            "Speed: 4.8ms preprocess, 246.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 faces, 635.8ms\n",
            "Speed: 4.2ms preprocess, 635.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 249.2ms\n",
            "Speed: 4.5ms preprocess, 249.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 636.7ms\n",
            "Speed: 7.5ms preprocess, 636.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 209.1ms\n",
            "Speed: 5.8ms preprocess, 209.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 393.1ms\n",
            "Speed: 4.3ms preprocess, 393.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 178.3ms\n",
            "Speed: 8.5ms preprocess, 178.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 388.2ms\n",
            "Speed: 4.4ms preprocess, 388.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 165.7ms\n",
            "Speed: 4.4ms preprocess, 165.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 489.2ms\n",
            "Speed: 4.6ms preprocess, 489.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 183.8ms\n",
            "Speed: 6.8ms preprocess, 183.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 402.7ms\n",
            "Speed: 4.6ms preprocess, 402.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 180.7ms\n",
            "Speed: 4.7ms preprocess, 180.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 414.6ms\n",
            "Speed: 4.4ms preprocess, 414.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 162.7ms\n",
            "Speed: 4.4ms preprocess, 162.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 408.4ms\n",
            "Speed: 4.4ms preprocess, 408.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 169.8ms\n",
            "Speed: 4.6ms preprocess, 169.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 422.8ms\n",
            "Speed: 4.9ms preprocess, 422.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 165.2ms\n",
            "Speed: 4.6ms preprocess, 165.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 391.8ms\n",
            "Speed: 4.1ms preprocess, 391.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 163.6ms\n",
            "Speed: 4.4ms preprocess, 163.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 394.1ms\n",
            "Speed: 4.5ms preprocess, 394.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 160.4ms\n",
            "Speed: 4.3ms preprocess, 160.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 417.1ms\n",
            "Speed: 5.6ms preprocess, 417.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 171.9ms\n",
            "Speed: 4.9ms preprocess, 171.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 394.9ms\n",
            "Speed: 5.4ms preprocess, 394.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 162.1ms\n",
            "Speed: 4.5ms preprocess, 162.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 403.9ms\n",
            "Speed: 5.5ms preprocess, 403.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 166.5ms\n",
            "Speed: 4.5ms preprocess, 166.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 570.1ms\n",
            "Speed: 4.4ms preprocess, 570.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 249.3ms\n",
            "Speed: 4.5ms preprocess, 249.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 634.5ms\n",
            "Speed: 8.3ms preprocess, 634.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 253.5ms\n",
            "Speed: 5.2ms preprocess, 253.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 614.8ms\n",
            "Speed: 4.3ms preprocess, 614.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 258.2ms\n",
            "Speed: 6.7ms preprocess, 258.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 42 faces, 627.5ms\n",
            "Speed: 4.3ms preprocess, 627.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 268.4ms\n",
            "Speed: 4.7ms preprocess, 268.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 faces, 450.9ms\n",
            "Speed: 5.4ms preprocess, 450.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 187.3ms\n",
            "Speed: 4.2ms preprocess, 187.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 402.7ms\n",
            "Speed: 4.1ms preprocess, 402.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 160.4ms\n",
            "Speed: 4.2ms preprocess, 160.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 422.2ms\n",
            "Speed: 4.4ms preprocess, 422.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 173.1ms\n",
            "Speed: 4.5ms preprocess, 173.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 392.3ms\n",
            "Speed: 4.7ms preprocess, 392.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 206.4ms\n",
            "Speed: 4.4ms preprocess, 206.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 397.2ms\n",
            "Speed: 4.7ms preprocess, 397.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 193.5ms\n",
            "Speed: 3.4ms preprocess, 193.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 395.0ms\n",
            "Speed: 4.5ms preprocess, 395.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 171.3ms\n",
            "Speed: 4.7ms preprocess, 171.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 412.7ms\n",
            "Speed: 4.4ms preprocess, 412.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 177.1ms\n",
            "Speed: 4.4ms preprocess, 177.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 415.3ms\n",
            "Speed: 5.2ms preprocess, 415.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 161.9ms\n",
            "Speed: 4.4ms preprocess, 161.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 395.4ms\n",
            "Speed: 4.3ms preprocess, 395.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 198.7ms\n",
            "Speed: 4.2ms preprocess, 198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 402.1ms\n",
            "Speed: 5.6ms preprocess, 402.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 169.9ms\n",
            "Speed: 4.3ms preprocess, 169.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 408.8ms\n",
            "Speed: 5.0ms preprocess, 408.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 176.0ms\n",
            "Speed: 4.7ms preprocess, 176.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 417.4ms\n",
            "Speed: 3.3ms preprocess, 417.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 169.9ms\n",
            "Speed: 4.6ms preprocess, 169.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 421.6ms\n",
            "Speed: 4.7ms preprocess, 421.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 278.4ms\n",
            "Speed: 5.8ms preprocess, 278.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 600.1ms\n",
            "Speed: 6.0ms preprocess, 600.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 264.6ms\n",
            "Speed: 4.4ms preprocess, 264.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 614.8ms\n",
            "Speed: 4.4ms preprocess, 614.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 258.5ms\n",
            "Speed: 4.3ms preprocess, 258.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 604.8ms\n",
            "Speed: 5.1ms preprocess, 604.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 284.4ms\n",
            "Speed: 4.5ms preprocess, 284.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 578.3ms\n",
            "Speed: 4.5ms preprocess, 578.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 168.7ms\n",
            "Speed: 4.4ms preprocess, 168.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 392.2ms\n",
            "Speed: 4.6ms preprocess, 392.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 160.7ms\n",
            "Speed: 4.7ms preprocess, 160.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 390.7ms\n",
            "Speed: 4.7ms preprocess, 390.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 163.2ms\n",
            "Speed: 4.6ms preprocess, 163.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 402.4ms\n",
            "Speed: 5.1ms preprocess, 402.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 162.9ms\n",
            "Speed: 4.3ms preprocess, 162.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 413.5ms\n",
            "Speed: 4.4ms preprocess, 413.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 163.7ms\n",
            "Speed: 4.6ms preprocess, 163.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 389.8ms\n",
            "Speed: 5.1ms preprocess, 389.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 165.2ms\n",
            "Speed: 5.3ms preprocess, 165.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 387.9ms\n",
            "Speed: 4.4ms preprocess, 387.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 166.4ms\n",
            "Speed: 4.4ms preprocess, 166.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 406.8ms\n",
            "Speed: 4.3ms preprocess, 406.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 165.8ms\n",
            "Speed: 4.7ms preprocess, 165.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 419.5ms\n",
            "Speed: 5.0ms preprocess, 419.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 164.9ms\n",
            "Speed: 4.6ms preprocess, 164.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 402.6ms\n",
            "Speed: 4.8ms preprocess, 402.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 176.5ms\n",
            "Speed: 4.3ms preprocess, 176.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 391.8ms\n",
            "Speed: 7.1ms preprocess, 391.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 160.1ms\n",
            "Speed: 4.3ms preprocess, 160.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 413.6ms\n",
            "Speed: 3.9ms preprocess, 413.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 165.4ms\n",
            "Speed: 4.4ms preprocess, 165.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 401.2ms\n",
            "Speed: 4.7ms preprocess, 401.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 178.5ms\n",
            "Speed: 4.9ms preprocess, 178.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 493.6ms\n",
            "Speed: 4.8ms preprocess, 493.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 255.0ms\n",
            "Speed: 4.4ms preprocess, 255.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 616.5ms\n",
            "Speed: 4.6ms preprocess, 616.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 262.1ms\n",
            "Speed: 4.4ms preprocess, 262.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 621.2ms\n",
            "Speed: 4.5ms preprocess, 621.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 248.3ms\n",
            "Speed: 4.4ms preprocess, 248.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 622.0ms\n",
            "Speed: 6.8ms preprocess, 622.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 260.2ms\n",
            "Speed: 5.9ms preprocess, 260.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 465.6ms\n",
            "Speed: 4.7ms preprocess, 465.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 164.3ms\n",
            "Speed: 4.6ms preprocess, 164.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 406.2ms\n",
            "Speed: 4.6ms preprocess, 406.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 203.9ms\n",
            "Speed: 5.8ms preprocess, 203.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 433.4ms\n",
            "Speed: 5.5ms preprocess, 433.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 164.2ms\n",
            "Speed: 5.7ms preprocess, 164.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 424.2ms\n",
            "Speed: 4.9ms preprocess, 424.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 175.3ms\n",
            "Speed: 6.1ms preprocess, 175.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 408.7ms\n",
            "Speed: 5.4ms preprocess, 408.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 190.4ms\n",
            "Speed: 5.0ms preprocess, 190.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 425.7ms\n",
            "Speed: 5.0ms preprocess, 425.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 172.5ms\n",
            "Speed: 5.2ms preprocess, 172.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 429.0ms\n",
            "Speed: 5.4ms preprocess, 429.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 178.0ms\n",
            "Speed: 5.1ms preprocess, 178.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 445.5ms\n",
            "Speed: 4.6ms preprocess, 445.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 280.4ms\n",
            "Speed: 4.6ms preprocess, 280.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 faces, 627.8ms\n",
            "Speed: 7.5ms preprocess, 627.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 276.9ms\n",
            "Speed: 5.4ms preprocess, 276.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 632.5ms\n",
            "Speed: 4.3ms preprocess, 632.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 276.4ms\n",
            "Speed: 5.0ms preprocess, 276.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 488.9ms\n",
            "Speed: 4.4ms preprocess, 488.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 169.4ms\n",
            "Speed: 4.8ms preprocess, 169.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 471.9ms\n",
            "Speed: 5.4ms preprocess, 471.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 177.1ms\n",
            "Speed: 5.1ms preprocess, 177.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 422.6ms\n",
            "Speed: 4.5ms preprocess, 422.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 166.6ms\n",
            "Speed: 5.6ms preprocess, 166.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 425.2ms\n",
            "Speed: 4.9ms preprocess, 425.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 175.8ms\n",
            "Speed: 4.5ms preprocess, 175.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 392.3ms\n",
            "Speed: 3.9ms preprocess, 392.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "‚úÖ Done. Improved gaze detection with cosine similarity, thresholding, and engagement percentages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This version with 5 class to label dataset 23 july morning.....\n",
        "LABELING IMAGES = v8"
      ],
      "metadata": {
        "id": "85OUfgL6jnuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Dataset/images/val'\n",
        "output_folder = '/content/drive/MyDrive/Dataset/labels/val'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "face_model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt', verbose=False)\n",
        "body_model = YOLO('yolov8n-pose.pt', verbose=False)\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=30,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    if v1 is None or v2 is None:\n",
        "        return 0.0\n",
        "    dot = np.dot(v1, v2)\n",
        "    norm_prod = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "    return dot / norm_prod if norm_prod > 1e-6 else 0.0\n",
        "\n",
        "MIN_FACE_HEIGHT_FOR_DETAILED = 70\n",
        "MIN_FACE_WIDTH_FOR_DETAILED = 50\n",
        "SLEEPY_EYE_RATIO_THRESH = 0.01\n",
        "TALKING_MOUTH_RATIO_THRESH = 2.8\n",
        "GAZE_SIMILARITY_THRESH = 0.4\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    body_results = body_model(image)[0]\n",
        "    person_boxes = [b for b in body_results.boxes.data.cpu().numpy() if int(b[5]) == 0]\n",
        "\n",
        "    face_results = face_model(image)[0]\n",
        "    boxes = face_results.boxes.xyxy.cpu().numpy().astype(int)\n",
        "    face_data = []\n",
        "\n",
        "    for (x1, y1, x2, y2) in boxes:\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "        face_w, face_h = x2 - x1, y2 - y1\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1, 'chin': 152,\n",
        "                    'left_eye_outer': 33, 'right_eye_outer': 263,\n",
        "                    'left_forehead': 10, 'mouth_left': 61,\n",
        "                    'mouth_right': 291, 'left_eye_top': 159,\n",
        "                    'left_eye_bottom': 145, 'right_eye_top': 386,\n",
        "                    'right_eye_bottom': 374\n",
        "                }\n",
        "\n",
        "                pts = {\n",
        "                    name: (landmark_to_point(landmarks.landmark[idx], face_crop.shape)[0] + x1m,\n",
        "                           landmark_to_point(landmarks.landmark[idx], face_crop.shape)[1] + y1m)\n",
        "                    for name, idx in points_ids.items()\n",
        "                }\n",
        "\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in\n",
        "                                     ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                gaze_vec = avg_dir / norm if norm > 1e-6 else None\n",
        "\n",
        "                def eye_ratio_calc():\n",
        "                    left_eye_h = np.linalg.norm(np.array(pts['left_eye_top']) - np.array(pts['left_eye_bottom']))\n",
        "                    left_eye_w = np.linalg.norm(np.array(pts['left_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    right_eye_h = np.linalg.norm(np.array(pts['right_eye_top']) - np.array(pts['right_eye_bottom']))\n",
        "                    right_eye_w = np.linalg.norm(np.array(pts['right_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    left_ratio = left_eye_h / left_eye_w if left_eye_w > 1e-6 else 0\n",
        "                    right_ratio = right_eye_h / right_eye_w if right_eye_w > 1e-6 else 0\n",
        "                    return (left_ratio + right_ratio) / 2\n",
        "\n",
        "                eye_ratio = eye_ratio_calc()\n",
        "                mouth_w = np.linalg.norm(np.array(pts['mouth_right']) - np.array(pts['mouth_left']))\n",
        "                mouth_h = np.linalg.norm(np.array(pts['chin']) - np.array(pts['nose_tip']))\n",
        "                mouth_ratio = mouth_h / mouth_w if mouth_w > 1e-6 else 0\n",
        "\n",
        "                face_data.append({\n",
        "                    'center': face_center, 'label': 'Unknown', 'gaze_vector': gaze_vec,\n",
        "                    'engagement_percent': None,\n",
        "                    'eye_ratio': eye_ratio, 'mouth_ratio': mouth_ratio,\n",
        "                    'face_w': face_w, 'face_h': face_h\n",
        "                })\n",
        "\n",
        "            except:\n",
        "                face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "                continue\n",
        "\n",
        "    valid_gaze_vectors = [f['gaze_vector'] for f in face_data if f['gaze_vector'] is not None]\n",
        "    if valid_gaze_vectors:\n",
        "        mean_gaze = np.mean(valid_gaze_vectors, axis=0)\n",
        "        mean_gaze /= np.linalg.norm(mean_gaze)\n",
        "\n",
        "        for f in face_data:\n",
        "            gv = f['gaze_vector']\n",
        "            if gv is not None:\n",
        "                similarity = cosine_similarity(gv, mean_gaze)\n",
        "                percent = int(similarity * 100)\n",
        "                f['engagement_percent'] = percent\n",
        "\n",
        "                if f['face_w'] < MIN_FACE_WIDTH_FOR_DETAILED or f['face_h'] < MIN_FACE_HEIGHT_FOR_DETAILED:\n",
        "                    f['label'] = 'Engaged' if similarity >= GAZE_SIMILARITY_THRESH else 'Distracted'\n",
        "                else:\n",
        "                    if f['eye_ratio'] < SLEEPY_EYE_RATIO_THRESH:\n",
        "                        f['label'] = 'Sleepy'\n",
        "                    elif f['mouth_ratio'] > TALKING_MOUTH_RATIO_THRESH:\n",
        "                        f['label'] = 'Talking'\n",
        "                    elif similarity < GAZE_SIMILARITY_THRESH:\n",
        "                        f['label'] = 'Distracted'\n",
        "                    else:\n",
        "                        f['label'] = 'Engaged'\n",
        "            else:\n",
        "                f['engagement_percent'] = None\n",
        "                f['label'] = 'Turned'\n",
        "    else:\n",
        "        for f in face_data:\n",
        "            f['engagement_percent'] = None\n",
        "            f['label'] = 'Turned'\n",
        "\n",
        "    # Save YOLO label file\n",
        "    txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    txt_path = os.path.join(output_folder, txt_filename)\n",
        "    with open(txt_path, 'w') as f:\n",
        "        for body in person_boxes:\n",
        "            x1, y1, x2, y2, _, _ = map(int, body[:6])\n",
        "            body_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "\n",
        "            closest_face = None\n",
        "            min_dist = float('inf')\n",
        "            for face in face_data:\n",
        "                fx, fy = face['center']\n",
        "                dist = np.linalg.norm(np.array([fx, fy]) - np.array(body_center))\n",
        "                if dist < min_dist and dist < 150:\n",
        "                    min_dist = dist\n",
        "                    closest_face = face\n",
        "\n",
        "            if closest_face:\n",
        "                label = closest_face['label']\n",
        "                class_id = {'Engaged': 0, 'Distracted': 1, 'Talking': 2, 'Sleepy': 3, 'Turned': 4}.get(label, 4)\n",
        "\n",
        "                xc = (x1 + x2) / 2 / orig_w\n",
        "                yc = (y1 + y2) / 2 / orig_h\n",
        "                w = (x2 - x1) / orig_w\n",
        "                h = (y2 - y1) / orig_h\n",
        "\n",
        "                f.write(f\"{class_id} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "print(\"‚úÖ Label .txt files saved for all images in output folder.\")\n"
      ],
      "metadata": {
        "id": "4mG7G444jwht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL TRAINING.."
      ],
      "metadata": {
        "id": "fozrqe6WuDJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/ultralytics/ultralytics.git@main\n",
        "\n"
      ],
      "metadata": {
        "id": "Hb9uH-V_uFUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "# Load a base model\n",
        "model = YOLO('yolo11m.pt')\n",
        "\n",
        "# Train the model and save outputs directly to Drive\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/Dataset/data.yml',\n",
        "    epochs=30,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    project='/content/drive/MyDrive/yolo_runs',  # <--- saves results in Drive\n",
        "    name='Exp1'  # optional: custom experiment name\n",
        ")\n"
      ],
      "metadata": {
        "id": "dYFJezZXwoAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the trained model\n",
        "model = YOLO('/content/drive/MyDrive/yolo_runs/Exp1/weights/best.pt')  # Update path if needed\n",
        "\n",
        "# Run inference on an image or folder\n",
        "#results = model('/content/drive/MyDrive/Saif/test/1590.jpg', save=True)  # Single image\n",
        "\n",
        "# Or on a folder\n",
        "results = model('/content/drive/MyDrive/Saif/test', save=True)\n"
      ],
      "metadata": {
        "id": "V8rqR3QMKPq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the folder (e.g., runs/detect/train)\n",
        "shutil.make_archive('detect_resu', 'zip', '/content/runs/detect/predict2')  # Change the path if needed\n",
        "\n",
        "# Download the zipped folder\n",
        "files.download('detect_resu.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "V9iNNH0pNxYy",
        "outputId": "2b353fe1-f6eb-461f-8725-692f632b7d46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c154582-44c3-45db-8977-a991be38ca71\", \"detect_resu.zip\", 83185580)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OrbH9RGha4b9oUQ8DypRU1QEsPCuTaK-",
      "authorship_tag": "ABX9TyPpH3pQwLzCKQMjpf10CFzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}