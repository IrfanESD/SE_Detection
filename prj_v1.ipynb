{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IrfanESD/SE_Detection/blob/main/prj_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Rq2E5-DB1T"
      },
      "outputs": [],
      "source": [
        " !pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm7djEzwFP8i"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# === ğŸ”§ Input: Set video path ===\n",
        "video_path = '/content/drive/MyDrive/Clips/C0016.MP4'\n",
        "output_folder = '/content/drive/MyDrive/clear_student_frames/MainSet14'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# === ğŸ§® Parameters ===\n",
        "sharpness_threshold = 100.0  # Higher = only clearer frames\n",
        "sampling_interval = 30      # Sample every 30 frames\n",
        "\n",
        "# === ğŸ¬ Read and Process the Video ===\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"âŒ Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Get and print video FPS (optional, for info)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(f\"ğŸ¥ Video FPS: {fps}\")\n",
        "\n",
        "frame_count = 0\n",
        "saved_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    # Only sample every 120 frames\n",
        "    if frame_count % sampling_interval != 0:\n",
        "        continue\n",
        "\n",
        "    # Convert frame to grayscale for sharpness detection\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "    # Save only sharp frames\n",
        "    if sharpness > sharpness_threshold:\n",
        "        filename = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "        cv2.imwrite(filename, frame)\n",
        "        saved_count += 1\n",
        "        print(f\"âœ… Saved frame {frame_count} | Sharpness: {sharpness:.2f}\")\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(f\"\\nâœ… Done: {saved_count} sharp frames saved to âœ '{output_folder}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace this with your actual folder path in Drive\n",
        "folder_path = '/content/drive/MyDrive/clear_student_frames/MainSet'\n",
        "\n",
        "# Get list of image files\n",
        "image_files = sorted([\n",
        "    f for f in os.listdir(folder_path)\n",
        "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "])\n",
        "\n",
        "# Rename images as a1.jpg, a2.jpg, ...\n",
        "for idx, filename in enumerate(image_files, start=1):\n",
        "    ext = os.path.splitext(filename)[1]  # Keeps original file extension\n",
        "    new_name = f'img{idx}{ext}'\n",
        "\n",
        "    old_path = os.path.join(folder_path, filename)\n",
        "    new_path = os.path.join(folder_path, new_name)\n",
        "\n",
        "    os.rename(old_path, new_path)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"âœ… Renamed {len(image_files)} images to ..., img{idx}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srav1U58_8B2",
        "outputId": "2655c1b1-b17b-4b16-bf79-077bf1e7ae17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Renamed 348 images to ..., img348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Set path to the parent folder containing 10 folders\n",
        "parent_dir = '/content/drive/MyDrive/clear_student_frames'  # â¬…ï¸ Change this\n",
        "\n",
        "# Step 3: Get list of all image paths from all subfolders\n",
        "image_extensions = ('*.jpg', '*.jpeg', '*.png')  # Extend if needed\n",
        "all_images = []\n",
        "\n",
        "for ext in image_extensions:\n",
        "    all_images.extend(glob.glob(os.path.join(parent_dir, '*', ext)))\n",
        "\n",
        "# Optional: Sort for consistent ordering\n",
        "all_images.sort()\n",
        "\n",
        "# Step 4: Rename all images serially and print progress\n",
        "start_serial = 1  # â¬…ï¸ Change this if you want to start from a different number\n",
        "renamed_count = 0\n",
        "\n",
        "for idx, img_path in enumerate(all_images, start_serial):\n",
        "    folder = os.path.dirname(img_path)\n",
        "    ext = os.path.splitext(img_path)[1]\n",
        "    new_name = f\"{idx}{ext}\"\n",
        "    new_path = os.path.join(folder, new_name)\n",
        "\n",
        "    try:\n",
        "        os.rename(img_path, new_path)\n",
        "        folder_name = os.path.basename(folder)\n",
        "        print(f\"{idx}: Renamed in '{folder_name}' â†’ {new_name}\")\n",
        "        renamed_count += 1\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error renaming '{img_path}': {e}\")\n",
        "\n",
        "# Step 5: Output total renamed images\n",
        "print(f\"\\nâœ… Total images renamed: {renamed_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCO3kYpWzdxP",
        "outputId": "0385a0fa-97e0-4458-b4eb-4eae067d1da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "1: Renamed in 'MainSet1' â†’ 1.jpg\n",
            "2: Renamed in 'MainSet1' â†’ 2.jpg\n",
            "3: Renamed in 'MainSet1' â†’ 3.jpg\n",
            "4: Renamed in 'MainSet1' â†’ 4.jpg\n",
            "5: Renamed in 'MainSet1' â†’ 5.jpg\n",
            "6: Renamed in 'MainSet1' â†’ 6.jpg\n",
            "7: Renamed in 'MainSet1' â†’ 7.jpg\n",
            "8: Renamed in 'MainSet1' â†’ 8.jpg\n",
            "9: Renamed in 'MainSet1' â†’ 9.jpg\n",
            "10: Renamed in 'MainSet1' â†’ 10.jpg\n",
            "11: Renamed in 'MainSet1' â†’ 11.jpg\n",
            "12: Renamed in 'MainSet1' â†’ 12.jpg\n",
            "13: Renamed in 'MainSet1' â†’ 13.jpg\n",
            "14: Renamed in 'MainSet1' â†’ 14.jpg\n",
            "15: Renamed in 'MainSet1' â†’ 15.jpg\n",
            "16: Renamed in 'MainSet1' â†’ 16.jpg\n",
            "17: Renamed in 'MainSet1' â†’ 17.jpg\n",
            "18: Renamed in 'MainSet1' â†’ 18.jpg\n",
            "19: Renamed in 'MainSet1' â†’ 19.jpg\n",
            "20: Renamed in 'MainSet1' â†’ 20.jpg\n",
            "21: Renamed in 'MainSet1' â†’ 21.jpg\n",
            "22: Renamed in 'MainSet1' â†’ 22.jpg\n",
            "23: Renamed in 'MainSet1' â†’ 23.jpg\n",
            "24: Renamed in 'MainSet1' â†’ 24.jpg\n",
            "25: Renamed in 'MainSet1' â†’ 25.jpg\n",
            "26: Renamed in 'MainSet1' â†’ 26.jpg\n",
            "27: Renamed in 'MainSet1' â†’ 27.jpg\n",
            "28: Renamed in 'MainSet1' â†’ 28.jpg\n",
            "29: Renamed in 'MainSet1' â†’ 29.jpg\n",
            "30: Renamed in 'MainSet1' â†’ 30.jpg\n",
            "31: Renamed in 'MainSet1' â†’ 31.jpg\n",
            "32: Renamed in 'MainSet1' â†’ 32.jpg\n",
            "33: Renamed in 'MainSet1' â†’ 33.jpg\n",
            "34: Renamed in 'MainSet1' â†’ 34.jpg\n",
            "35: Renamed in 'MainSet1' â†’ 35.jpg\n",
            "36: Renamed in 'MainSet1' â†’ 36.jpg\n",
            "37: Renamed in 'MainSet1' â†’ 37.jpg\n",
            "38: Renamed in 'MainSet1' â†’ 38.jpg\n",
            "39: Renamed in 'MainSet1' â†’ 39.jpg\n",
            "40: Renamed in 'MainSet1' â†’ 40.jpg\n",
            "41: Renamed in 'MainSet1' â†’ 41.jpg\n",
            "42: Renamed in 'MainSet1' â†’ 42.jpg\n",
            "43: Renamed in 'MainSet1' â†’ 43.jpg\n",
            "44: Renamed in 'MainSet1' â†’ 44.jpg\n",
            "45: Renamed in 'MainSet1' â†’ 45.jpg\n",
            "46: Renamed in 'MainSet1' â†’ 46.jpg\n",
            "47: Renamed in 'MainSet1' â†’ 47.jpg\n",
            "48: Renamed in 'MainSet1' â†’ 48.jpg\n",
            "49: Renamed in 'MainSet1' â†’ 49.jpg\n",
            "50: Renamed in 'MainSet1' â†’ 50.jpg\n",
            "51: Renamed in 'MainSet1' â†’ 51.jpg\n",
            "52: Renamed in 'MainSet1' â†’ 52.jpg\n",
            "53: Renamed in 'MainSet1' â†’ 53.jpg\n",
            "54: Renamed in 'MainSet1' â†’ 54.jpg\n",
            "55: Renamed in 'MainSet1' â†’ 55.jpg\n",
            "56: Renamed in 'MainSet1' â†’ 56.jpg\n",
            "57: Renamed in 'MainSet1' â†’ 57.jpg\n",
            "58: Renamed in 'MainSet1' â†’ 58.jpg\n",
            "59: Renamed in 'MainSet1' â†’ 59.jpg\n",
            "60: Renamed in 'MainSet1' â†’ 60.jpg\n",
            "61: Renamed in 'MainSet1' â†’ 61.jpg\n",
            "62: Renamed in 'MainSet1' â†’ 62.jpg\n",
            "63: Renamed in 'MainSet1' â†’ 63.jpg\n",
            "64: Renamed in 'MainSet1' â†’ 64.jpg\n",
            "65: Renamed in 'MainSet1' â†’ 65.jpg\n",
            "66: Renamed in 'MainSet1' â†’ 66.jpg\n",
            "67: Renamed in 'MainSet1' â†’ 67.jpg\n",
            "68: Renamed in 'MainSet1' â†’ 68.jpg\n",
            "69: Renamed in 'MainSet1' â†’ 69.jpg\n",
            "70: Renamed in 'MainSet1' â†’ 70.jpg\n",
            "71: Renamed in 'MainSet1' â†’ 71.jpg\n",
            "72: Renamed in 'MainSet1' â†’ 72.jpg\n",
            "73: Renamed in 'MainSet1' â†’ 73.jpg\n",
            "74: Renamed in 'MainSet1' â†’ 74.jpg\n",
            "75: Renamed in 'MainSet1' â†’ 75.jpg\n",
            "76: Renamed in 'MainSet1' â†’ 76.jpg\n",
            "77: Renamed in 'MainSet1' â†’ 77.jpg\n",
            "78: Renamed in 'MainSet1' â†’ 78.jpg\n",
            "79: Renamed in 'MainSet1' â†’ 79.jpg\n",
            "80: Renamed in 'MainSet1' â†’ 80.jpg\n",
            "81: Renamed in 'MainSet1' â†’ 81.jpg\n",
            "82: Renamed in 'MainSet1' â†’ 82.jpg\n",
            "83: Renamed in 'MainSet1' â†’ 83.jpg\n",
            "84: Renamed in 'MainSet1' â†’ 84.jpg\n",
            "85: Renamed in 'MainSet1' â†’ 85.jpg\n",
            "86: Renamed in 'MainSet1' â†’ 86.jpg\n",
            "87: Renamed in 'MainSet1' â†’ 87.jpg\n",
            "88: Renamed in 'MainSet1' â†’ 88.jpg\n",
            "89: Renamed in 'MainSet1' â†’ 89.jpg\n",
            "90: Renamed in 'MainSet1' â†’ 90.jpg\n",
            "91: Renamed in 'MainSet1' â†’ 91.jpg\n",
            "92: Renamed in 'MainSet1' â†’ 92.jpg\n",
            "93: Renamed in 'MainSet1' â†’ 93.jpg\n",
            "94: Renamed in 'MainSet1' â†’ 94.jpg\n",
            "95: Renamed in 'MainSet1' â†’ 95.jpg\n",
            "96: Renamed in 'MainSet1' â†’ 96.jpg\n",
            "97: Renamed in 'MainSet1' â†’ 97.jpg\n",
            "98: Renamed in 'MainSet1' â†’ 98.jpg\n",
            "99: Renamed in 'MainSet1' â†’ 99.jpg\n",
            "100: Renamed in 'MainSet1' â†’ 100.jpg\n",
            "101: Renamed in 'MainSet1' â†’ 101.jpg\n",
            "102: Renamed in 'MainSet1' â†’ 102.jpg\n",
            "103: Renamed in 'MainSet1' â†’ 103.jpg\n",
            "104: Renamed in 'MainSet1' â†’ 104.jpg\n",
            "105: Renamed in 'MainSet1' â†’ 105.jpg\n",
            "106: Renamed in 'MainSet1' â†’ 106.jpg\n",
            "107: Renamed in 'MainSet1' â†’ 107.jpg\n",
            "108: Renamed in 'MainSet1' â†’ 108.jpg\n",
            "109: Renamed in 'MainSet1' â†’ 109.jpg\n",
            "110: Renamed in 'MainSet1' â†’ 110.jpg\n",
            "111: Renamed in 'MainSet1' â†’ 111.jpg\n",
            "112: Renamed in 'MainSet1' â†’ 112.jpg\n",
            "113: Renamed in 'MainSet1' â†’ 113.jpg\n",
            "114: Renamed in 'MainSet1' â†’ 114.jpg\n",
            "115: Renamed in 'MainSet1' â†’ 115.jpg\n",
            "116: Renamed in 'MainSet1' â†’ 116.jpg\n",
            "117: Renamed in 'MainSet1' â†’ 117.jpg\n",
            "118: Renamed in 'MainSet1' â†’ 118.jpg\n",
            "119: Renamed in 'MainSet1' â†’ 119.jpg\n",
            "120: Renamed in 'MainSet1' â†’ 120.jpg\n",
            "121: Renamed in 'MainSet1' â†’ 121.jpg\n",
            "122: Renamed in 'MainSet1' â†’ 122.jpg\n",
            "123: Renamed in 'MainSet1' â†’ 123.jpg\n",
            "124: Renamed in 'MainSet1' â†’ 124.jpg\n",
            "125: Renamed in 'MainSet1' â†’ 125.jpg\n",
            "126: Renamed in 'MainSet1' â†’ 126.jpg\n",
            "127: Renamed in 'MainSet1' â†’ 127.jpg\n",
            "128: Renamed in 'MainSet1' â†’ 128.jpg\n",
            "129: Renamed in 'MainSet1' â†’ 129.jpg\n",
            "130: Renamed in 'MainSet1' â†’ 130.jpg\n",
            "131: Renamed in 'MainSet1' â†’ 131.jpg\n",
            "132: Renamed in 'MainSet1' â†’ 132.jpg\n",
            "133: Renamed in 'MainSet1' â†’ 133.jpg\n",
            "134: Renamed in 'MainSet1' â†’ 134.jpg\n",
            "135: Renamed in 'MainSet1' â†’ 135.jpg\n",
            "136: Renamed in 'MainSet1' â†’ 136.jpg\n",
            "137: Renamed in 'MainSet1' â†’ 137.jpg\n",
            "138: Renamed in 'MainSet1' â†’ 138.jpg\n",
            "139: Renamed in 'MainSet1' â†’ 139.jpg\n",
            "140: Renamed in 'MainSet1' â†’ 140.jpg\n",
            "141: Renamed in 'MainSet1' â†’ 141.jpg\n",
            "142: Renamed in 'MainSet1' â†’ 142.jpg\n",
            "143: Renamed in 'MainSet1' â†’ 143.jpg\n",
            "144: Renamed in 'MainSet1' â†’ 144.jpg\n",
            "145: Renamed in 'MainSet1' â†’ 145.jpg\n",
            "146: Renamed in 'MainSet1' â†’ 146.jpg\n",
            "147: Renamed in 'MainSet1' â†’ 147.jpg\n",
            "148: Renamed in 'MainSet1' â†’ 148.jpg\n",
            "149: Renamed in 'MainSet1' â†’ 149.jpg\n",
            "150: Renamed in 'MainSet1' â†’ 150.jpg\n",
            "151: Renamed in 'MainSet1' â†’ 151.jpg\n",
            "152: Renamed in 'MainSet1' â†’ 152.jpg\n",
            "153: Renamed in 'MainSet1' â†’ 153.jpg\n",
            "154: Renamed in 'MainSet1' â†’ 154.jpg\n",
            "155: Renamed in 'MainSet1' â†’ 155.jpg\n",
            "156: Renamed in 'MainSet1' â†’ 156.jpg\n",
            "157: Renamed in 'MainSet1' â†’ 157.jpg\n",
            "158: Renamed in 'MainSet1' â†’ 158.jpg\n",
            "159: Renamed in 'MainSet1' â†’ 159.jpg\n",
            "160: Renamed in 'MainSet1' â†’ 160.jpg\n",
            "161: Renamed in 'MainSet1' â†’ 161.jpg\n",
            "162: Renamed in 'MainSet1' â†’ 162.jpg\n",
            "163: Renamed in 'MainSet1' â†’ 163.jpg\n",
            "164: Renamed in 'MainSet1' â†’ 164.jpg\n",
            "165: Renamed in 'MainSet1' â†’ 165.jpg\n",
            "166: Renamed in 'MainSet1' â†’ 166.jpg\n",
            "167: Renamed in 'MainSet1' â†’ 167.jpg\n",
            "168: Renamed in 'MainSet1' â†’ 168.jpg\n",
            "169: Renamed in 'MainSet1' â†’ 169.jpg\n",
            "170: Renamed in 'MainSet1' â†’ 170.jpg\n",
            "171: Renamed in 'MainSet1' â†’ 171.jpg\n",
            "172: Renamed in 'MainSet1' â†’ 172.jpg\n",
            "173: Renamed in 'MainSet1' â†’ 173.jpg\n",
            "174: Renamed in 'MainSet1' â†’ 174.jpg\n",
            "175: Renamed in 'MainSet1' â†’ 175.jpg\n",
            "176: Renamed in 'MainSet1' â†’ 176.jpg\n",
            "177: Renamed in 'MainSet1' â†’ 177.jpg\n",
            "178: Renamed in 'MainSet1' â†’ 178.jpg\n",
            "179: Renamed in 'MainSet1' â†’ 179.jpg\n",
            "180: Renamed in 'MainSet1' â†’ 180.jpg\n",
            "181: Renamed in 'MainSet1' â†’ 181.jpg\n",
            "182: Renamed in 'MainSet1' â†’ 182.jpg\n",
            "183: Renamed in 'MainSet1' â†’ 183.jpg\n",
            "184: Renamed in 'MainSet1' â†’ 184.jpg\n",
            "185: Renamed in 'MainSet1' â†’ 185.jpg\n",
            "186: Renamed in 'MainSet1' â†’ 186.jpg\n",
            "187: Renamed in 'MainSet1' â†’ 187.jpg\n",
            "188: Renamed in 'MainSet1' â†’ 188.jpg\n",
            "189: Renamed in 'MainSet1' â†’ 189.jpg\n",
            "190: Renamed in 'MainSet1' â†’ 190.jpg\n",
            "191: Renamed in 'MainSet1' â†’ 191.jpg\n",
            "192: Renamed in 'MainSet1' â†’ 192.jpg\n",
            "193: Renamed in 'MainSet1' â†’ 193.jpg\n",
            "194: Renamed in 'MainSet1' â†’ 194.jpg\n",
            "195: Renamed in 'MainSet1' â†’ 195.jpg\n",
            "196: Renamed in 'MainSet1' â†’ 196.jpg\n",
            "197: Renamed in 'MainSet1' â†’ 197.jpg\n",
            "198: Renamed in 'MainSet1' â†’ 198.jpg\n",
            "199: Renamed in 'MainSet1' â†’ 199.jpg\n",
            "200: Renamed in 'MainSet1' â†’ 200.jpg\n",
            "201: Renamed in 'MainSet1' â†’ 201.jpg\n",
            "202: Renamed in 'MainSet1' â†’ 202.jpg\n",
            "203: Renamed in 'MainSet1' â†’ 203.jpg\n",
            "204: Renamed in 'MainSet1' â†’ 204.jpg\n",
            "205: Renamed in 'MainSet1' â†’ 205.jpg\n",
            "206: Renamed in 'MainSet1' â†’ 206.jpg\n",
            "207: Renamed in 'MainSet1' â†’ 207.jpg\n",
            "208: Renamed in 'MainSet1' â†’ 208.jpg\n",
            "209: Renamed in 'MainSet1' â†’ 209.jpg\n",
            "210: Renamed in 'MainSet1' â†’ 210.jpg\n",
            "211: Renamed in 'MainSet1' â†’ 211.jpg\n",
            "212: Renamed in 'MainSet1' â†’ 212.jpg\n",
            "213: Renamed in 'MainSet10' â†’ 213.jpg\n",
            "214: Renamed in 'MainSet10' â†’ 214.jpg\n",
            "215: Renamed in 'MainSet10' â†’ 215.jpg\n",
            "216: Renamed in 'MainSet10' â†’ 216.jpg\n",
            "217: Renamed in 'MainSet10' â†’ 217.jpg\n",
            "218: Renamed in 'MainSet10' â†’ 218.jpg\n",
            "219: Renamed in 'MainSet10' â†’ 219.jpg\n",
            "220: Renamed in 'MainSet10' â†’ 220.jpg\n",
            "221: Renamed in 'MainSet10' â†’ 221.jpg\n",
            "222: Renamed in 'MainSet10' â†’ 222.jpg\n",
            "223: Renamed in 'MainSet10' â†’ 223.jpg\n",
            "224: Renamed in 'MainSet10' â†’ 224.jpg\n",
            "225: Renamed in 'MainSet10' â†’ 225.jpg\n",
            "226: Renamed in 'MainSet10' â†’ 226.jpg\n",
            "227: Renamed in 'MainSet10' â†’ 227.jpg\n",
            "228: Renamed in 'MainSet10' â†’ 228.jpg\n",
            "229: Renamed in 'MainSet10' â†’ 229.jpg\n",
            "230: Renamed in 'MainSet10' â†’ 230.jpg\n",
            "231: Renamed in 'MainSet10' â†’ 231.jpg\n",
            "232: Renamed in 'MainSet10' â†’ 232.jpg\n",
            "233: Renamed in 'MainSet10' â†’ 233.jpg\n",
            "234: Renamed in 'MainSet10' â†’ 234.jpg\n",
            "235: Renamed in 'MainSet10' â†’ 235.jpg\n",
            "236: Renamed in 'MainSet10' â†’ 236.jpg\n",
            "237: Renamed in 'MainSet10' â†’ 237.jpg\n",
            "238: Renamed in 'MainSet10' â†’ 238.jpg\n",
            "239: Renamed in 'MainSet10' â†’ 239.jpg\n",
            "240: Renamed in 'MainSet10' â†’ 240.jpg\n",
            "241: Renamed in 'MainSet10' â†’ 241.jpg\n",
            "242: Renamed in 'MainSet10' â†’ 242.jpg\n",
            "243: Renamed in 'MainSet10' â†’ 243.jpg\n",
            "244: Renamed in 'MainSet10' â†’ 244.jpg\n",
            "245: Renamed in 'MainSet10' â†’ 245.jpg\n",
            "246: Renamed in 'MainSet10' â†’ 246.jpg\n",
            "247: Renamed in 'MainSet10' â†’ 247.jpg\n",
            "248: Renamed in 'MainSet10' â†’ 248.jpg\n",
            "249: Renamed in 'MainSet10' â†’ 249.jpg\n",
            "250: Renamed in 'MainSet10' â†’ 250.jpg\n",
            "251: Renamed in 'MainSet10' â†’ 251.jpg\n",
            "252: Renamed in 'MainSet10' â†’ 252.jpg\n",
            "253: Renamed in 'MainSet10' â†’ 253.jpg\n",
            "254: Renamed in 'MainSet10' â†’ 254.jpg\n",
            "255: Renamed in 'MainSet10' â†’ 255.jpg\n",
            "256: Renamed in 'MainSet10' â†’ 256.jpg\n",
            "257: Renamed in 'MainSet10' â†’ 257.jpg\n",
            "258: Renamed in 'MainSet10' â†’ 258.jpg\n",
            "259: Renamed in 'MainSet10' â†’ 259.jpg\n",
            "260: Renamed in 'MainSet10' â†’ 260.jpg\n",
            "261: Renamed in 'MainSet10' â†’ 261.jpg\n",
            "262: Renamed in 'MainSet10' â†’ 262.jpg\n",
            "263: Renamed in 'MainSet10' â†’ 263.jpg\n",
            "264: Renamed in 'MainSet10' â†’ 264.jpg\n",
            "265: Renamed in 'MainSet10' â†’ 265.jpg\n",
            "266: Renamed in 'MainSet10' â†’ 266.jpg\n",
            "267: Renamed in 'MainSet10' â†’ 267.jpg\n",
            "268: Renamed in 'MainSet10' â†’ 268.jpg\n",
            "269: Renamed in 'MainSet10' â†’ 269.jpg\n",
            "270: Renamed in 'MainSet10' â†’ 270.jpg\n",
            "271: Renamed in 'MainSet10' â†’ 271.jpg\n",
            "272: Renamed in 'MainSet10' â†’ 272.jpg\n",
            "273: Renamed in 'MainSet10' â†’ 273.jpg\n",
            "274: Renamed in 'MainSet10' â†’ 274.jpg\n",
            "275: Renamed in 'MainSet10' â†’ 275.jpg\n",
            "276: Renamed in 'MainSet10' â†’ 276.jpg\n",
            "277: Renamed in 'MainSet10' â†’ 277.jpg\n",
            "278: Renamed in 'MainSet10' â†’ 278.jpg\n",
            "279: Renamed in 'MainSet10' â†’ 279.jpg\n",
            "280: Renamed in 'MainSet10' â†’ 280.jpg\n",
            "281: Renamed in 'MainSet10' â†’ 281.jpg\n",
            "282: Renamed in 'MainSet10' â†’ 282.jpg\n",
            "283: Renamed in 'MainSet10' â†’ 283.jpg\n",
            "284: Renamed in 'MainSet10' â†’ 284.jpg\n",
            "285: Renamed in 'MainSet10' â†’ 285.jpg\n",
            "286: Renamed in 'MainSet10' â†’ 286.jpg\n",
            "287: Renamed in 'MainSet10' â†’ 287.jpg\n",
            "288: Renamed in 'MainSet10' â†’ 288.jpg\n",
            "289: Renamed in 'MainSet10' â†’ 289.jpg\n",
            "290: Renamed in 'MainSet10' â†’ 290.jpg\n",
            "291: Renamed in 'MainSet10' â†’ 291.jpg\n",
            "292: Renamed in 'MainSet10' â†’ 292.jpg\n",
            "293: Renamed in 'MainSet10' â†’ 293.jpg\n",
            "294: Renamed in 'MainSet10' â†’ 294.jpg\n",
            "295: Renamed in 'MainSet10' â†’ 295.jpg\n",
            "296: Renamed in 'MainSet10' â†’ 296.jpg\n",
            "297: Renamed in 'MainSet10' â†’ 297.jpg\n",
            "298: Renamed in 'MainSet10' â†’ 298.jpg\n",
            "299: Renamed in 'MainSet10' â†’ 299.jpg\n",
            "300: Renamed in 'MainSet10' â†’ 300.jpg\n",
            "301: Renamed in 'MainSet10' â†’ 301.jpg\n",
            "302: Renamed in 'MainSet10' â†’ 302.jpg\n",
            "303: Renamed in 'MainSet10' â†’ 303.jpg\n",
            "304: Renamed in 'MainSet10' â†’ 304.jpg\n",
            "305: Renamed in 'MainSet10' â†’ 305.jpg\n",
            "306: Renamed in 'MainSet10' â†’ 306.jpg\n",
            "307: Renamed in 'MainSet10' â†’ 307.jpg\n",
            "308: Renamed in 'MainSet10' â†’ 308.jpg\n",
            "309: Renamed in 'MainSet10' â†’ 309.jpg\n",
            "310: Renamed in 'MainSet10' â†’ 310.jpg\n",
            "311: Renamed in 'MainSet10' â†’ 311.jpg\n",
            "312: Renamed in 'MainSet10' â†’ 312.jpg\n",
            "313: Renamed in 'MainSet10' â†’ 313.jpg\n",
            "314: Renamed in 'MainSet10' â†’ 314.jpg\n",
            "315: Renamed in 'MainSet10' â†’ 315.jpg\n",
            "316: Renamed in 'MainSet10' â†’ 316.jpg\n",
            "317: Renamed in 'MainSet10' â†’ 317.jpg\n",
            "318: Renamed in 'MainSet10' â†’ 318.jpg\n",
            "319: Renamed in 'MainSet10' â†’ 319.jpg\n",
            "320: Renamed in 'MainSet10' â†’ 320.jpg\n",
            "321: Renamed in 'MainSet10' â†’ 321.jpg\n",
            "322: Renamed in 'MainSet10' â†’ 322.jpg\n",
            "323: Renamed in 'MainSet10' â†’ 323.jpg\n",
            "324: Renamed in 'MainSet10' â†’ 324.jpg\n",
            "325: Renamed in 'MainSet10' â†’ 325.jpg\n",
            "326: Renamed in 'MainSet10' â†’ 326.jpg\n",
            "327: Renamed in 'MainSet10' â†’ 327.jpg\n",
            "328: Renamed in 'MainSet10' â†’ 328.jpg\n",
            "329: Renamed in 'MainSet10' â†’ 329.jpg\n",
            "330: Renamed in 'MainSet10' â†’ 330.jpg\n",
            "331: Renamed in 'MainSet10' â†’ 331.jpg\n",
            "332: Renamed in 'MainSet10' â†’ 332.jpg\n",
            "333: Renamed in 'MainSet10' â†’ 333.jpg\n",
            "334: Renamed in 'MainSet10' â†’ 334.jpg\n",
            "335: Renamed in 'MainSet10' â†’ 335.jpg\n",
            "336: Renamed in 'MainSet10' â†’ 336.jpg\n",
            "337: Renamed in 'MainSet10' â†’ 337.jpg\n",
            "338: Renamed in 'MainSet10' â†’ 338.jpg\n",
            "339: Renamed in 'MainSet10' â†’ 339.jpg\n",
            "340: Renamed in 'MainSet10' â†’ 340.jpg\n",
            "341: Renamed in 'MainSet10' â†’ 341.jpg\n",
            "342: Renamed in 'MainSet10' â†’ 342.jpg\n",
            "343: Renamed in 'MainSet10' â†’ 343.jpg\n",
            "344: Renamed in 'MainSet10' â†’ 344.jpg\n",
            "345: Renamed in 'MainSet10' â†’ 345.jpg\n",
            "346: Renamed in 'MainSet10' â†’ 346.jpg\n",
            "347: Renamed in 'MainSet10' â†’ 347.jpg\n",
            "348: Renamed in 'MainSet10' â†’ 348.jpg\n",
            "349: Renamed in 'MainSet10' â†’ 349.jpg\n",
            "350: Renamed in 'MainSet10' â†’ 350.jpg\n",
            "351: Renamed in 'MainSet10' â†’ 351.jpg\n",
            "352: Renamed in 'MainSet10' â†’ 352.jpg\n",
            "353: Renamed in 'MainSet10' â†’ 353.jpg\n",
            "354: Renamed in 'MainSet10' â†’ 354.jpg\n",
            "355: Renamed in 'MainSet10' â†’ 355.jpg\n",
            "356: Renamed in 'MainSet10' â†’ 356.jpg\n",
            "357: Renamed in 'MainSet10' â†’ 357.jpg\n",
            "358: Renamed in 'MainSet10' â†’ 358.jpg\n",
            "359: Renamed in 'MainSet10' â†’ 359.jpg\n",
            "360: Renamed in 'MainSet10' â†’ 360.jpg\n",
            "361: Renamed in 'MainSet10' â†’ 361.jpg\n",
            "362: Renamed in 'MainSet10' â†’ 362.jpg\n",
            "363: Renamed in 'MainSet10' â†’ 363.jpg\n",
            "364: Renamed in 'MainSet11' â†’ 364.jpg\n",
            "365: Renamed in 'MainSet11' â†’ 365.jpg\n",
            "366: Renamed in 'MainSet11' â†’ 366.jpg\n",
            "367: Renamed in 'MainSet11' â†’ 367.jpg\n",
            "368: Renamed in 'MainSet11' â†’ 368.jpg\n",
            "369: Renamed in 'MainSet11' â†’ 369.jpg\n",
            "370: Renamed in 'MainSet11' â†’ 370.jpg\n",
            "371: Renamed in 'MainSet11' â†’ 371.jpg\n",
            "372: Renamed in 'MainSet11' â†’ 372.jpg\n",
            "373: Renamed in 'MainSet11' â†’ 373.jpg\n",
            "374: Renamed in 'MainSet11' â†’ 374.jpg\n",
            "375: Renamed in 'MainSet11' â†’ 375.jpg\n",
            "376: Renamed in 'MainSet11' â†’ 376.jpg\n",
            "377: Renamed in 'MainSet11' â†’ 377.jpg\n",
            "378: Renamed in 'MainSet11' â†’ 378.jpg\n",
            "379: Renamed in 'MainSet11' â†’ 379.jpg\n",
            "380: Renamed in 'MainSet11' â†’ 380.jpg\n",
            "381: Renamed in 'MainSet11' â†’ 381.jpg\n",
            "382: Renamed in 'MainSet11' â†’ 382.jpg\n",
            "383: Renamed in 'MainSet11' â†’ 383.jpg\n",
            "384: Renamed in 'MainSet11' â†’ 384.jpg\n",
            "385: Renamed in 'MainSet11' â†’ 385.jpg\n",
            "386: Renamed in 'MainSet11' â†’ 386.jpg\n",
            "387: Renamed in 'MainSet11' â†’ 387.jpg\n",
            "388: Renamed in 'MainSet11' â†’ 388.jpg\n",
            "389: Renamed in 'MainSet11' â†’ 389.jpg\n",
            "390: Renamed in 'MainSet11' â†’ 390.jpg\n",
            "391: Renamed in 'MainSet11' â†’ 391.jpg\n",
            "392: Renamed in 'MainSet11' â†’ 392.jpg\n",
            "393: Renamed in 'MainSet11' â†’ 393.jpg\n",
            "394: Renamed in 'MainSet11' â†’ 394.jpg\n",
            "395: Renamed in 'MainSet11' â†’ 395.jpg\n",
            "396: Renamed in 'MainSet11' â†’ 396.jpg\n",
            "397: Renamed in 'MainSet11' â†’ 397.jpg\n",
            "398: Renamed in 'MainSet11' â†’ 398.jpg\n",
            "399: Renamed in 'MainSet11' â†’ 399.jpg\n",
            "400: Renamed in 'MainSet11' â†’ 400.jpg\n",
            "401: Renamed in 'MainSet11' â†’ 401.jpg\n",
            "402: Renamed in 'MainSet11' â†’ 402.jpg\n",
            "403: Renamed in 'MainSet11' â†’ 403.jpg\n",
            "404: Renamed in 'MainSet11' â†’ 404.jpg\n",
            "405: Renamed in 'MainSet11' â†’ 405.jpg\n",
            "406: Renamed in 'MainSet11' â†’ 406.jpg\n",
            "407: Renamed in 'MainSet11' â†’ 407.jpg\n",
            "408: Renamed in 'MainSet11' â†’ 408.jpg\n",
            "409: Renamed in 'MainSet11' â†’ 409.jpg\n",
            "410: Renamed in 'MainSet11' â†’ 410.jpg\n",
            "411: Renamed in 'MainSet11' â†’ 411.jpg\n",
            "412: Renamed in 'MainSet11' â†’ 412.jpg\n",
            "413: Renamed in 'MainSet11' â†’ 413.jpg\n",
            "414: Renamed in 'MainSet11' â†’ 414.jpg\n",
            "415: Renamed in 'MainSet11' â†’ 415.jpg\n",
            "416: Renamed in 'MainSet11' â†’ 416.jpg\n",
            "417: Renamed in 'MainSet11' â†’ 417.jpg\n",
            "418: Renamed in 'MainSet11' â†’ 418.jpg\n",
            "419: Renamed in 'MainSet11' â†’ 419.jpg\n",
            "420: Renamed in 'MainSet11' â†’ 420.jpg\n",
            "421: Renamed in 'MainSet11' â†’ 421.jpg\n",
            "422: Renamed in 'MainSet11' â†’ 422.jpg\n",
            "423: Renamed in 'MainSet11' â†’ 423.jpg\n",
            "424: Renamed in 'MainSet11' â†’ 424.jpg\n",
            "425: Renamed in 'MainSet11' â†’ 425.jpg\n",
            "426: Renamed in 'MainSet11' â†’ 426.jpg\n",
            "427: Renamed in 'MainSet11' â†’ 427.jpg\n",
            "428: Renamed in 'MainSet11' â†’ 428.jpg\n",
            "429: Renamed in 'MainSet11' â†’ 429.jpg\n",
            "430: Renamed in 'MainSet11' â†’ 430.jpg\n",
            "431: Renamed in 'MainSet11' â†’ 431.jpg\n",
            "432: Renamed in 'MainSet11' â†’ 432.jpg\n",
            "433: Renamed in 'MainSet11' â†’ 433.jpg\n",
            "434: Renamed in 'MainSet11' â†’ 434.jpg\n",
            "435: Renamed in 'MainSet11' â†’ 435.jpg\n",
            "436: Renamed in 'MainSet11' â†’ 436.jpg\n",
            "437: Renamed in 'MainSet11' â†’ 437.jpg\n",
            "438: Renamed in 'MainSet11' â†’ 438.jpg\n",
            "439: Renamed in 'MainSet11' â†’ 439.jpg\n",
            "440: Renamed in 'MainSet11' â†’ 440.jpg\n",
            "441: Renamed in 'MainSet11' â†’ 441.jpg\n",
            "442: Renamed in 'MainSet11' â†’ 442.jpg\n",
            "443: Renamed in 'MainSet11' â†’ 443.jpg\n",
            "444: Renamed in 'MainSet11' â†’ 444.jpg\n",
            "445: Renamed in 'MainSet11' â†’ 445.jpg\n",
            "446: Renamed in 'MainSet11' â†’ 446.jpg\n",
            "447: Renamed in 'MainSet11' â†’ 447.jpg\n",
            "448: Renamed in 'MainSet11' â†’ 448.jpg\n",
            "449: Renamed in 'MainSet11' â†’ 449.jpg\n",
            "450: Renamed in 'MainSet11' â†’ 450.jpg\n",
            "451: Renamed in 'MainSet11' â†’ 451.jpg\n",
            "452: Renamed in 'MainSet11' â†’ 452.jpg\n",
            "453: Renamed in 'MainSet11' â†’ 453.jpg\n",
            "454: Renamed in 'MainSet11' â†’ 454.jpg\n",
            "455: Renamed in 'MainSet11' â†’ 455.jpg\n",
            "456: Renamed in 'MainSet11' â†’ 456.jpg\n",
            "457: Renamed in 'MainSet11' â†’ 457.jpg\n",
            "458: Renamed in 'MainSet11' â†’ 458.jpg\n",
            "459: Renamed in 'MainSet11' â†’ 459.jpg\n",
            "460: Renamed in 'MainSet11' â†’ 460.jpg\n",
            "461: Renamed in 'MainSet11' â†’ 461.jpg\n",
            "462: Renamed in 'MainSet11' â†’ 462.jpg\n",
            "463: Renamed in 'MainSet11' â†’ 463.jpg\n",
            "464: Renamed in 'MainSet11' â†’ 464.jpg\n",
            "465: Renamed in 'MainSet11' â†’ 465.jpg\n",
            "466: Renamed in 'MainSet11' â†’ 466.jpg\n",
            "467: Renamed in 'MainSet11' â†’ 467.jpg\n",
            "468: Renamed in 'MainSet11' â†’ 468.jpg\n",
            "469: Renamed in 'MainSet11' â†’ 469.jpg\n",
            "470: Renamed in 'MainSet11' â†’ 470.jpg\n",
            "471: Renamed in 'MainSet11' â†’ 471.jpg\n",
            "472: Renamed in 'MainSet11' â†’ 472.jpg\n",
            "473: Renamed in 'MainSet11' â†’ 473.jpg\n",
            "474: Renamed in 'MainSet11' â†’ 474.jpg\n",
            "475: Renamed in 'MainSet11' â†’ 475.jpg\n",
            "476: Renamed in 'MainSet11' â†’ 476.jpg\n",
            "477: Renamed in 'MainSet11' â†’ 477.jpg\n",
            "478: Renamed in 'MainSet11' â†’ 478.jpg\n",
            "479: Renamed in 'MainSet11' â†’ 479.jpg\n",
            "480: Renamed in 'MainSet11' â†’ 480.jpg\n",
            "481: Renamed in 'MainSet11' â†’ 481.jpg\n",
            "482: Renamed in 'MainSet11' â†’ 482.jpg\n",
            "483: Renamed in 'MainSet11' â†’ 483.jpg\n",
            "484: Renamed in 'MainSet11' â†’ 484.jpg\n",
            "485: Renamed in 'MainSet11' â†’ 485.jpg\n",
            "486: Renamed in 'MainSet11' â†’ 486.jpg\n",
            "487: Renamed in 'MainSet11' â†’ 487.jpg\n",
            "488: Renamed in 'MainSet11' â†’ 488.jpg\n",
            "489: Renamed in 'MainSet11' â†’ 489.jpg\n",
            "490: Renamed in 'MainSet11' â†’ 490.jpg\n",
            "491: Renamed in 'MainSet11' â†’ 491.jpg\n",
            "492: Renamed in 'MainSet11' â†’ 492.jpg\n",
            "493: Renamed in 'MainSet11' â†’ 493.jpg\n",
            "494: Renamed in 'MainSet11' â†’ 494.jpg\n",
            "495: Renamed in 'MainSet11' â†’ 495.jpg\n",
            "496: Renamed in 'MainSet11' â†’ 496.jpg\n",
            "497: Renamed in 'MainSet11' â†’ 497.jpg\n",
            "498: Renamed in 'MainSet11' â†’ 498.jpg\n",
            "499: Renamed in 'MainSet11' â†’ 499.jpg\n",
            "500: Renamed in 'MainSet12' â†’ 500.jpg\n",
            "501: Renamed in 'MainSet12' â†’ 501.jpg\n",
            "502: Renamed in 'MainSet12' â†’ 502.jpg\n",
            "503: Renamed in 'MainSet12' â†’ 503.jpg\n",
            "504: Renamed in 'MainSet12' â†’ 504.jpg\n",
            "505: Renamed in 'MainSet12' â†’ 505.jpg\n",
            "506: Renamed in 'MainSet12' â†’ 506.jpg\n",
            "507: Renamed in 'MainSet12' â†’ 507.jpg\n",
            "508: Renamed in 'MainSet12' â†’ 508.jpg\n",
            "509: Renamed in 'MainSet12' â†’ 509.jpg\n",
            "510: Renamed in 'MainSet12' â†’ 510.jpg\n",
            "511: Renamed in 'MainSet12' â†’ 511.jpg\n",
            "512: Renamed in 'MainSet12' â†’ 512.jpg\n",
            "513: Renamed in 'MainSet12' â†’ 513.jpg\n",
            "514: Renamed in 'MainSet12' â†’ 514.jpg\n",
            "515: Renamed in 'MainSet12' â†’ 515.jpg\n",
            "516: Renamed in 'MainSet12' â†’ 516.jpg\n",
            "517: Renamed in 'MainSet12' â†’ 517.jpg\n",
            "518: Renamed in 'MainSet12' â†’ 518.jpg\n",
            "519: Renamed in 'MainSet12' â†’ 519.jpg\n",
            "520: Renamed in 'MainSet12' â†’ 520.jpg\n",
            "521: Renamed in 'MainSet12' â†’ 521.jpg\n",
            "522: Renamed in 'MainSet12' â†’ 522.jpg\n",
            "523: Renamed in 'MainSet12' â†’ 523.jpg\n",
            "524: Renamed in 'MainSet12' â†’ 524.jpg\n",
            "525: Renamed in 'MainSet12' â†’ 525.jpg\n",
            "526: Renamed in 'MainSet12' â†’ 526.jpg\n",
            "527: Renamed in 'MainSet12' â†’ 527.jpg\n",
            "528: Renamed in 'MainSet12' â†’ 528.jpg\n",
            "529: Renamed in 'MainSet12' â†’ 529.jpg\n",
            "530: Renamed in 'MainSet12' â†’ 530.jpg\n",
            "531: Renamed in 'MainSet12' â†’ 531.jpg\n",
            "532: Renamed in 'MainSet12' â†’ 532.jpg\n",
            "533: Renamed in 'MainSet12' â†’ 533.jpg\n",
            "534: Renamed in 'MainSet12' â†’ 534.jpg\n",
            "535: Renamed in 'MainSet12' â†’ 535.jpg\n",
            "536: Renamed in 'MainSet12' â†’ 536.jpg\n",
            "537: Renamed in 'MainSet12' â†’ 537.jpg\n",
            "538: Renamed in 'MainSet12' â†’ 538.jpg\n",
            "539: Renamed in 'MainSet12' â†’ 539.jpg\n",
            "540: Renamed in 'MainSet12' â†’ 540.jpg\n",
            "541: Renamed in 'MainSet12' â†’ 541.jpg\n",
            "542: Renamed in 'MainSet12' â†’ 542.jpg\n",
            "543: Renamed in 'MainSet12' â†’ 543.jpg\n",
            "544: Renamed in 'MainSet12' â†’ 544.jpg\n",
            "545: Renamed in 'MainSet12' â†’ 545.jpg\n",
            "546: Renamed in 'MainSet12' â†’ 546.jpg\n",
            "547: Renamed in 'MainSet12' â†’ 547.jpg\n",
            "548: Renamed in 'MainSet12' â†’ 548.jpg\n",
            "549: Renamed in 'MainSet12' â†’ 549.jpg\n",
            "550: Renamed in 'MainSet12' â†’ 550.jpg\n",
            "551: Renamed in 'MainSet12' â†’ 551.jpg\n",
            "552: Renamed in 'MainSet12' â†’ 552.jpg\n",
            "553: Renamed in 'MainSet12' â†’ 553.jpg\n",
            "554: Renamed in 'MainSet12' â†’ 554.jpg\n",
            "555: Renamed in 'MainSet12' â†’ 555.jpg\n",
            "556: Renamed in 'MainSet12' â†’ 556.jpg\n",
            "557: Renamed in 'MainSet12' â†’ 557.jpg\n",
            "558: Renamed in 'MainSet12' â†’ 558.jpg\n",
            "559: Renamed in 'MainSet12' â†’ 559.jpg\n",
            "560: Renamed in 'MainSet12' â†’ 560.jpg\n",
            "561: Renamed in 'MainSet12' â†’ 561.jpg\n",
            "562: Renamed in 'MainSet12' â†’ 562.jpg\n",
            "563: Renamed in 'MainSet12' â†’ 563.jpg\n",
            "564: Renamed in 'MainSet12' â†’ 564.jpg\n",
            "565: Renamed in 'MainSet12' â†’ 565.jpg\n",
            "566: Renamed in 'MainSet12' â†’ 566.jpg\n",
            "567: Renamed in 'MainSet12' â†’ 567.jpg\n",
            "568: Renamed in 'MainSet12' â†’ 568.jpg\n",
            "569: Renamed in 'MainSet12' â†’ 569.jpg\n",
            "570: Renamed in 'MainSet12' â†’ 570.jpg\n",
            "571: Renamed in 'MainSet12' â†’ 571.jpg\n",
            "572: Renamed in 'MainSet12' â†’ 572.jpg\n",
            "573: Renamed in 'MainSet12' â†’ 573.jpg\n",
            "574: Renamed in 'MainSet12' â†’ 574.jpg\n",
            "575: Renamed in 'MainSet12' â†’ 575.jpg\n",
            "576: Renamed in 'MainSet12' â†’ 576.jpg\n",
            "577: Renamed in 'MainSet12' â†’ 577.jpg\n",
            "578: Renamed in 'MainSet12' â†’ 578.jpg\n",
            "579: Renamed in 'MainSet12' â†’ 579.jpg\n",
            "580: Renamed in 'MainSet12' â†’ 580.jpg\n",
            "581: Renamed in 'MainSet12' â†’ 581.jpg\n",
            "582: Renamed in 'MainSet12' â†’ 582.jpg\n",
            "583: Renamed in 'MainSet12' â†’ 583.jpg\n",
            "584: Renamed in 'MainSet12' â†’ 584.jpg\n",
            "585: Renamed in 'MainSet12' â†’ 585.jpg\n",
            "586: Renamed in 'MainSet12' â†’ 586.jpg\n",
            "587: Renamed in 'MainSet12' â†’ 587.jpg\n",
            "588: Renamed in 'MainSet12' â†’ 588.jpg\n",
            "589: Renamed in 'MainSet12' â†’ 589.jpg\n",
            "590: Renamed in 'MainSet12' â†’ 590.jpg\n",
            "591: Renamed in 'MainSet12' â†’ 591.jpg\n",
            "592: Renamed in 'MainSet12' â†’ 592.jpg\n",
            "593: Renamed in 'MainSet12' â†’ 593.jpg\n",
            "594: Renamed in 'MainSet12' â†’ 594.jpg\n",
            "595: Renamed in 'MainSet12' â†’ 595.jpg\n",
            "596: Renamed in 'MainSet12' â†’ 596.jpg\n",
            "597: Renamed in 'MainSet12' â†’ 597.jpg\n",
            "598: Renamed in 'MainSet12' â†’ 598.jpg\n",
            "599: Renamed in 'MainSet12' â†’ 599.jpg\n",
            "600: Renamed in 'MainSet12' â†’ 600.jpg\n",
            "601: Renamed in 'MainSet12' â†’ 601.jpg\n",
            "602: Renamed in 'MainSet12' â†’ 602.jpg\n",
            "603: Renamed in 'MainSet12' â†’ 603.jpg\n",
            "604: Renamed in 'MainSet12' â†’ 604.jpg\n",
            "605: Renamed in 'MainSet12' â†’ 605.jpg\n",
            "606: Renamed in 'MainSet12' â†’ 606.jpg\n",
            "607: Renamed in 'MainSet12' â†’ 607.jpg\n",
            "608: Renamed in 'MainSet12' â†’ 608.jpg\n",
            "609: Renamed in 'MainSet12' â†’ 609.jpg\n",
            "610: Renamed in 'MainSet12' â†’ 610.jpg\n",
            "611: Renamed in 'MainSet12' â†’ 611.jpg\n",
            "612: Renamed in 'MainSet12' â†’ 612.jpg\n",
            "613: Renamed in 'MainSet12' â†’ 613.jpg\n",
            "614: Renamed in 'MainSet12' â†’ 614.jpg\n",
            "615: Renamed in 'MainSet12' â†’ 615.jpg\n",
            "616: Renamed in 'MainSet12' â†’ 616.jpg\n",
            "617: Renamed in 'MainSet13' â†’ 617.jpg\n",
            "618: Renamed in 'MainSet13' â†’ 618.jpg\n",
            "619: Renamed in 'MainSet13' â†’ 619.jpg\n",
            "620: Renamed in 'MainSet13' â†’ 620.jpg\n",
            "621: Renamed in 'MainSet13' â†’ 621.jpg\n",
            "622: Renamed in 'MainSet13' â†’ 622.jpg\n",
            "623: Renamed in 'MainSet13' â†’ 623.jpg\n",
            "624: Renamed in 'MainSet13' â†’ 624.jpg\n",
            "625: Renamed in 'MainSet13' â†’ 625.jpg\n",
            "626: Renamed in 'MainSet13' â†’ 626.jpg\n",
            "627: Renamed in 'MainSet13' â†’ 627.jpg\n",
            "628: Renamed in 'MainSet13' â†’ 628.jpg\n",
            "629: Renamed in 'MainSet13' â†’ 629.jpg\n",
            "630: Renamed in 'MainSet13' â†’ 630.jpg\n",
            "631: Renamed in 'MainSet13' â†’ 631.jpg\n",
            "632: Renamed in 'MainSet13' â†’ 632.jpg\n",
            "633: Renamed in 'MainSet13' â†’ 633.jpg\n",
            "634: Renamed in 'MainSet13' â†’ 634.jpg\n",
            "635: Renamed in 'MainSet13' â†’ 635.jpg\n",
            "636: Renamed in 'MainSet13' â†’ 636.jpg\n",
            "637: Renamed in 'MainSet13' â†’ 637.jpg\n",
            "638: Renamed in 'MainSet13' â†’ 638.jpg\n",
            "639: Renamed in 'MainSet13' â†’ 639.jpg\n",
            "640: Renamed in 'MainSet13' â†’ 640.jpg\n",
            "641: Renamed in 'MainSet13' â†’ 641.jpg\n",
            "642: Renamed in 'MainSet13' â†’ 642.jpg\n",
            "643: Renamed in 'MainSet13' â†’ 643.jpg\n",
            "644: Renamed in 'MainSet13' â†’ 644.jpg\n",
            "645: Renamed in 'MainSet13' â†’ 645.jpg\n",
            "646: Renamed in 'MainSet13' â†’ 646.jpg\n",
            "647: Renamed in 'MainSet13' â†’ 647.jpg\n",
            "648: Renamed in 'MainSet13' â†’ 648.jpg\n",
            "649: Renamed in 'MainSet13' â†’ 649.jpg\n",
            "650: Renamed in 'MainSet13' â†’ 650.jpg\n",
            "651: Renamed in 'MainSet13' â†’ 651.jpg\n",
            "652: Renamed in 'MainSet13' â†’ 652.jpg\n",
            "653: Renamed in 'MainSet13' â†’ 653.jpg\n",
            "654: Renamed in 'MainSet13' â†’ 654.jpg\n",
            "655: Renamed in 'MainSet13' â†’ 655.jpg\n",
            "656: Renamed in 'MainSet13' â†’ 656.jpg\n",
            "657: Renamed in 'MainSet13' â†’ 657.jpg\n",
            "658: Renamed in 'MainSet13' â†’ 658.jpg\n",
            "659: Renamed in 'MainSet13' â†’ 659.jpg\n",
            "660: Renamed in 'MainSet13' â†’ 660.jpg\n",
            "661: Renamed in 'MainSet13' â†’ 661.jpg\n",
            "662: Renamed in 'MainSet13' â†’ 662.jpg\n",
            "663: Renamed in 'MainSet13' â†’ 663.jpg\n",
            "664: Renamed in 'MainSet13' â†’ 664.jpg\n",
            "665: Renamed in 'MainSet13' â†’ 665.jpg\n",
            "666: Renamed in 'MainSet13' â†’ 666.jpg\n",
            "667: Renamed in 'MainSet13' â†’ 667.jpg\n",
            "668: Renamed in 'MainSet13' â†’ 668.jpg\n",
            "669: Renamed in 'MainSet13' â†’ 669.jpg\n",
            "670: Renamed in 'MainSet13' â†’ 670.jpg\n",
            "671: Renamed in 'MainSet13' â†’ 671.jpg\n",
            "672: Renamed in 'MainSet13' â†’ 672.jpg\n",
            "673: Renamed in 'MainSet13' â†’ 673.jpg\n",
            "674: Renamed in 'MainSet13' â†’ 674.jpg\n",
            "675: Renamed in 'MainSet13' â†’ 675.jpg\n",
            "676: Renamed in 'MainSet13' â†’ 676.jpg\n",
            "677: Renamed in 'MainSet13' â†’ 677.jpg\n",
            "678: Renamed in 'MainSet13' â†’ 678.jpg\n",
            "679: Renamed in 'MainSet13' â†’ 679.jpg\n",
            "680: Renamed in 'MainSet13' â†’ 680.jpg\n",
            "681: Renamed in 'MainSet13' â†’ 681.jpg\n",
            "682: Renamed in 'MainSet13' â†’ 682.jpg\n",
            "683: Renamed in 'MainSet13' â†’ 683.jpg\n",
            "684: Renamed in 'MainSet13' â†’ 684.jpg\n",
            "685: Renamed in 'MainSet13' â†’ 685.jpg\n",
            "686: Renamed in 'MainSet13' â†’ 686.jpg\n",
            "687: Renamed in 'MainSet13' â†’ 687.jpg\n",
            "688: Renamed in 'MainSet13' â†’ 688.jpg\n",
            "689: Renamed in 'MainSet13' â†’ 689.jpg\n",
            "690: Renamed in 'MainSet13' â†’ 690.jpg\n",
            "691: Renamed in 'MainSet13' â†’ 691.jpg\n",
            "692: Renamed in 'MainSet13' â†’ 692.jpg\n",
            "693: Renamed in 'MainSet13' â†’ 693.jpg\n",
            "694: Renamed in 'MainSet13' â†’ 694.jpg\n",
            "695: Renamed in 'MainSet13' â†’ 695.jpg\n",
            "696: Renamed in 'MainSet13' â†’ 696.jpg\n",
            "697: Renamed in 'MainSet13' â†’ 697.jpg\n",
            "698: Renamed in 'MainSet13' â†’ 698.jpg\n",
            "699: Renamed in 'MainSet13' â†’ 699.jpg\n",
            "700: Renamed in 'MainSet13' â†’ 700.jpg\n",
            "701: Renamed in 'MainSet13' â†’ 701.jpg\n",
            "702: Renamed in 'MainSet13' â†’ 702.jpg\n",
            "703: Renamed in 'MainSet13' â†’ 703.jpg\n",
            "704: Renamed in 'MainSet13' â†’ 704.jpg\n",
            "705: Renamed in 'MainSet13' â†’ 705.jpg\n",
            "706: Renamed in 'MainSet13' â†’ 706.jpg\n",
            "707: Renamed in 'MainSet13' â†’ 707.jpg\n",
            "708: Renamed in 'MainSet13' â†’ 708.jpg\n",
            "709: Renamed in 'MainSet13' â†’ 709.jpg\n",
            "710: Renamed in 'MainSet13' â†’ 710.jpg\n",
            "711: Renamed in 'MainSet13' â†’ 711.jpg\n",
            "712: Renamed in 'MainSet13' â†’ 712.jpg\n",
            "713: Renamed in 'MainSet13' â†’ 713.jpg\n",
            "714: Renamed in 'MainSet13' â†’ 714.jpg\n",
            "715: Renamed in 'MainSet13' â†’ 715.jpg\n",
            "716: Renamed in 'MainSet13' â†’ 716.jpg\n",
            "717: Renamed in 'MainSet13' â†’ 717.jpg\n",
            "718: Renamed in 'MainSet13' â†’ 718.jpg\n",
            "719: Renamed in 'MainSet13' â†’ 719.jpg\n",
            "720: Renamed in 'MainSet13' â†’ 720.jpg\n",
            "721: Renamed in 'MainSet13' â†’ 721.jpg\n",
            "722: Renamed in 'MainSet13' â†’ 722.jpg\n",
            "723: Renamed in 'MainSet13' â†’ 723.jpg\n",
            "724: Renamed in 'MainSet13' â†’ 724.jpg\n",
            "725: Renamed in 'MainSet13' â†’ 725.jpg\n",
            "726: Renamed in 'MainSet13' â†’ 726.jpg\n",
            "727: Renamed in 'MainSet13' â†’ 727.jpg\n",
            "728: Renamed in 'MainSet13' â†’ 728.jpg\n",
            "729: Renamed in 'MainSet13' â†’ 729.jpg\n",
            "730: Renamed in 'MainSet13' â†’ 730.jpg\n",
            "731: Renamed in 'MainSet13' â†’ 731.jpg\n",
            "732: Renamed in 'MainSet13' â†’ 732.jpg\n",
            "733: Renamed in 'MainSet13' â†’ 733.jpg\n",
            "734: Renamed in 'MainSet13' â†’ 734.jpg\n",
            "735: Renamed in 'MainSet13' â†’ 735.jpg\n",
            "736: Renamed in 'MainSet13' â†’ 736.jpg\n",
            "737: Renamed in 'MainSet13' â†’ 737.jpg\n",
            "738: Renamed in 'MainSet13' â†’ 738.jpg\n",
            "739: Renamed in 'MainSet13' â†’ 739.jpg\n",
            "740: Renamed in 'MainSet13' â†’ 740.jpg\n",
            "741: Renamed in 'MainSet13' â†’ 741.jpg\n",
            "742: Renamed in 'MainSet13' â†’ 742.jpg\n",
            "743: Renamed in 'MainSet13' â†’ 743.jpg\n",
            "744: Renamed in 'MainSet13' â†’ 744.jpg\n",
            "745: Renamed in 'MainSet13' â†’ 745.jpg\n",
            "746: Renamed in 'MainSet13' â†’ 746.jpg\n",
            "747: Renamed in 'MainSet13' â†’ 747.jpg\n",
            "748: Renamed in 'MainSet13' â†’ 748.jpg\n",
            "749: Renamed in 'MainSet13' â†’ 749.jpg\n",
            "750: Renamed in 'MainSet13' â†’ 750.jpg\n",
            "751: Renamed in 'MainSet13' â†’ 751.jpg\n",
            "752: Renamed in 'MainSet13' â†’ 752.jpg\n",
            "753: Renamed in 'MainSet13' â†’ 753.jpg\n",
            "754: Renamed in 'MainSet13' â†’ 754.jpg\n",
            "755: Renamed in 'MainSet13' â†’ 755.jpg\n",
            "756: Renamed in 'MainSet13' â†’ 756.jpg\n",
            "757: Renamed in 'MainSet13' â†’ 757.jpg\n",
            "758: Renamed in 'MainSet13' â†’ 758.jpg\n",
            "759: Renamed in 'MainSet13' â†’ 759.jpg\n",
            "760: Renamed in 'MainSet13' â†’ 760.jpg\n",
            "761: Renamed in 'MainSet13' â†’ 761.jpg\n",
            "762: Renamed in 'MainSet13' â†’ 762.jpg\n",
            "763: Renamed in 'MainSet13' â†’ 763.jpg\n",
            "764: Renamed in 'MainSet13' â†’ 764.jpg\n",
            "765: Renamed in 'MainSet13' â†’ 765.jpg\n",
            "766: Renamed in 'MainSet13' â†’ 766.jpg\n",
            "767: Renamed in 'MainSet13' â†’ 767.jpg\n",
            "768: Renamed in 'MainSet13' â†’ 768.jpg\n",
            "769: Renamed in 'MainSet13' â†’ 769.jpg\n",
            "770: Renamed in 'MainSet13' â†’ 770.jpg\n",
            "771: Renamed in 'MainSet13' â†’ 771.jpg\n",
            "772: Renamed in 'MainSet13' â†’ 772.jpg\n",
            "773: Renamed in 'MainSet13' â†’ 773.jpg\n",
            "774: Renamed in 'MainSet13' â†’ 774.jpg\n",
            "775: Renamed in 'MainSet13' â†’ 775.jpg\n",
            "776: Renamed in 'MainSet13' â†’ 776.jpg\n",
            "777: Renamed in 'MainSet13' â†’ 777.jpg\n",
            "778: Renamed in 'MainSet13' â†’ 778.jpg\n",
            "779: Renamed in 'MainSet13' â†’ 779.jpg\n",
            "780: Renamed in 'MainSet13' â†’ 780.jpg\n",
            "781: Renamed in 'MainSet13' â†’ 781.jpg\n",
            "782: Renamed in 'MainSet13' â†’ 782.jpg\n",
            "783: Renamed in 'MainSet13' â†’ 783.jpg\n",
            "784: Renamed in 'MainSet13' â†’ 784.jpg\n",
            "785: Renamed in 'MainSet13' â†’ 785.jpg\n",
            "786: Renamed in 'MainSet13' â†’ 786.jpg\n",
            "787: Renamed in 'MainSet13' â†’ 787.jpg\n",
            "788: Renamed in 'MainSet13' â†’ 788.jpg\n",
            "789: Renamed in 'MainSet13' â†’ 789.jpg\n",
            "790: Renamed in 'MainSet13' â†’ 790.jpg\n",
            "791: Renamed in 'MainSet13' â†’ 791.jpg\n",
            "792: Renamed in 'MainSet13' â†’ 792.jpg\n",
            "793: Renamed in 'MainSet13' â†’ 793.jpg\n",
            "794: Renamed in 'MainSet13' â†’ 794.jpg\n",
            "795: Renamed in 'MainSet13' â†’ 795.jpg\n",
            "796: Renamed in 'MainSet13' â†’ 796.jpg\n",
            "797: Renamed in 'MainSet13' â†’ 797.jpg\n",
            "798: Renamed in 'MainSet13' â†’ 798.jpg\n",
            "799: Renamed in 'MainSet13' â†’ 799.jpg\n",
            "800: Renamed in 'MainSet13' â†’ 800.jpg\n",
            "801: Renamed in 'MainSet13' â†’ 801.jpg\n",
            "802: Renamed in 'MainSet13' â†’ 802.jpg\n",
            "803: Renamed in 'MainSet13' â†’ 803.jpg\n",
            "804: Renamed in 'MainSet13' â†’ 804.jpg\n",
            "805: Renamed in 'MainSet13' â†’ 805.jpg\n",
            "806: Renamed in 'MainSet13' â†’ 806.jpg\n",
            "807: Renamed in 'MainSet13' â†’ 807.jpg\n",
            "808: Renamed in 'MainSet13' â†’ 808.jpg\n",
            "809: Renamed in 'MainSet13' â†’ 809.jpg\n",
            "810: Renamed in 'MainSet13' â†’ 810.jpg\n",
            "811: Renamed in 'MainSet13' â†’ 811.jpg\n",
            "812: Renamed in 'MainSet13' â†’ 812.jpg\n",
            "813: Renamed in 'MainSet13' â†’ 813.jpg\n",
            "814: Renamed in 'MainSet13' â†’ 814.jpg\n",
            "815: Renamed in 'MainSet13' â†’ 815.jpg\n",
            "816: Renamed in 'MainSet13' â†’ 816.jpg\n",
            "817: Renamed in 'MainSet13' â†’ 817.jpg\n",
            "818: Renamed in 'MainSet13' â†’ 818.jpg\n",
            "819: Renamed in 'MainSet13' â†’ 819.jpg\n",
            "820: Renamed in 'MainSet13' â†’ 820.jpg\n",
            "821: Renamed in 'MainSet13' â†’ 821.jpg\n",
            "822: Renamed in 'MainSet13' â†’ 822.jpg\n",
            "823: Renamed in 'MainSet13' â†’ 823.jpg\n",
            "824: Renamed in 'MainSet13' â†’ 824.jpg\n",
            "825: Renamed in 'MainSet13' â†’ 825.jpg\n",
            "826: Renamed in 'MainSet13' â†’ 826.jpg\n",
            "827: Renamed in 'MainSet13' â†’ 827.jpg\n",
            "828: Renamed in 'MainSet13' â†’ 828.jpg\n",
            "829: Renamed in 'MainSet14' â†’ 829.jpg\n",
            "830: Renamed in 'MainSet14' â†’ 830.jpg\n",
            "831: Renamed in 'MainSet14' â†’ 831.jpg\n",
            "832: Renamed in 'MainSet14' â†’ 832.jpg\n",
            "833: Renamed in 'MainSet14' â†’ 833.jpg\n",
            "834: Renamed in 'MainSet14' â†’ 834.jpg\n",
            "835: Renamed in 'MainSet14' â†’ 835.jpg\n",
            "836: Renamed in 'MainSet14' â†’ 836.jpg\n",
            "837: Renamed in 'MainSet14' â†’ 837.jpg\n",
            "838: Renamed in 'MainSet14' â†’ 838.jpg\n",
            "839: Renamed in 'MainSet14' â†’ 839.jpg\n",
            "840: Renamed in 'MainSet14' â†’ 840.jpg\n",
            "841: Renamed in 'MainSet14' â†’ 841.jpg\n",
            "842: Renamed in 'MainSet14' â†’ 842.jpg\n",
            "843: Renamed in 'MainSet14' â†’ 843.jpg\n",
            "844: Renamed in 'MainSet14' â†’ 844.jpg\n",
            "845: Renamed in 'MainSet14' â†’ 845.jpg\n",
            "846: Renamed in 'MainSet14' â†’ 846.jpg\n",
            "847: Renamed in 'MainSet14' â†’ 847.jpg\n",
            "848: Renamed in 'MainSet14' â†’ 848.jpg\n",
            "849: Renamed in 'MainSet14' â†’ 849.jpg\n",
            "850: Renamed in 'MainSet14' â†’ 850.jpg\n",
            "851: Renamed in 'MainSet14' â†’ 851.jpg\n",
            "852: Renamed in 'MainSet14' â†’ 852.jpg\n",
            "853: Renamed in 'MainSet14' â†’ 853.jpg\n",
            "854: Renamed in 'MainSet14' â†’ 854.jpg\n",
            "855: Renamed in 'MainSet14' â†’ 855.jpg\n",
            "856: Renamed in 'MainSet14' â†’ 856.jpg\n",
            "857: Renamed in 'MainSet14' â†’ 857.jpg\n",
            "858: Renamed in 'MainSet14' â†’ 858.jpg\n",
            "859: Renamed in 'MainSet14' â†’ 859.jpg\n",
            "860: Renamed in 'MainSet14' â†’ 860.jpg\n",
            "861: Renamed in 'MainSet14' â†’ 861.jpg\n",
            "862: Renamed in 'MainSet14' â†’ 862.jpg\n",
            "863: Renamed in 'MainSet14' â†’ 863.jpg\n",
            "864: Renamed in 'MainSet14' â†’ 864.jpg\n",
            "865: Renamed in 'MainSet14' â†’ 865.jpg\n",
            "866: Renamed in 'MainSet14' â†’ 866.jpg\n",
            "867: Renamed in 'MainSet14' â†’ 867.jpg\n",
            "868: Renamed in 'MainSet14' â†’ 868.jpg\n",
            "869: Renamed in 'MainSet14' â†’ 869.jpg\n",
            "870: Renamed in 'MainSet14' â†’ 870.jpg\n",
            "871: Renamed in 'MainSet14' â†’ 871.jpg\n",
            "872: Renamed in 'MainSet14' â†’ 872.jpg\n",
            "873: Renamed in 'MainSet14' â†’ 873.jpg\n",
            "874: Renamed in 'MainSet14' â†’ 874.jpg\n",
            "875: Renamed in 'MainSet14' â†’ 875.jpg\n",
            "876: Renamed in 'MainSet14' â†’ 876.jpg\n",
            "877: Renamed in 'MainSet14' â†’ 877.jpg\n",
            "878: Renamed in 'MainSet14' â†’ 878.jpg\n",
            "879: Renamed in 'MainSet14' â†’ 879.jpg\n",
            "880: Renamed in 'MainSet14' â†’ 880.jpg\n",
            "881: Renamed in 'MainSet14' â†’ 881.jpg\n",
            "882: Renamed in 'MainSet14' â†’ 882.jpg\n",
            "883: Renamed in 'MainSet14' â†’ 883.jpg\n",
            "884: Renamed in 'MainSet14' â†’ 884.jpg\n",
            "885: Renamed in 'MainSet14' â†’ 885.jpg\n",
            "886: Renamed in 'MainSet14' â†’ 886.jpg\n",
            "887: Renamed in 'MainSet14' â†’ 887.jpg\n",
            "888: Renamed in 'MainSet14' â†’ 888.jpg\n",
            "889: Renamed in 'MainSet14' â†’ 889.jpg\n",
            "890: Renamed in 'MainSet14' â†’ 890.jpg\n",
            "891: Renamed in 'MainSet14' â†’ 891.jpg\n",
            "892: Renamed in 'MainSet14' â†’ 892.jpg\n",
            "893: Renamed in 'MainSet14' â†’ 893.jpg\n",
            "894: Renamed in 'MainSet14' â†’ 894.jpg\n",
            "895: Renamed in 'MainSet14' â†’ 895.jpg\n",
            "896: Renamed in 'MainSet14' â†’ 896.jpg\n",
            "897: Renamed in 'MainSet14' â†’ 897.jpg\n",
            "898: Renamed in 'MainSet14' â†’ 898.jpg\n",
            "899: Renamed in 'MainSet14' â†’ 899.jpg\n",
            "900: Renamed in 'MainSet14' â†’ 900.jpg\n",
            "901: Renamed in 'MainSet14' â†’ 901.jpg\n",
            "902: Renamed in 'MainSet14' â†’ 902.jpg\n",
            "903: Renamed in 'MainSet14' â†’ 903.jpg\n",
            "904: Renamed in 'MainSet14' â†’ 904.jpg\n",
            "905: Renamed in 'MainSet14' â†’ 905.jpg\n",
            "906: Renamed in 'MainSet14' â†’ 906.jpg\n",
            "907: Renamed in 'MainSet14' â†’ 907.jpg\n",
            "908: Renamed in 'MainSet14' â†’ 908.jpg\n",
            "909: Renamed in 'MainSet14' â†’ 909.jpg\n",
            "910: Renamed in 'MainSet14' â†’ 910.jpg\n",
            "911: Renamed in 'MainSet14' â†’ 911.jpg\n",
            "912: Renamed in 'MainSet14' â†’ 912.jpg\n",
            "913: Renamed in 'MainSet14' â†’ 913.jpg\n",
            "914: Renamed in 'MainSet14' â†’ 914.jpg\n",
            "915: Renamed in 'MainSet14' â†’ 915.jpg\n",
            "916: Renamed in 'MainSet14' â†’ 916.jpg\n",
            "917: Renamed in 'MainSet14' â†’ 917.jpg\n",
            "918: Renamed in 'MainSet14' â†’ 918.jpg\n",
            "919: Renamed in 'MainSet14' â†’ 919.jpg\n",
            "920: Renamed in 'MainSet14' â†’ 920.jpg\n",
            "921: Renamed in 'MainSet14' â†’ 921.jpg\n",
            "922: Renamed in 'MainSet14' â†’ 922.jpg\n",
            "923: Renamed in 'MainSet14' â†’ 923.jpg\n",
            "924: Renamed in 'MainSet14' â†’ 924.jpg\n",
            "925: Renamed in 'MainSet14' â†’ 925.jpg\n",
            "926: Renamed in 'MainSet14' â†’ 926.jpg\n",
            "927: Renamed in 'MainSet14' â†’ 927.jpg\n",
            "928: Renamed in 'MainSet14' â†’ 928.jpg\n",
            "929: Renamed in 'MainSet14' â†’ 929.jpg\n",
            "930: Renamed in 'MainSet14' â†’ 930.jpg\n",
            "931: Renamed in 'MainSet14' â†’ 931.jpg\n",
            "932: Renamed in 'MainSet14' â†’ 932.jpg\n",
            "933: Renamed in 'MainSet14' â†’ 933.jpg\n",
            "934: Renamed in 'MainSet14' â†’ 934.jpg\n",
            "935: Renamed in 'MainSet14' â†’ 935.jpg\n",
            "936: Renamed in 'MainSet14' â†’ 936.jpg\n",
            "937: Renamed in 'MainSet14' â†’ 937.jpg\n",
            "938: Renamed in 'MainSet14' â†’ 938.jpg\n",
            "939: Renamed in 'MainSet14' â†’ 939.jpg\n",
            "940: Renamed in 'MainSet14' â†’ 940.jpg\n",
            "941: Renamed in 'MainSet14' â†’ 941.jpg\n",
            "942: Renamed in 'MainSet14' â†’ 942.jpg\n",
            "943: Renamed in 'MainSet14' â†’ 943.jpg\n",
            "944: Renamed in 'MainSet14' â†’ 944.jpg\n",
            "945: Renamed in 'MainSet14' â†’ 945.jpg\n",
            "946: Renamed in 'MainSet14' â†’ 946.jpg\n",
            "947: Renamed in 'MainSet14' â†’ 947.jpg\n",
            "948: Renamed in 'MainSet14' â†’ 948.jpg\n",
            "949: Renamed in 'MainSet14' â†’ 949.jpg\n",
            "950: Renamed in 'MainSet14' â†’ 950.jpg\n",
            "951: Renamed in 'MainSet14' â†’ 951.jpg\n",
            "952: Renamed in 'MainSet14' â†’ 952.jpg\n",
            "953: Renamed in 'MainSet14' â†’ 953.jpg\n",
            "954: Renamed in 'MainSet14' â†’ 954.jpg\n",
            "955: Renamed in 'MainSet14' â†’ 955.jpg\n",
            "956: Renamed in 'MainSet14' â†’ 956.jpg\n",
            "957: Renamed in 'MainSet14' â†’ 957.jpg\n",
            "958: Renamed in 'MainSet14' â†’ 958.jpg\n",
            "959: Renamed in 'MainSet14' â†’ 959.jpg\n",
            "960: Renamed in 'MainSet14' â†’ 960.jpg\n",
            "961: Renamed in 'MainSet14' â†’ 961.jpg\n",
            "962: Renamed in 'MainSet14' â†’ 962.jpg\n",
            "963: Renamed in 'MainSet14' â†’ 963.jpg\n",
            "964: Renamed in 'MainSet14' â†’ 964.jpg\n",
            "965: Renamed in 'MainSet14' â†’ 965.jpg\n",
            "966: Renamed in 'MainSet14' â†’ 966.jpg\n",
            "967: Renamed in 'MainSet14' â†’ 967.jpg\n",
            "968: Renamed in 'MainSet14' â†’ 968.jpg\n",
            "969: Renamed in 'MainSet14' â†’ 969.jpg\n",
            "970: Renamed in 'MainSet14' â†’ 970.jpg\n",
            "971: Renamed in 'MainSet14' â†’ 971.jpg\n",
            "972: Renamed in 'MainSet14' â†’ 972.jpg\n",
            "973: Renamed in 'MainSet14' â†’ 973.jpg\n",
            "974: Renamed in 'MainSet14' â†’ 974.jpg\n",
            "975: Renamed in 'MainSet14' â†’ 975.jpg\n",
            "976: Renamed in 'MainSet14' â†’ 976.jpg\n",
            "977: Renamed in 'MainSet14' â†’ 977.jpg\n",
            "978: Renamed in 'MainSet14' â†’ 978.jpg\n",
            "979: Renamed in 'MainSet14' â†’ 979.jpg\n",
            "980: Renamed in 'MainSet14' â†’ 980.jpg\n",
            "981: Renamed in 'MainSet14' â†’ 981.jpg\n",
            "982: Renamed in 'MainSet14' â†’ 982.jpg\n",
            "983: Renamed in 'MainSet14' â†’ 983.jpg\n",
            "984: Renamed in 'MainSet14' â†’ 984.jpg\n",
            "985: Renamed in 'MainSet14' â†’ 985.jpg\n",
            "986: Renamed in 'MainSet14' â†’ 986.jpg\n",
            "987: Renamed in 'MainSet14' â†’ 987.jpg\n",
            "988: Renamed in 'MainSet14' â†’ 988.jpg\n",
            "989: Renamed in 'MainSet14' â†’ 989.jpg\n",
            "990: Renamed in 'MainSet14' â†’ 990.jpg\n",
            "991: Renamed in 'MainSet14' â†’ 991.jpg\n",
            "992: Renamed in 'MainSet14' â†’ 992.jpg\n",
            "993: Renamed in 'MainSet14' â†’ 993.jpg\n",
            "994: Renamed in 'MainSet14' â†’ 994.jpg\n",
            "995: Renamed in 'MainSet14' â†’ 995.jpg\n",
            "996: Renamed in 'MainSet14' â†’ 996.jpg\n",
            "997: Renamed in 'MainSet14' â†’ 997.jpg\n",
            "998: Renamed in 'MainSet14' â†’ 998.jpg\n",
            "999: Renamed in 'MainSet14' â†’ 999.jpg\n",
            "1000: Renamed in 'MainSet14' â†’ 1000.jpg\n",
            "1001: Renamed in 'MainSet14' â†’ 1001.jpg\n",
            "1002: Renamed in 'MainSet14' â†’ 1002.jpg\n",
            "1003: Renamed in 'MainSet14' â†’ 1003.jpg\n",
            "1004: Renamed in 'MainSet14' â†’ 1004.jpg\n",
            "1005: Renamed in 'MainSet14' â†’ 1005.jpg\n",
            "1006: Renamed in 'MainSet14' â†’ 1006.jpg\n",
            "1007: Renamed in 'MainSet14' â†’ 1007.jpg\n",
            "1008: Renamed in 'MainSet14' â†’ 1008.jpg\n",
            "1009: Renamed in 'MainSet14' â†’ 1009.jpg\n",
            "1010: Renamed in 'MainSet14' â†’ 1010.jpg\n",
            "1011: Renamed in 'MainSet14' â†’ 1011.jpg\n",
            "1012: Renamed in 'MainSet14' â†’ 1012.jpg\n",
            "1013: Renamed in 'MainSet14' â†’ 1013.jpg\n",
            "1014: Renamed in 'MainSet14' â†’ 1014.jpg\n",
            "1015: Renamed in 'MainSet14' â†’ 1015.jpg\n",
            "1016: Renamed in 'MainSet14' â†’ 1016.jpg\n",
            "1017: Renamed in 'MainSet14' â†’ 1017.jpg\n",
            "1018: Renamed in 'MainSet14' â†’ 1018.jpg\n",
            "1019: Renamed in 'MainSet14' â†’ 1019.jpg\n",
            "1020: Renamed in 'MainSet14' â†’ 1020.jpg\n",
            "1021: Renamed in 'MainSet14' â†’ 1021.jpg\n",
            "1022: Renamed in 'MainSet14' â†’ 1022.jpg\n",
            "1023: Renamed in 'MainSet14' â†’ 1023.jpg\n",
            "1024: Renamed in 'MainSet14' â†’ 1024.jpg\n",
            "1025: Renamed in 'MainSet14' â†’ 1025.jpg\n",
            "1026: Renamed in 'MainSet14' â†’ 1026.jpg\n",
            "1027: Renamed in 'MainSet14' â†’ 1027.jpg\n",
            "1028: Renamed in 'MainSet14' â†’ 1028.jpg\n",
            "1029: Renamed in 'MainSet14' â†’ 1029.jpg\n",
            "1030: Renamed in 'MainSet14' â†’ 1030.jpg\n",
            "1031: Renamed in 'MainSet14' â†’ 1031.jpg\n",
            "1032: Renamed in 'MainSet14' â†’ 1032.jpg\n",
            "1033: Renamed in 'MainSet14' â†’ 1033.jpg\n",
            "1034: Renamed in 'MainSet14' â†’ 1034.jpg\n",
            "1035: Renamed in 'MainSet14' â†’ 1035.jpg\n",
            "1036: Renamed in 'MainSet14' â†’ 1036.jpg\n",
            "1037: Renamed in 'MainSet14' â†’ 1037.jpg\n",
            "1038: Renamed in 'MainSet14' â†’ 1038.jpg\n",
            "1039: Renamed in 'MainSet14' â†’ 1039.jpg\n",
            "1040: Renamed in 'MainSet14' â†’ 1040.jpg\n",
            "1041: Renamed in 'MainSet14' â†’ 1041.jpg\n",
            "1042: Renamed in 'MainSet14' â†’ 1042.jpg\n",
            "1043: Renamed in 'MainSet14' â†’ 1043.jpg\n",
            "1044: Renamed in 'MainSet14' â†’ 1044.jpg\n",
            "1045: Renamed in 'MainSet14' â†’ 1045.jpg\n",
            "1046: Renamed in 'MainSet14' â†’ 1046.jpg\n",
            "1047: Renamed in 'MainSet14' â†’ 1047.jpg\n",
            "1048: Renamed in 'MainSet14' â†’ 1048.jpg\n",
            "1049: Renamed in 'MainSet14' â†’ 1049.jpg\n",
            "1050: Renamed in 'MainSet14' â†’ 1050.jpg\n",
            "1051: Renamed in 'MainSet14' â†’ 1051.jpg\n",
            "1052: Renamed in 'MainSet14' â†’ 1052.jpg\n",
            "1053: Renamed in 'MainSet14' â†’ 1053.jpg\n",
            "1054: Renamed in 'MainSet14' â†’ 1054.jpg\n",
            "1055: Renamed in 'MainSet14' â†’ 1055.jpg\n",
            "1056: Renamed in 'MainSet14' â†’ 1056.jpg\n",
            "1057: Renamed in 'MainSet14' â†’ 1057.jpg\n",
            "1058: Renamed in 'MainSet2' â†’ 1058.jpg\n",
            "1059: Renamed in 'MainSet2' â†’ 1059.jpg\n",
            "1060: Renamed in 'MainSet2' â†’ 1060.jpg\n",
            "1061: Renamed in 'MainSet2' â†’ 1061.jpg\n",
            "1062: Renamed in 'MainSet2' â†’ 1062.jpg\n",
            "1063: Renamed in 'MainSet2' â†’ 1063.jpg\n",
            "1064: Renamed in 'MainSet2' â†’ 1064.jpg\n",
            "1065: Renamed in 'MainSet2' â†’ 1065.jpg\n",
            "1066: Renamed in 'MainSet2' â†’ 1066.jpg\n",
            "1067: Renamed in 'MainSet2' â†’ 1067.jpg\n",
            "1068: Renamed in 'MainSet2' â†’ 1068.jpg\n",
            "1069: Renamed in 'MainSet2' â†’ 1069.jpg\n",
            "1070: Renamed in 'MainSet2' â†’ 1070.jpg\n",
            "1071: Renamed in 'MainSet2' â†’ 1071.jpg\n",
            "1072: Renamed in 'MainSet2' â†’ 1072.jpg\n",
            "1073: Renamed in 'MainSet2' â†’ 1073.jpg\n",
            "1074: Renamed in 'MainSet2' â†’ 1074.jpg\n",
            "1075: Renamed in 'MainSet2' â†’ 1075.jpg\n",
            "1076: Renamed in 'MainSet2' â†’ 1076.jpg\n",
            "1077: Renamed in 'MainSet2' â†’ 1077.jpg\n",
            "1078: Renamed in 'MainSet2' â†’ 1078.jpg\n",
            "1079: Renamed in 'MainSet2' â†’ 1079.jpg\n",
            "1080: Renamed in 'MainSet2' â†’ 1080.jpg\n",
            "1081: Renamed in 'MainSet2' â†’ 1081.jpg\n",
            "1082: Renamed in 'MainSet2' â†’ 1082.jpg\n",
            "1083: Renamed in 'MainSet2' â†’ 1083.jpg\n",
            "1084: Renamed in 'MainSet2' â†’ 1084.jpg\n",
            "1085: Renamed in 'MainSet2' â†’ 1085.jpg\n",
            "1086: Renamed in 'MainSet2' â†’ 1086.jpg\n",
            "1087: Renamed in 'MainSet2' â†’ 1087.jpg\n",
            "1088: Renamed in 'MainSet2' â†’ 1088.jpg\n",
            "1089: Renamed in 'MainSet2' â†’ 1089.jpg\n",
            "1090: Renamed in 'MainSet2' â†’ 1090.jpg\n",
            "1091: Renamed in 'MainSet2' â†’ 1091.jpg\n",
            "1092: Renamed in 'MainSet2' â†’ 1092.jpg\n",
            "1093: Renamed in 'MainSet2' â†’ 1093.jpg\n",
            "1094: Renamed in 'MainSet2' â†’ 1094.jpg\n",
            "1095: Renamed in 'MainSet2' â†’ 1095.jpg\n",
            "1096: Renamed in 'MainSet2' â†’ 1096.jpg\n",
            "1097: Renamed in 'MainSet2' â†’ 1097.jpg\n",
            "1098: Renamed in 'MainSet2' â†’ 1098.jpg\n",
            "1099: Renamed in 'MainSet2' â†’ 1099.jpg\n",
            "1100: Renamed in 'MainSet2' â†’ 1100.jpg\n",
            "1101: Renamed in 'MainSet2' â†’ 1101.jpg\n",
            "1102: Renamed in 'MainSet2' â†’ 1102.jpg\n",
            "1103: Renamed in 'MainSet2' â†’ 1103.jpg\n",
            "1104: Renamed in 'MainSet2' â†’ 1104.jpg\n",
            "1105: Renamed in 'MainSet2' â†’ 1105.jpg\n",
            "1106: Renamed in 'MainSet2' â†’ 1106.jpg\n",
            "1107: Renamed in 'MainSet2' â†’ 1107.jpg\n",
            "1108: Renamed in 'MainSet2' â†’ 1108.jpg\n",
            "1109: Renamed in 'MainSet2' â†’ 1109.jpg\n",
            "1110: Renamed in 'MainSet2' â†’ 1110.jpg\n",
            "1111: Renamed in 'MainSet2' â†’ 1111.jpg\n",
            "1112: Renamed in 'MainSet2' â†’ 1112.jpg\n",
            "1113: Renamed in 'MainSet2' â†’ 1113.jpg\n",
            "1114: Renamed in 'MainSet2' â†’ 1114.jpg\n",
            "1115: Renamed in 'MainSet2' â†’ 1115.jpg\n",
            "1116: Renamed in 'MainSet2' â†’ 1116.jpg\n",
            "1117: Renamed in 'MainSet2' â†’ 1117.jpg\n",
            "1118: Renamed in 'MainSet2' â†’ 1118.jpg\n",
            "1119: Renamed in 'MainSet2' â†’ 1119.jpg\n",
            "1120: Renamed in 'MainSet2' â†’ 1120.jpg\n",
            "1121: Renamed in 'MainSet2' â†’ 1121.jpg\n",
            "1122: Renamed in 'MainSet2' â†’ 1122.jpg\n",
            "1123: Renamed in 'MainSet2' â†’ 1123.jpg\n",
            "1124: Renamed in 'MainSet2' â†’ 1124.jpg\n",
            "1125: Renamed in 'MainSet2' â†’ 1125.jpg\n",
            "1126: Renamed in 'MainSet2' â†’ 1126.jpg\n",
            "1127: Renamed in 'MainSet2' â†’ 1127.jpg\n",
            "1128: Renamed in 'MainSet2' â†’ 1128.jpg\n",
            "1129: Renamed in 'MainSet2' â†’ 1129.jpg\n",
            "1130: Renamed in 'MainSet2' â†’ 1130.jpg\n",
            "1131: Renamed in 'MainSet2' â†’ 1131.jpg\n",
            "1132: Renamed in 'MainSet2' â†’ 1132.jpg\n",
            "1133: Renamed in 'MainSet2' â†’ 1133.jpg\n",
            "1134: Renamed in 'MainSet2' â†’ 1134.jpg\n",
            "1135: Renamed in 'MainSet2' â†’ 1135.jpg\n",
            "1136: Renamed in 'MainSet2' â†’ 1136.jpg\n",
            "1137: Renamed in 'MainSet2' â†’ 1137.jpg\n",
            "1138: Renamed in 'MainSet2' â†’ 1138.jpg\n",
            "1139: Renamed in 'MainSet2' â†’ 1139.jpg\n",
            "1140: Renamed in 'MainSet2' â†’ 1140.jpg\n",
            "1141: Renamed in 'MainSet2' â†’ 1141.jpg\n",
            "1142: Renamed in 'MainSet2' â†’ 1142.jpg\n",
            "1143: Renamed in 'MainSet2' â†’ 1143.jpg\n",
            "1144: Renamed in 'MainSet2' â†’ 1144.jpg\n",
            "1145: Renamed in 'MainSet2' â†’ 1145.jpg\n",
            "1146: Renamed in 'MainSet2' â†’ 1146.jpg\n",
            "1147: Renamed in 'MainSet2' â†’ 1147.jpg\n",
            "1148: Renamed in 'MainSet2' â†’ 1148.jpg\n",
            "1149: Renamed in 'MainSet2' â†’ 1149.jpg\n",
            "1150: Renamed in 'MainSet2' â†’ 1150.jpg\n",
            "1151: Renamed in 'MainSet2' â†’ 1151.jpg\n",
            "1152: Renamed in 'MainSet2' â†’ 1152.jpg\n",
            "1153: Renamed in 'MainSet2' â†’ 1153.jpg\n",
            "1154: Renamed in 'MainSet2' â†’ 1154.jpg\n",
            "1155: Renamed in 'MainSet2' â†’ 1155.jpg\n",
            "1156: Renamed in 'MainSet2' â†’ 1156.jpg\n",
            "1157: Renamed in 'MainSet2' â†’ 1157.jpg\n",
            "1158: Renamed in 'MainSet2' â†’ 1158.jpg\n",
            "1159: Renamed in 'MainSet2' â†’ 1159.jpg\n",
            "1160: Renamed in 'MainSet2' â†’ 1160.jpg\n",
            "1161: Renamed in 'MainSet2' â†’ 1161.jpg\n",
            "1162: Renamed in 'MainSet2' â†’ 1162.jpg\n",
            "1163: Renamed in 'MainSet2' â†’ 1163.jpg\n",
            "1164: Renamed in 'MainSet2' â†’ 1164.jpg\n",
            "1165: Renamed in 'MainSet2' â†’ 1165.jpg\n",
            "1166: Renamed in 'MainSet2' â†’ 1166.jpg\n",
            "1167: Renamed in 'MainSet2' â†’ 1167.jpg\n",
            "1168: Renamed in 'MainSet2' â†’ 1168.jpg\n",
            "1169: Renamed in 'MainSet2' â†’ 1169.jpg\n",
            "1170: Renamed in 'MainSet2' â†’ 1170.jpg\n",
            "1171: Renamed in 'MainSet2' â†’ 1171.jpg\n",
            "1172: Renamed in 'MainSet2' â†’ 1172.jpg\n",
            "1173: Renamed in 'MainSet2' â†’ 1173.jpg\n",
            "1174: Renamed in 'MainSet2' â†’ 1174.jpg\n",
            "1175: Renamed in 'MainSet2' â†’ 1175.jpg\n",
            "1176: Renamed in 'MainSet2' â†’ 1176.jpg\n",
            "1177: Renamed in 'MainSet2' â†’ 1177.jpg\n",
            "1178: Renamed in 'MainSet2' â†’ 1178.jpg\n",
            "1179: Renamed in 'MainSet2' â†’ 1179.jpg\n",
            "1180: Renamed in 'MainSet2' â†’ 1180.jpg\n",
            "1181: Renamed in 'MainSet2' â†’ 1181.jpg\n",
            "1182: Renamed in 'MainSet2' â†’ 1182.jpg\n",
            "1183: Renamed in 'MainSet2' â†’ 1183.jpg\n",
            "1184: Renamed in 'MainSet2' â†’ 1184.jpg\n",
            "1185: Renamed in 'MainSet2' â†’ 1185.jpg\n",
            "1186: Renamed in 'MainSet2' â†’ 1186.jpg\n",
            "1187: Renamed in 'MainSet2' â†’ 1187.jpg\n",
            "1188: Renamed in 'MainSet2' â†’ 1188.jpg\n",
            "1189: Renamed in 'MainSet2' â†’ 1189.jpg\n",
            "1190: Renamed in 'MainSet2' â†’ 1190.jpg\n",
            "1191: Renamed in 'MainSet2' â†’ 1191.jpg\n",
            "1192: Renamed in 'MainSet2' â†’ 1192.jpg\n",
            "1193: Renamed in 'MainSet2' â†’ 1193.jpg\n",
            "1194: Renamed in 'MainSet2' â†’ 1194.jpg\n",
            "1195: Renamed in 'MainSet2' â†’ 1195.jpg\n",
            "1196: Renamed in 'MainSet2' â†’ 1196.jpg\n",
            "1197: Renamed in 'MainSet2' â†’ 1197.jpg\n",
            "1198: Renamed in 'MainSet2' â†’ 1198.jpg\n",
            "1199: Renamed in 'MainSet2' â†’ 1199.jpg\n",
            "1200: Renamed in 'MainSet2' â†’ 1200.jpg\n",
            "1201: Renamed in 'MainSet2' â†’ 1201.jpg\n",
            "1202: Renamed in 'MainSet2' â†’ 1202.jpg\n",
            "1203: Renamed in 'MainSet2' â†’ 1203.jpg\n",
            "1204: Renamed in 'MainSet2' â†’ 1204.jpg\n",
            "1205: Renamed in 'MainSet2' â†’ 1205.jpg\n",
            "1206: Renamed in 'MainSet2' â†’ 1206.jpg\n",
            "1207: Renamed in 'MainSet2' â†’ 1207.jpg\n",
            "1208: Renamed in 'MainSet2' â†’ 1208.jpg\n",
            "1209: Renamed in 'MainSet2' â†’ 1209.jpg\n",
            "1210: Renamed in 'MainSet2' â†’ 1210.jpg\n",
            "1211: Renamed in 'MainSet2' â†’ 1211.jpg\n",
            "1212: Renamed in 'MainSet2' â†’ 1212.jpg\n",
            "1213: Renamed in 'MainSet2' â†’ 1213.jpg\n",
            "1214: Renamed in 'MainSet2' â†’ 1214.jpg\n",
            "1215: Renamed in 'MainSet2' â†’ 1215.jpg\n",
            "1216: Renamed in 'MainSet2' â†’ 1216.jpg\n",
            "1217: Renamed in 'MainSet2' â†’ 1217.jpg\n",
            "1218: Renamed in 'MainSet2' â†’ 1218.jpg\n",
            "1219: Renamed in 'MainSet2' â†’ 1219.jpg\n",
            "1220: Renamed in 'MainSet2' â†’ 1220.jpg\n",
            "1221: Renamed in 'MainSet2' â†’ 1221.jpg\n",
            "1222: Renamed in 'MainSet2' â†’ 1222.jpg\n",
            "1223: Renamed in 'MainSet2' â†’ 1223.jpg\n",
            "1224: Renamed in 'MainSet2' â†’ 1224.jpg\n",
            "1225: Renamed in 'MainSet2' â†’ 1225.jpg\n",
            "1226: Renamed in 'MainSet2' â†’ 1226.jpg\n",
            "1227: Renamed in 'MainSet2' â†’ 1227.jpg\n",
            "1228: Renamed in 'MainSet2' â†’ 1228.jpg\n",
            "1229: Renamed in 'MainSet2' â†’ 1229.jpg\n",
            "1230: Renamed in 'MainSet2' â†’ 1230.jpg\n",
            "1231: Renamed in 'MainSet2' â†’ 1231.jpg\n",
            "1232: Renamed in 'MainSet2' â†’ 1232.jpg\n",
            "1233: Renamed in 'MainSet2' â†’ 1233.jpg\n",
            "1234: Renamed in 'MainSet2' â†’ 1234.jpg\n",
            "1235: Renamed in 'MainSet2' â†’ 1235.jpg\n",
            "1236: Renamed in 'MainSet2' â†’ 1236.jpg\n",
            "1237: Renamed in 'MainSet2' â†’ 1237.jpg\n",
            "1238: Renamed in 'MainSet2' â†’ 1238.jpg\n",
            "1239: Renamed in 'MainSet2' â†’ 1239.jpg\n",
            "1240: Renamed in 'MainSet2' â†’ 1240.jpg\n",
            "1241: Renamed in 'MainSet2' â†’ 1241.jpg\n",
            "1242: Renamed in 'MainSet3' â†’ 1242.jpg\n",
            "1243: Renamed in 'MainSet3' â†’ 1243.jpg\n",
            "1244: Renamed in 'MainSet3' â†’ 1244.jpg\n",
            "1245: Renamed in 'MainSet3' â†’ 1245.jpg\n",
            "1246: Renamed in 'MainSet3' â†’ 1246.jpg\n",
            "1247: Renamed in 'MainSet3' â†’ 1247.jpg\n",
            "1248: Renamed in 'MainSet3' â†’ 1248.jpg\n",
            "1249: Renamed in 'MainSet3' â†’ 1249.jpg\n",
            "1250: Renamed in 'MainSet3' â†’ 1250.jpg\n",
            "1251: Renamed in 'MainSet3' â†’ 1251.jpg\n",
            "1252: Renamed in 'MainSet3' â†’ 1252.jpg\n",
            "1253: Renamed in 'MainSet3' â†’ 1253.jpg\n",
            "1254: Renamed in 'MainSet3' â†’ 1254.jpg\n",
            "1255: Renamed in 'MainSet3' â†’ 1255.jpg\n",
            "1256: Renamed in 'MainSet3' â†’ 1256.jpg\n",
            "1257: Renamed in 'MainSet3' â†’ 1257.jpg\n",
            "1258: Renamed in 'MainSet3' â†’ 1258.jpg\n",
            "1259: Renamed in 'MainSet3' â†’ 1259.jpg\n",
            "1260: Renamed in 'MainSet3' â†’ 1260.jpg\n",
            "1261: Renamed in 'MainSet3' â†’ 1261.jpg\n",
            "1262: Renamed in 'MainSet3' â†’ 1262.jpg\n",
            "1263: Renamed in 'MainSet3' â†’ 1263.jpg\n",
            "1264: Renamed in 'MainSet3' â†’ 1264.jpg\n",
            "1265: Renamed in 'MainSet3' â†’ 1265.jpg\n",
            "1266: Renamed in 'MainSet3' â†’ 1266.jpg\n",
            "1267: Renamed in 'MainSet3' â†’ 1267.jpg\n",
            "1268: Renamed in 'MainSet3' â†’ 1268.jpg\n",
            "1269: Renamed in 'MainSet3' â†’ 1269.jpg\n",
            "1270: Renamed in 'MainSet3' â†’ 1270.jpg\n",
            "1271: Renamed in 'MainSet3' â†’ 1271.jpg\n",
            "1272: Renamed in 'MainSet3' â†’ 1272.jpg\n",
            "1273: Renamed in 'MainSet3' â†’ 1273.jpg\n",
            "1274: Renamed in 'MainSet3' â†’ 1274.jpg\n",
            "1275: Renamed in 'MainSet3' â†’ 1275.jpg\n",
            "1276: Renamed in 'MainSet3' â†’ 1276.jpg\n",
            "1277: Renamed in 'MainSet3' â†’ 1277.jpg\n",
            "1278: Renamed in 'MainSet3' â†’ 1278.jpg\n",
            "1279: Renamed in 'MainSet3' â†’ 1279.jpg\n",
            "1280: Renamed in 'MainSet3' â†’ 1280.jpg\n",
            "1281: Renamed in 'MainSet3' â†’ 1281.jpg\n",
            "1282: Renamed in 'MainSet3' â†’ 1282.jpg\n",
            "1283: Renamed in 'MainSet3' â†’ 1283.jpg\n",
            "1284: Renamed in 'MainSet3' â†’ 1284.jpg\n",
            "1285: Renamed in 'MainSet3' â†’ 1285.jpg\n",
            "1286: Renamed in 'MainSet3' â†’ 1286.jpg\n",
            "1287: Renamed in 'MainSet3' â†’ 1287.jpg\n",
            "1288: Renamed in 'MainSet3' â†’ 1288.jpg\n",
            "1289: Renamed in 'MainSet3' â†’ 1289.jpg\n",
            "1290: Renamed in 'MainSet3' â†’ 1290.jpg\n",
            "1291: Renamed in 'MainSet3' â†’ 1291.jpg\n",
            "1292: Renamed in 'MainSet3' â†’ 1292.jpg\n",
            "1293: Renamed in 'MainSet3' â†’ 1293.jpg\n",
            "1294: Renamed in 'MainSet3' â†’ 1294.jpg\n",
            "1295: Renamed in 'MainSet3' â†’ 1295.jpg\n",
            "1296: Renamed in 'MainSet3' â†’ 1296.jpg\n",
            "1297: Renamed in 'MainSet3' â†’ 1297.jpg\n",
            "1298: Renamed in 'MainSet3' â†’ 1298.jpg\n",
            "1299: Renamed in 'MainSet3' â†’ 1299.jpg\n",
            "1300: Renamed in 'MainSet3' â†’ 1300.jpg\n",
            "1301: Renamed in 'MainSet3' â†’ 1301.jpg\n",
            "1302: Renamed in 'MainSet3' â†’ 1302.jpg\n",
            "1303: Renamed in 'MainSet3' â†’ 1303.jpg\n",
            "1304: Renamed in 'MainSet3' â†’ 1304.jpg\n",
            "1305: Renamed in 'MainSet3' â†’ 1305.jpg\n",
            "1306: Renamed in 'MainSet3' â†’ 1306.jpg\n",
            "1307: Renamed in 'MainSet3' â†’ 1307.jpg\n",
            "1308: Renamed in 'MainSet3' â†’ 1308.jpg\n",
            "1309: Renamed in 'MainSet3' â†’ 1309.jpg\n",
            "1310: Renamed in 'MainSet3' â†’ 1310.jpg\n",
            "1311: Renamed in 'MainSet3' â†’ 1311.jpg\n",
            "1312: Renamed in 'MainSet3' â†’ 1312.jpg\n",
            "1313: Renamed in 'MainSet3' â†’ 1313.jpg\n",
            "1314: Renamed in 'MainSet3' â†’ 1314.jpg\n",
            "1315: Renamed in 'MainSet3' â†’ 1315.jpg\n",
            "1316: Renamed in 'MainSet3' â†’ 1316.jpg\n",
            "1317: Renamed in 'MainSet3' â†’ 1317.jpg\n",
            "1318: Renamed in 'MainSet3' â†’ 1318.jpg\n",
            "1319: Renamed in 'MainSet4' â†’ 1319.jpg\n",
            "1320: Renamed in 'MainSet4' â†’ 1320.jpg\n",
            "1321: Renamed in 'MainSet4' â†’ 1321.jpg\n",
            "1322: Renamed in 'MainSet4' â†’ 1322.jpg\n",
            "1323: Renamed in 'MainSet4' â†’ 1323.jpg\n",
            "1324: Renamed in 'MainSet4' â†’ 1324.jpg\n",
            "1325: Renamed in 'MainSet4' â†’ 1325.jpg\n",
            "1326: Renamed in 'MainSet4' â†’ 1326.jpg\n",
            "1327: Renamed in 'MainSet4' â†’ 1327.jpg\n",
            "1328: Renamed in 'MainSet4' â†’ 1328.jpg\n",
            "1329: Renamed in 'MainSet4' â†’ 1329.jpg\n",
            "1330: Renamed in 'MainSet4' â†’ 1330.jpg\n",
            "1331: Renamed in 'MainSet4' â†’ 1331.jpg\n",
            "1332: Renamed in 'MainSet4' â†’ 1332.jpg\n",
            "1333: Renamed in 'MainSet4' â†’ 1333.jpg\n",
            "1334: Renamed in 'MainSet4' â†’ 1334.jpg\n",
            "1335: Renamed in 'MainSet4' â†’ 1335.jpg\n",
            "1336: Renamed in 'MainSet4' â†’ 1336.jpg\n",
            "1337: Renamed in 'MainSet4' â†’ 1337.jpg\n",
            "1338: Renamed in 'MainSet4' â†’ 1338.jpg\n",
            "1339: Renamed in 'MainSet4' â†’ 1339.jpg\n",
            "1340: Renamed in 'MainSet4' â†’ 1340.jpg\n",
            "1341: Renamed in 'MainSet4' â†’ 1341.jpg\n",
            "1342: Renamed in 'MainSet4' â†’ 1342.jpg\n",
            "1343: Renamed in 'MainSet4' â†’ 1343.jpg\n",
            "1344: Renamed in 'MainSet4' â†’ 1344.jpg\n",
            "1345: Renamed in 'MainSet4' â†’ 1345.jpg\n",
            "1346: Renamed in 'MainSet4' â†’ 1346.jpg\n",
            "1347: Renamed in 'MainSet4' â†’ 1347.jpg\n",
            "1348: Renamed in 'MainSet4' â†’ 1348.jpg\n",
            "1349: Renamed in 'MainSet4' â†’ 1349.jpg\n",
            "1350: Renamed in 'MainSet4' â†’ 1350.jpg\n",
            "1351: Renamed in 'MainSet4' â†’ 1351.jpg\n",
            "1352: Renamed in 'MainSet4' â†’ 1352.jpg\n",
            "1353: Renamed in 'MainSet4' â†’ 1353.jpg\n",
            "1354: Renamed in 'MainSet4' â†’ 1354.jpg\n",
            "1355: Renamed in 'MainSet4' â†’ 1355.jpg\n",
            "1356: Renamed in 'MainSet4' â†’ 1356.jpg\n",
            "1357: Renamed in 'MainSet4' â†’ 1357.jpg\n",
            "1358: Renamed in 'MainSet4' â†’ 1358.jpg\n",
            "1359: Renamed in 'MainSet4' â†’ 1359.jpg\n",
            "1360: Renamed in 'MainSet4' â†’ 1360.jpg\n",
            "1361: Renamed in 'MainSet4' â†’ 1361.jpg\n",
            "1362: Renamed in 'MainSet4' â†’ 1362.jpg\n",
            "1363: Renamed in 'MainSet4' â†’ 1363.jpg\n",
            "1364: Renamed in 'MainSet4' â†’ 1364.jpg\n",
            "1365: Renamed in 'MainSet4' â†’ 1365.jpg\n",
            "1366: Renamed in 'MainSet4' â†’ 1366.jpg\n",
            "1367: Renamed in 'MainSet4' â†’ 1367.jpg\n",
            "1368: Renamed in 'MainSet4' â†’ 1368.jpg\n",
            "1369: Renamed in 'MainSet4' â†’ 1369.jpg\n",
            "1370: Renamed in 'MainSet4' â†’ 1370.jpg\n",
            "1371: Renamed in 'MainSet4' â†’ 1371.jpg\n",
            "1372: Renamed in 'MainSet4' â†’ 1372.jpg\n",
            "1373: Renamed in 'MainSet4' â†’ 1373.jpg\n",
            "1374: Renamed in 'MainSet4' â†’ 1374.jpg\n",
            "1375: Renamed in 'MainSet4' â†’ 1375.jpg\n",
            "1376: Renamed in 'MainSet4' â†’ 1376.jpg\n",
            "1377: Renamed in 'MainSet4' â†’ 1377.jpg\n",
            "1378: Renamed in 'MainSet4' â†’ 1378.jpg\n",
            "1379: Renamed in 'MainSet4' â†’ 1379.jpg\n",
            "1380: Renamed in 'MainSet4' â†’ 1380.jpg\n",
            "1381: Renamed in 'MainSet4' â†’ 1381.jpg\n",
            "1382: Renamed in 'MainSet4' â†’ 1382.jpg\n",
            "1383: Renamed in 'MainSet4' â†’ 1383.jpg\n",
            "1384: Renamed in 'MainSet4' â†’ 1384.jpg\n",
            "1385: Renamed in 'MainSet4' â†’ 1385.jpg\n",
            "1386: Renamed in 'MainSet4' â†’ 1386.jpg\n",
            "1387: Renamed in 'MainSet4' â†’ 1387.jpg\n",
            "1388: Renamed in 'MainSet4' â†’ 1388.jpg\n",
            "1389: Renamed in 'MainSet4' â†’ 1389.jpg\n",
            "1390: Renamed in 'MainSet4' â†’ 1390.jpg\n",
            "1391: Renamed in 'MainSet4' â†’ 1391.jpg\n",
            "1392: Renamed in 'MainSet4' â†’ 1392.jpg\n",
            "1393: Renamed in 'MainSet4' â†’ 1393.jpg\n",
            "1394: Renamed in 'MainSet4' â†’ 1394.jpg\n",
            "1395: Renamed in 'MainSet4' â†’ 1395.jpg\n",
            "1396: Renamed in 'MainSet4' â†’ 1396.jpg\n",
            "1397: Renamed in 'MainSet4' â†’ 1397.jpg\n",
            "1398: Renamed in 'MainSet4' â†’ 1398.jpg\n",
            "1399: Renamed in 'MainSet4' â†’ 1399.jpg\n",
            "1400: Renamed in 'MainSet4' â†’ 1400.jpg\n",
            "1401: Renamed in 'MainSet4' â†’ 1401.jpg\n",
            "1402: Renamed in 'MainSet4' â†’ 1402.jpg\n",
            "1403: Renamed in 'MainSet4' â†’ 1403.jpg\n",
            "1404: Renamed in 'MainSet4' â†’ 1404.jpg\n",
            "1405: Renamed in 'MainSet4' â†’ 1405.jpg\n",
            "1406: Renamed in 'MainSet4' â†’ 1406.jpg\n",
            "1407: Renamed in 'MainSet4' â†’ 1407.jpg\n",
            "1408: Renamed in 'MainSet4' â†’ 1408.jpg\n",
            "1409: Renamed in 'MainSet4' â†’ 1409.jpg\n",
            "1410: Renamed in 'MainSet4' â†’ 1410.jpg\n",
            "1411: Renamed in 'MainSet4' â†’ 1411.jpg\n",
            "1412: Renamed in 'MainSet4' â†’ 1412.jpg\n",
            "1413: Renamed in 'MainSet4' â†’ 1413.jpg\n",
            "1414: Renamed in 'MainSet4' â†’ 1414.jpg\n",
            "1415: Renamed in 'MainSet4' â†’ 1415.jpg\n",
            "1416: Renamed in 'MainSet4' â†’ 1416.jpg\n",
            "1417: Renamed in 'MainSet4' â†’ 1417.jpg\n",
            "1418: Renamed in 'MainSet4' â†’ 1418.jpg\n",
            "1419: Renamed in 'MainSet4' â†’ 1419.jpg\n",
            "1420: Renamed in 'MainSet4' â†’ 1420.jpg\n",
            "1421: Renamed in 'MainSet4' â†’ 1421.jpg\n",
            "1422: Renamed in 'MainSet4' â†’ 1422.jpg\n",
            "1423: Renamed in 'MainSet4' â†’ 1423.jpg\n",
            "1424: Renamed in 'MainSet4' â†’ 1424.jpg\n",
            "1425: Renamed in 'MainSet4' â†’ 1425.jpg\n",
            "1426: Renamed in 'MainSet4' â†’ 1426.jpg\n",
            "1427: Renamed in 'MainSet4' â†’ 1427.jpg\n",
            "1428: Renamed in 'MainSet4' â†’ 1428.jpg\n",
            "1429: Renamed in 'MainSet4' â†’ 1429.jpg\n",
            "1430: Renamed in 'MainSet4' â†’ 1430.jpg\n",
            "1431: Renamed in 'MainSet4' â†’ 1431.jpg\n",
            "1432: Renamed in 'MainSet4' â†’ 1432.jpg\n",
            "1433: Renamed in 'MainSet4' â†’ 1433.jpg\n",
            "1434: Renamed in 'MainSet4' â†’ 1434.jpg\n",
            "1435: Renamed in 'MainSet4' â†’ 1435.jpg\n",
            "1436: Renamed in 'MainSet4' â†’ 1436.jpg\n",
            "1437: Renamed in 'MainSet4' â†’ 1437.jpg\n",
            "1438: Renamed in 'MainSet4' â†’ 1438.jpg\n",
            "1439: Renamed in 'MainSet5' â†’ 1439.jpg\n",
            "1440: Renamed in 'MainSet5' â†’ 1440.jpg\n",
            "1441: Renamed in 'MainSet5' â†’ 1441.jpg\n",
            "1442: Renamed in 'MainSet5' â†’ 1442.jpg\n",
            "1443: Renamed in 'MainSet5' â†’ 1443.jpg\n",
            "1444: Renamed in 'MainSet5' â†’ 1444.jpg\n",
            "1445: Renamed in 'MainSet5' â†’ 1445.jpg\n",
            "1446: Renamed in 'MainSet5' â†’ 1446.jpg\n",
            "1447: Renamed in 'MainSet5' â†’ 1447.jpg\n",
            "1448: Renamed in 'MainSet5' â†’ 1448.jpg\n",
            "1449: Renamed in 'MainSet5' â†’ 1449.jpg\n",
            "1450: Renamed in 'MainSet5' â†’ 1450.jpg\n",
            "1451: Renamed in 'MainSet5' â†’ 1451.jpg\n",
            "1452: Renamed in 'MainSet5' â†’ 1452.jpg\n",
            "1453: Renamed in 'MainSet5' â†’ 1453.jpg\n",
            "1454: Renamed in 'MainSet5' â†’ 1454.jpg\n",
            "1455: Renamed in 'MainSet6' â†’ 1455.jpg\n",
            "1456: Renamed in 'MainSet6' â†’ 1456.jpg\n",
            "1457: Renamed in 'MainSet6' â†’ 1457.jpg\n",
            "1458: Renamed in 'MainSet6' â†’ 1458.jpg\n",
            "1459: Renamed in 'MainSet6' â†’ 1459.jpg\n",
            "1460: Renamed in 'MainSet6' â†’ 1460.jpg\n",
            "1461: Renamed in 'MainSet6' â†’ 1461.jpg\n",
            "1462: Renamed in 'MainSet6' â†’ 1462.jpg\n",
            "1463: Renamed in 'MainSet7' â†’ 1463.jpg\n",
            "1464: Renamed in 'MainSet7' â†’ 1464.jpg\n",
            "1465: Renamed in 'MainSet7' â†’ 1465.jpg\n",
            "1466: Renamed in 'MainSet7' â†’ 1466.jpg\n",
            "1467: Renamed in 'MainSet7' â†’ 1467.jpg\n",
            "1468: Renamed in 'MainSet7' â†’ 1468.jpg\n",
            "1469: Renamed in 'MainSet7' â†’ 1469.jpg\n",
            "1470: Renamed in 'MainSet7' â†’ 1470.jpg\n",
            "1471: Renamed in 'MainSet7' â†’ 1471.jpg\n",
            "1472: Renamed in 'MainSet7' â†’ 1472.jpg\n",
            "1473: Renamed in 'MainSet7' â†’ 1473.jpg\n",
            "1474: Renamed in 'MainSet7' â†’ 1474.jpg\n",
            "1475: Renamed in 'MainSet7' â†’ 1475.jpg\n",
            "1476: Renamed in 'MainSet7' â†’ 1476.jpg\n",
            "1477: Renamed in 'MainSet7' â†’ 1477.jpg\n",
            "1478: Renamed in 'MainSet7' â†’ 1478.jpg\n",
            "1479: Renamed in 'MainSet7' â†’ 1479.jpg\n",
            "1480: Renamed in 'MainSet7' â†’ 1480.jpg\n",
            "1481: Renamed in 'MainSet7' â†’ 1481.jpg\n",
            "1482: Renamed in 'MainSet7' â†’ 1482.jpg\n",
            "1483: Renamed in 'MainSet7' â†’ 1483.jpg\n",
            "1484: Renamed in 'MainSet7' â†’ 1484.jpg\n",
            "1485: Renamed in 'MainSet7' â†’ 1485.jpg\n",
            "1486: Renamed in 'MainSet7' â†’ 1486.jpg\n",
            "1487: Renamed in 'MainSet7' â†’ 1487.jpg\n",
            "1488: Renamed in 'MainSet7' â†’ 1488.jpg\n",
            "1489: Renamed in 'MainSet7' â†’ 1489.jpg\n",
            "1490: Renamed in 'MainSet7' â†’ 1490.jpg\n",
            "1491: Renamed in 'MainSet7' â†’ 1491.jpg\n",
            "1492: Renamed in 'MainSet7' â†’ 1492.jpg\n",
            "1493: Renamed in 'MainSet7' â†’ 1493.jpg\n",
            "1494: Renamed in 'MainSet7' â†’ 1494.jpg\n",
            "1495: Renamed in 'MainSet7' â†’ 1495.jpg\n",
            "1496: Renamed in 'MainSet7' â†’ 1496.jpg\n",
            "1497: Renamed in 'MainSet7' â†’ 1497.jpg\n",
            "1498: Renamed in 'MainSet7' â†’ 1498.jpg\n",
            "1499: Renamed in 'MainSet7' â†’ 1499.jpg\n",
            "1500: Renamed in 'MainSet7' â†’ 1500.jpg\n",
            "1501: Renamed in 'MainSet7' â†’ 1501.jpg\n",
            "1502: Renamed in 'MainSet7' â†’ 1502.jpg\n",
            "1503: Renamed in 'MainSet7' â†’ 1503.jpg\n",
            "1504: Renamed in 'MainSet7' â†’ 1504.jpg\n",
            "1505: Renamed in 'MainSet7' â†’ 1505.jpg\n",
            "1506: Renamed in 'MainSet7' â†’ 1506.jpg\n",
            "1507: Renamed in 'MainSet7' â†’ 1507.jpg\n",
            "1508: Renamed in 'MainSet7' â†’ 1508.jpg\n",
            "1509: Renamed in 'MainSet7' â†’ 1509.jpg\n",
            "1510: Renamed in 'MainSet7' â†’ 1510.jpg\n",
            "1511: Renamed in 'MainSet7' â†’ 1511.jpg\n",
            "1512: Renamed in 'MainSet7' â†’ 1512.jpg\n",
            "1513: Renamed in 'MainSet7' â†’ 1513.jpg\n",
            "1514: Renamed in 'MainSet7' â†’ 1514.jpg\n",
            "1515: Renamed in 'MainSet7' â†’ 1515.jpg\n",
            "1516: Renamed in 'MainSet7' â†’ 1516.jpg\n",
            "1517: Renamed in 'MainSet7' â†’ 1517.jpg\n",
            "1518: Renamed in 'MainSet7' â†’ 1518.jpg\n",
            "1519: Renamed in 'MainSet7' â†’ 1519.jpg\n",
            "1520: Renamed in 'MainSet7' â†’ 1520.jpg\n",
            "1521: Renamed in 'MainSet7' â†’ 1521.jpg\n",
            "1522: Renamed in 'MainSet7' â†’ 1522.jpg\n",
            "1523: Renamed in 'MainSet7' â†’ 1523.jpg\n",
            "1524: Renamed in 'MainSet7' â†’ 1524.jpg\n",
            "1525: Renamed in 'MainSet7' â†’ 1525.jpg\n",
            "1526: Renamed in 'MainSet7' â†’ 1526.jpg\n",
            "1527: Renamed in 'MainSet7' â†’ 1527.jpg\n",
            "1528: Renamed in 'MainSet7' â†’ 1528.jpg\n",
            "1529: Renamed in 'MainSet7' â†’ 1529.jpg\n",
            "1530: Renamed in 'MainSet7' â†’ 1530.jpg\n",
            "1531: Renamed in 'MainSet7' â†’ 1531.jpg\n",
            "1532: Renamed in 'MainSet7' â†’ 1532.jpg\n",
            "1533: Renamed in 'MainSet7' â†’ 1533.jpg\n",
            "1534: Renamed in 'MainSet7' â†’ 1534.jpg\n",
            "1535: Renamed in 'MainSet7' â†’ 1535.jpg\n",
            "1536: Renamed in 'MainSet7' â†’ 1536.jpg\n",
            "1537: Renamed in 'MainSet7' â†’ 1537.jpg\n",
            "1538: Renamed in 'MainSet7' â†’ 1538.jpg\n",
            "1539: Renamed in 'MainSet7' â†’ 1539.jpg\n",
            "1540: Renamed in 'MainSet7' â†’ 1540.jpg\n",
            "1541: Renamed in 'MainSet7' â†’ 1541.jpg\n",
            "1542: Renamed in 'MainSet7' â†’ 1542.jpg\n",
            "1543: Renamed in 'MainSet7' â†’ 1543.jpg\n",
            "1544: Renamed in 'MainSet7' â†’ 1544.jpg\n",
            "1545: Renamed in 'MainSet7' â†’ 1545.jpg\n",
            "1546: Renamed in 'MainSet7' â†’ 1546.jpg\n",
            "1547: Renamed in 'MainSet7' â†’ 1547.jpg\n",
            "1548: Renamed in 'MainSet7' â†’ 1548.jpg\n",
            "1549: Renamed in 'MainSet7' â†’ 1549.jpg\n",
            "1550: Renamed in 'MainSet7' â†’ 1550.jpg\n",
            "1551: Renamed in 'MainSet7' â†’ 1551.jpg\n",
            "1552: Renamed in 'MainSet7' â†’ 1552.jpg\n",
            "1553: Renamed in 'MainSet7' â†’ 1553.jpg\n",
            "1554: Renamed in 'MainSet7' â†’ 1554.jpg\n",
            "1555: Renamed in 'MainSet7' â†’ 1555.jpg\n",
            "1556: Renamed in 'MainSet7' â†’ 1556.jpg\n",
            "1557: Renamed in 'MainSet7' â†’ 1557.jpg\n",
            "1558: Renamed in 'MainSet7' â†’ 1558.jpg\n",
            "1559: Renamed in 'MainSet7' â†’ 1559.jpg\n",
            "1560: Renamed in 'MainSet7' â†’ 1560.jpg\n",
            "1561: Renamed in 'MainSet7' â†’ 1561.jpg\n",
            "1562: Renamed in 'MainSet7' â†’ 1562.jpg\n",
            "1563: Renamed in 'MainSet7' â†’ 1563.jpg\n",
            "1564: Renamed in 'MainSet7' â†’ 1564.jpg\n",
            "1565: Renamed in 'MainSet7' â†’ 1565.jpg\n",
            "1566: Renamed in 'MainSet7' â†’ 1566.jpg\n",
            "1567: Renamed in 'MainSet7' â†’ 1567.jpg\n",
            "1568: Renamed in 'MainSet7' â†’ 1568.jpg\n",
            "1569: Renamed in 'MainSet7' â†’ 1569.jpg\n",
            "1570: Renamed in 'MainSet7' â†’ 1570.jpg\n",
            "1571: Renamed in 'MainSet7' â†’ 1571.jpg\n",
            "1572: Renamed in 'MainSet7' â†’ 1572.jpg\n",
            "1573: Renamed in 'MainSet7' â†’ 1573.jpg\n",
            "1574: Renamed in 'MainSet7' â†’ 1574.jpg\n",
            "1575: Renamed in 'MainSet7' â†’ 1575.jpg\n",
            "1576: Renamed in 'MainSet7' â†’ 1576.jpg\n",
            "1577: Renamed in 'MainSet7' â†’ 1577.jpg\n",
            "1578: Renamed in 'MainSet7' â†’ 1578.jpg\n",
            "1579: Renamed in 'MainSet7' â†’ 1579.jpg\n",
            "1580: Renamed in 'MainSet7' â†’ 1580.jpg\n",
            "1581: Renamed in 'MainSet7' â†’ 1581.jpg\n",
            "1582: Renamed in 'MainSet7' â†’ 1582.jpg\n",
            "1583: Renamed in 'MainSet7' â†’ 1583.jpg\n",
            "1584: Renamed in 'MainSet7' â†’ 1584.jpg\n",
            "1585: Renamed in 'MainSet7' â†’ 1585.jpg\n",
            "1586: Renamed in 'MainSet7' â†’ 1586.jpg\n",
            "1587: Renamed in 'MainSet7' â†’ 1587.jpg\n",
            "1588: Renamed in 'MainSet7' â†’ 1588.jpg\n",
            "1589: Renamed in 'MainSet7' â†’ 1589.jpg\n",
            "1590: Renamed in 'MainSet7' â†’ 1590.jpg\n",
            "1591: Renamed in 'MainSet7' â†’ 1591.jpg\n",
            "1592: Renamed in 'MainSet7' â†’ 1592.jpg\n",
            "1593: Renamed in 'MainSet7' â†’ 1593.jpg\n",
            "1594: Renamed in 'MainSet7' â†’ 1594.jpg\n",
            "1595: Renamed in 'MainSet7' â†’ 1595.jpg\n",
            "1596: Renamed in 'MainSet7' â†’ 1596.jpg\n",
            "1597: Renamed in 'MainSet7' â†’ 1597.jpg\n",
            "1598: Renamed in 'MainSet7' â†’ 1598.jpg\n",
            "1599: Renamed in 'MainSet7' â†’ 1599.jpg\n",
            "1600: Renamed in 'MainSet7' â†’ 1600.jpg\n",
            "1601: Renamed in 'MainSet7' â†’ 1601.jpg\n",
            "1602: Renamed in 'MainSet7' â†’ 1602.jpg\n",
            "1603: Renamed in 'MainSet7' â†’ 1603.jpg\n",
            "1604: Renamed in 'MainSet7' â†’ 1604.jpg\n",
            "1605: Renamed in 'MainSet7' â†’ 1605.jpg\n",
            "1606: Renamed in 'MainSet7' â†’ 1606.jpg\n",
            "1607: Renamed in 'MainSet7' â†’ 1607.jpg\n",
            "1608: Renamed in 'MainSet7' â†’ 1608.jpg\n",
            "1609: Renamed in 'MainSet7' â†’ 1609.jpg\n",
            "1610: Renamed in 'MainSet7' â†’ 1610.jpg\n",
            "1611: Renamed in 'MainSet7' â†’ 1611.jpg\n",
            "1612: Renamed in 'MainSet7' â†’ 1612.jpg\n",
            "1613: Renamed in 'MainSet7' â†’ 1613.jpg\n",
            "1614: Renamed in 'MainSet7' â†’ 1614.jpg\n",
            "1615: Renamed in 'MainSet7' â†’ 1615.jpg\n",
            "1616: Renamed in 'MainSet7' â†’ 1616.jpg\n",
            "1617: Renamed in 'MainSet7' â†’ 1617.jpg\n",
            "1618: Renamed in 'MainSet7' â†’ 1618.jpg\n",
            "1619: Renamed in 'MainSet7' â†’ 1619.jpg\n",
            "1620: Renamed in 'MainSet7' â†’ 1620.jpg\n",
            "1621: Renamed in 'MainSet7' â†’ 1621.jpg\n",
            "1622: Renamed in 'MainSet7' â†’ 1622.jpg\n",
            "1623: Renamed in 'MainSet7' â†’ 1623.jpg\n",
            "1624: Renamed in 'MainSet7' â†’ 1624.jpg\n",
            "1625: Renamed in 'MainSet7' â†’ 1625.jpg\n",
            "1626: Renamed in 'MainSet7' â†’ 1626.jpg\n",
            "1627: Renamed in 'MainSet7' â†’ 1627.jpg\n",
            "1628: Renamed in 'MainSet7' â†’ 1628.jpg\n",
            "1629: Renamed in 'MainSet7' â†’ 1629.jpg\n",
            "1630: Renamed in 'MainSet7' â†’ 1630.jpg\n",
            "1631: Renamed in 'MainSet7' â†’ 1631.jpg\n",
            "1632: Renamed in 'MainSet7' â†’ 1632.jpg\n",
            "1633: Renamed in 'MainSet7' â†’ 1633.jpg\n",
            "1634: Renamed in 'MainSet7' â†’ 1634.jpg\n",
            "1635: Renamed in 'MainSet7' â†’ 1635.jpg\n",
            "1636: Renamed in 'MainSet7' â†’ 1636.jpg\n",
            "1637: Renamed in 'MainSet7' â†’ 1637.jpg\n",
            "1638: Renamed in 'MainSet7' â†’ 1638.jpg\n",
            "1639: Renamed in 'MainSet7' â†’ 1639.jpg\n",
            "1640: Renamed in 'MainSet7' â†’ 1640.jpg\n",
            "1641: Renamed in 'MainSet7' â†’ 1641.jpg\n",
            "1642: Renamed in 'MainSet7' â†’ 1642.jpg\n",
            "1643: Renamed in 'MainSet7' â†’ 1643.jpg\n",
            "1644: Renamed in 'MainSet7' â†’ 1644.jpg\n",
            "1645: Renamed in 'MainSet7' â†’ 1645.jpg\n",
            "1646: Renamed in 'MainSet7' â†’ 1646.jpg\n",
            "1647: Renamed in 'MainSet7' â†’ 1647.jpg\n",
            "1648: Renamed in 'MainSet7' â†’ 1648.jpg\n",
            "1649: Renamed in 'MainSet7' â†’ 1649.jpg\n",
            "1650: Renamed in 'MainSet7' â†’ 1650.jpg\n",
            "1651: Renamed in 'MainSet7' â†’ 1651.jpg\n",
            "1652: Renamed in 'MainSet7' â†’ 1652.jpg\n",
            "1653: Renamed in 'MainSet7' â†’ 1653.jpg\n",
            "1654: Renamed in 'MainSet7' â†’ 1654.jpg\n",
            "1655: Renamed in 'MainSet7' â†’ 1655.jpg\n",
            "1656: Renamed in 'MainSet7' â†’ 1656.jpg\n",
            "1657: Renamed in 'MainSet7' â†’ 1657.jpg\n",
            "1658: Renamed in 'MainSet7' â†’ 1658.jpg\n",
            "1659: Renamed in 'MainSet7' â†’ 1659.jpg\n",
            "1660: Renamed in 'MainSet7' â†’ 1660.jpg\n",
            "1661: Renamed in 'MainSet7' â†’ 1661.jpg\n",
            "1662: Renamed in 'MainSet7' â†’ 1662.jpg\n",
            "1663: Renamed in 'MainSet7' â†’ 1663.jpg\n",
            "1664: Renamed in 'MainSet7' â†’ 1664.jpg\n",
            "1665: Renamed in 'MainSet8' â†’ 1665.jpg\n",
            "1666: Renamed in 'MainSet8' â†’ 1666.jpg\n",
            "1667: Renamed in 'MainSet8' â†’ 1667.jpg\n",
            "1668: Renamed in 'MainSet8' â†’ 1668.jpg\n",
            "1669: Renamed in 'MainSet8' â†’ 1669.jpg\n",
            "1670: Renamed in 'MainSet8' â†’ 1670.jpg\n",
            "1671: Renamed in 'MainSet8' â†’ 1671.jpg\n",
            "1672: Renamed in 'MainSet8' â†’ 1672.jpg\n",
            "1673: Renamed in 'MainSet8' â†’ 1673.jpg\n",
            "1674: Renamed in 'MainSet8' â†’ 1674.jpg\n",
            "1675: Renamed in 'MainSet8' â†’ 1675.jpg\n",
            "1676: Renamed in 'MainSet8' â†’ 1676.jpg\n",
            "1677: Renamed in 'MainSet8' â†’ 1677.jpg\n",
            "1678: Renamed in 'MainSet8' â†’ 1678.jpg\n",
            "1679: Renamed in 'MainSet8' â†’ 1679.jpg\n",
            "1680: Renamed in 'MainSet8' â†’ 1680.jpg\n",
            "1681: Renamed in 'MainSet8' â†’ 1681.jpg\n",
            "1682: Renamed in 'MainSet8' â†’ 1682.jpg\n",
            "1683: Renamed in 'MainSet8' â†’ 1683.jpg\n",
            "1684: Renamed in 'MainSet8' â†’ 1684.jpg\n",
            "1685: Renamed in 'MainSet8' â†’ 1685.jpg\n",
            "1686: Renamed in 'MainSet8' â†’ 1686.jpg\n",
            "1687: Renamed in 'MainSet8' â†’ 1687.jpg\n",
            "1688: Renamed in 'MainSet8' â†’ 1688.jpg\n",
            "1689: Renamed in 'MainSet8' â†’ 1689.jpg\n",
            "1690: Renamed in 'MainSet8' â†’ 1690.jpg\n",
            "1691: Renamed in 'MainSet8' â†’ 1691.jpg\n",
            "1692: Renamed in 'MainSet8' â†’ 1692.jpg\n",
            "1693: Renamed in 'MainSet8' â†’ 1693.jpg\n",
            "1694: Renamed in 'MainSet8' â†’ 1694.jpg\n",
            "1695: Renamed in 'MainSet8' â†’ 1695.jpg\n",
            "1696: Renamed in 'MainSet8' â†’ 1696.jpg\n",
            "1697: Renamed in 'MainSet8' â†’ 1697.jpg\n",
            "1698: Renamed in 'MainSet8' â†’ 1698.jpg\n",
            "1699: Renamed in 'MainSet8' â†’ 1699.jpg\n",
            "1700: Renamed in 'MainSet8' â†’ 1700.jpg\n",
            "1701: Renamed in 'MainSet8' â†’ 1701.jpg\n",
            "1702: Renamed in 'MainSet8' â†’ 1702.jpg\n",
            "1703: Renamed in 'MainSet8' â†’ 1703.jpg\n",
            "1704: Renamed in 'MainSet8' â†’ 1704.jpg\n",
            "1705: Renamed in 'MainSet8' â†’ 1705.jpg\n",
            "1706: Renamed in 'MainSet8' â†’ 1706.jpg\n",
            "1707: Renamed in 'MainSet8' â†’ 1707.jpg\n",
            "1708: Renamed in 'MainSet8' â†’ 1708.jpg\n",
            "1709: Renamed in 'MainSet8' â†’ 1709.jpg\n",
            "1710: Renamed in 'MainSet8' â†’ 1710.jpg\n",
            "1711: Renamed in 'MainSet8' â†’ 1711.jpg\n",
            "1712: Renamed in 'MainSet8' â†’ 1712.jpg\n",
            "1713: Renamed in 'MainSet8' â†’ 1713.jpg\n",
            "1714: Renamed in 'MainSet8' â†’ 1714.jpg\n",
            "1715: Renamed in 'MainSet8' â†’ 1715.jpg\n",
            "1716: Renamed in 'MainSet8' â†’ 1716.jpg\n",
            "1717: Renamed in 'MainSet8' â†’ 1717.jpg\n",
            "1718: Renamed in 'MainSet8' â†’ 1718.jpg\n",
            "1719: Renamed in 'MainSet8' â†’ 1719.jpg\n",
            "1720: Renamed in 'MainSet8' â†’ 1720.jpg\n",
            "1721: Renamed in 'MainSet8' â†’ 1721.jpg\n",
            "1722: Renamed in 'MainSet8' â†’ 1722.jpg\n",
            "1723: Renamed in 'MainSet8' â†’ 1723.jpg\n",
            "1724: Renamed in 'MainSet8' â†’ 1724.jpg\n",
            "1725: Renamed in 'MainSet8' â†’ 1725.jpg\n",
            "1726: Renamed in 'MainSet8' â†’ 1726.jpg\n",
            "1727: Renamed in 'MainSet8' â†’ 1727.jpg\n",
            "1728: Renamed in 'MainSet8' â†’ 1728.jpg\n",
            "1729: Renamed in 'MainSet8' â†’ 1729.jpg\n",
            "1730: Renamed in 'MainSet8' â†’ 1730.jpg\n",
            "1731: Renamed in 'MainSet8' â†’ 1731.jpg\n",
            "1732: Renamed in 'MainSet8' â†’ 1732.jpg\n",
            "1733: Renamed in 'MainSet8' â†’ 1733.jpg\n",
            "1734: Renamed in 'MainSet8' â†’ 1734.jpg\n",
            "1735: Renamed in 'MainSet8' â†’ 1735.jpg\n",
            "1736: Renamed in 'MainSet8' â†’ 1736.jpg\n",
            "1737: Renamed in 'MainSet8' â†’ 1737.jpg\n",
            "1738: Renamed in 'MainSet8' â†’ 1738.jpg\n",
            "1739: Renamed in 'MainSet8' â†’ 1739.jpg\n",
            "1740: Renamed in 'MainSet8' â†’ 1740.jpg\n",
            "1741: Renamed in 'MainSet8' â†’ 1741.jpg\n",
            "1742: Renamed in 'MainSet8' â†’ 1742.jpg\n",
            "1743: Renamed in 'MainSet8' â†’ 1743.jpg\n",
            "1744: Renamed in 'MainSet8' â†’ 1744.jpg\n",
            "1745: Renamed in 'MainSet8' â†’ 1745.jpg\n",
            "1746: Renamed in 'MainSet8' â†’ 1746.jpg\n",
            "1747: Renamed in 'MainSet8' â†’ 1747.jpg\n",
            "1748: Renamed in 'MainSet8' â†’ 1748.jpg\n",
            "1749: Renamed in 'MainSet8' â†’ 1749.jpg\n",
            "1750: Renamed in 'MainSet8' â†’ 1750.jpg\n",
            "1751: Renamed in 'MainSet8' â†’ 1751.jpg\n",
            "1752: Renamed in 'MainSet8' â†’ 1752.jpg\n",
            "1753: Renamed in 'MainSet8' â†’ 1753.jpg\n",
            "1754: Renamed in 'MainSet8' â†’ 1754.jpg\n",
            "1755: Renamed in 'MainSet8' â†’ 1755.jpg\n",
            "1756: Renamed in 'MainSet8' â†’ 1756.jpg\n",
            "1757: Renamed in 'MainSet8' â†’ 1757.jpg\n",
            "1758: Renamed in 'MainSet8' â†’ 1758.jpg\n",
            "1759: Renamed in 'MainSet8' â†’ 1759.jpg\n",
            "1760: Renamed in 'MainSet8' â†’ 1760.jpg\n",
            "1761: Renamed in 'MainSet8' â†’ 1761.jpg\n",
            "1762: Renamed in 'MainSet8' â†’ 1762.jpg\n",
            "1763: Renamed in 'MainSet8' â†’ 1763.jpg\n",
            "1764: Renamed in 'MainSet8' â†’ 1764.jpg\n",
            "1765: Renamed in 'MainSet8' â†’ 1765.jpg\n",
            "1766: Renamed in 'MainSet8' â†’ 1766.jpg\n",
            "1767: Renamed in 'MainSet8' â†’ 1767.jpg\n",
            "1768: Renamed in 'MainSet8' â†’ 1768.jpg\n",
            "1769: Renamed in 'MainSet8' â†’ 1769.jpg\n",
            "1770: Renamed in 'MainSet8' â†’ 1770.jpg\n",
            "1771: Renamed in 'MainSet8' â†’ 1771.jpg\n",
            "1772: Renamed in 'MainSet8' â†’ 1772.jpg\n",
            "1773: Renamed in 'MainSet8' â†’ 1773.jpg\n",
            "1774: Renamed in 'MainSet8' â†’ 1774.jpg\n",
            "1775: Renamed in 'MainSet8' â†’ 1775.jpg\n",
            "1776: Renamed in 'MainSet8' â†’ 1776.jpg\n",
            "1777: Renamed in 'MainSet8' â†’ 1777.jpg\n",
            "1778: Renamed in 'MainSet8' â†’ 1778.jpg\n",
            "1779: Renamed in 'MainSet8' â†’ 1779.jpg\n",
            "1780: Renamed in 'MainSet8' â†’ 1780.jpg\n",
            "1781: Renamed in 'MainSet8' â†’ 1781.jpg\n",
            "1782: Renamed in 'MainSet8' â†’ 1782.jpg\n",
            "1783: Renamed in 'MainSet8' â†’ 1783.jpg\n",
            "1784: Renamed in 'MainSet8' â†’ 1784.jpg\n",
            "1785: Renamed in 'MainSet8' â†’ 1785.jpg\n",
            "1786: Renamed in 'MainSet8' â†’ 1786.jpg\n",
            "1787: Renamed in 'MainSet8' â†’ 1787.jpg\n",
            "1788: Renamed in 'MainSet8' â†’ 1788.jpg\n",
            "1789: Renamed in 'MainSet8' â†’ 1789.jpg\n",
            "1790: Renamed in 'MainSet8' â†’ 1790.jpg\n",
            "1791: Renamed in 'MainSet8' â†’ 1791.jpg\n",
            "1792: Renamed in 'MainSet8' â†’ 1792.jpg\n",
            "1793: Renamed in 'MainSet8' â†’ 1793.jpg\n",
            "1794: Renamed in 'MainSet8' â†’ 1794.jpg\n",
            "1795: Renamed in 'MainSet8' â†’ 1795.jpg\n",
            "1796: Renamed in 'MainSet8' â†’ 1796.jpg\n",
            "1797: Renamed in 'MainSet8' â†’ 1797.jpg\n",
            "1798: Renamed in 'MainSet8' â†’ 1798.jpg\n",
            "1799: Renamed in 'MainSet8' â†’ 1799.jpg\n",
            "1800: Renamed in 'MainSet8' â†’ 1800.jpg\n",
            "1801: Renamed in 'MainSet8' â†’ 1801.jpg\n",
            "1802: Renamed in 'MainSet8' â†’ 1802.jpg\n",
            "1803: Renamed in 'MainSet8' â†’ 1803.jpg\n",
            "1804: Renamed in 'MainSet8' â†’ 1804.jpg\n",
            "1805: Renamed in 'MainSet8' â†’ 1805.jpg\n",
            "1806: Renamed in 'MainSet8' â†’ 1806.jpg\n",
            "1807: Renamed in 'MainSet8' â†’ 1807.jpg\n",
            "1808: Renamed in 'MainSet8' â†’ 1808.jpg\n",
            "1809: Renamed in 'MainSet8' â†’ 1809.jpg\n",
            "1810: Renamed in 'MainSet8' â†’ 1810.jpg\n",
            "1811: Renamed in 'MainSet8' â†’ 1811.jpg\n",
            "1812: Renamed in 'MainSet8' â†’ 1812.jpg\n",
            "1813: Renamed in 'MainSet8' â†’ 1813.jpg\n",
            "1814: Renamed in 'MainSet8' â†’ 1814.jpg\n",
            "1815: Renamed in 'MainSet8' â†’ 1815.jpg\n",
            "1816: Renamed in 'MainSet8' â†’ 1816.jpg\n",
            "1817: Renamed in 'MainSet8' â†’ 1817.jpg\n",
            "1818: Renamed in 'MainSet8' â†’ 1818.jpg\n",
            "1819: Renamed in 'MainSet9' â†’ 1819.jpg\n",
            "1820: Renamed in 'MainSet9' â†’ 1820.jpg\n",
            "1821: Renamed in 'MainSet9' â†’ 1821.jpg\n",
            "1822: Renamed in 'MainSet9' â†’ 1822.jpg\n",
            "1823: Renamed in 'MainSet9' â†’ 1823.jpg\n",
            "1824: Renamed in 'MainSet9' â†’ 1824.jpg\n",
            "1825: Renamed in 'MainSet9' â†’ 1825.jpg\n",
            "1826: Renamed in 'MainSet9' â†’ 1826.jpg\n",
            "1827: Renamed in 'MainSet9' â†’ 1827.jpg\n",
            "1828: Renamed in 'MainSet9' â†’ 1828.jpg\n",
            "1829: Renamed in 'MainSet9' â†’ 1829.jpg\n",
            "1830: Renamed in 'MainSet9' â†’ 1830.jpg\n",
            "1831: Renamed in 'MainSet9' â†’ 1831.jpg\n",
            "1832: Renamed in 'MainSet9' â†’ 1832.jpg\n",
            "1833: Renamed in 'MainSet9' â†’ 1833.jpg\n",
            "1834: Renamed in 'MainSet9' â†’ 1834.jpg\n",
            "1835: Renamed in 'MainSet9' â†’ 1835.jpg\n",
            "1836: Renamed in 'MainSet9' â†’ 1836.jpg\n",
            "1837: Renamed in 'MainSet9' â†’ 1837.jpg\n",
            "1838: Renamed in 'MainSet9' â†’ 1838.jpg\n",
            "1839: Renamed in 'MainSet9' â†’ 1839.jpg\n",
            "1840: Renamed in 'MainSet9' â†’ 1840.jpg\n",
            "1841: Renamed in 'MainSet9' â†’ 1841.jpg\n",
            "1842: Renamed in 'MainSet9' â†’ 1842.jpg\n",
            "1843: Renamed in 'MainSet9' â†’ 1843.jpg\n",
            "1844: Renamed in 'MainSet9' â†’ 1844.jpg\n",
            "1845: Renamed in 'MainSet9' â†’ 1845.jpg\n",
            "1846: Renamed in 'MainSet9' â†’ 1846.jpg\n",
            "1847: Renamed in 'MainSet9' â†’ 1847.jpg\n",
            "1848: Renamed in 'MainSet9' â†’ 1848.jpg\n",
            "1849: Renamed in 'MainSet9' â†’ 1849.jpg\n",
            "1850: Renamed in 'MainSet9' â†’ 1850.jpg\n",
            "1851: Renamed in 'MainSet9' â†’ 1851.jpg\n",
            "1852: Renamed in 'MainSet9' â†’ 1852.jpg\n",
            "1853: Renamed in 'MainSet9' â†’ 1853.jpg\n",
            "1854: Renamed in 'MainSet9' â†’ 1854.jpg\n",
            "1855: Renamed in 'MainSet9' â†’ 1855.jpg\n",
            "1856: Renamed in 'MainSet9' â†’ 1856.jpg\n",
            "1857: Renamed in 'MainSet9' â†’ 1857.jpg\n",
            "1858: Renamed in 'MainSet9' â†’ 1858.jpg\n",
            "1859: Renamed in 'MainSet9' â†’ 1859.jpg\n",
            "1860: Renamed in 'MainSet9' â†’ 1860.jpg\n",
            "1861: Renamed in 'MainSet9' â†’ 1861.jpg\n",
            "1862: Renamed in 'MainSet9' â†’ 1862.jpg\n",
            "1863: Renamed in 'MainSet9' â†’ 1863.jpg\n",
            "1864: Renamed in 'MainSet9' â†’ 1864.jpg\n",
            "1865: Renamed in 'MainSet9' â†’ 1865.jpg\n",
            "1866: Renamed in 'MainSet9' â†’ 1866.jpg\n",
            "1867: Renamed in 'MainSet9' â†’ 1867.jpg\n",
            "1868: Renamed in 'MainSet9' â†’ 1868.jpg\n",
            "1869: Renamed in 'MainSet9' â†’ 1869.jpg\n",
            "1870: Renamed in 'MainSet9' â†’ 1870.jpg\n",
            "1871: Renamed in 'MainSet9' â†’ 1871.jpg\n",
            "1872: Renamed in 'MainSet9' â†’ 1872.jpg\n",
            "1873: Renamed in 'MainSet9' â†’ 1873.jpg\n",
            "1874: Renamed in 'MainSet9' â†’ 1874.jpg\n",
            "1875: Renamed in 'MainSet9' â†’ 1875.jpg\n",
            "1876: Renamed in 'MainSet9' â†’ 1876.jpg\n",
            "1877: Renamed in 'MainSet9' â†’ 1877.jpg\n",
            "1878: Renamed in 'MainSet9' â†’ 1878.jpg\n",
            "1879: Renamed in 'MainSet9' â†’ 1879.jpg\n",
            "1880: Renamed in 'MainSet9' â†’ 1880.jpg\n",
            "1881: Renamed in 'MainSet9' â†’ 1881.jpg\n",
            "1882: Renamed in 'MainSet9' â†’ 1882.jpg\n",
            "1883: Renamed in 'MainSet9' â†’ 1883.jpg\n",
            "1884: Renamed in 'MainSet9' â†’ 1884.jpg\n",
            "1885: Renamed in 'MainSet9' â†’ 1885.jpg\n",
            "1886: Renamed in 'MainSet9' â†’ 1886.jpg\n",
            "1887: Renamed in 'MainSet9' â†’ 1887.jpg\n",
            "1888: Renamed in 'MainSet9' â†’ 1888.jpg\n",
            "1889: Renamed in 'MainSet9' â†’ 1889.jpg\n",
            "1890: Renamed in 'MainSet9' â†’ 1890.jpg\n",
            "1891: Renamed in 'MainSet9' â†’ 1891.jpg\n",
            "1892: Renamed in 'MainSet9' â†’ 1892.jpg\n",
            "1893: Renamed in 'MainSet9' â†’ 1893.jpg\n",
            "1894: Renamed in 'MainSet9' â†’ 1894.jpg\n",
            "1895: Renamed in 'MainSet9' â†’ 1895.jpg\n",
            "1896: Renamed in 'MainSet9' â†’ 1896.jpg\n",
            "1897: Renamed in 'MainSet9' â†’ 1897.jpg\n",
            "1898: Renamed in 'MainSet9' â†’ 1898.jpg\n",
            "1899: Renamed in 'MainSet9' â†’ 1899.jpg\n",
            "1900: Renamed in 'MainSet9' â†’ 1900.jpg\n",
            "1901: Renamed in 'MainSet9' â†’ 1901.jpg\n",
            "1902: Renamed in 'MainSet9' â†’ 1902.jpg\n",
            "1903: Renamed in 'MainSet9' â†’ 1903.jpg\n",
            "1904: Renamed in 'MainSet9' â†’ 1904.jpg\n",
            "1905: Renamed in 'MainSet9' â†’ 1905.jpg\n",
            "1906: Renamed in 'MainSet9' â†’ 1906.jpg\n",
            "1907: Renamed in 'MainSet9' â†’ 1907.jpg\n",
            "1908: Renamed in 'MainSet9' â†’ 1908.jpg\n",
            "1909: Renamed in 'MainSet9' â†’ 1909.jpg\n",
            "1910: Renamed in 'MainSet9' â†’ 1910.jpg\n",
            "1911: Renamed in 'MainSet9' â†’ 1911.jpg\n",
            "1912: Renamed in 'MainSet9' â†’ 1912.jpg\n",
            "1913: Renamed in 'MainSet9' â†’ 1913.jpg\n",
            "1914: Renamed in 'MainSet9' â†’ 1914.jpg\n",
            "1915: Renamed in 'MainSet9' â†’ 1915.jpg\n",
            "1916: Renamed in 'MainSet9' â†’ 1916.jpg\n",
            "1917: Renamed in 'MainSet9' â†’ 1917.jpg\n",
            "1918: Renamed in 'MainSet9' â†’ 1918.jpg\n",
            "1919: Renamed in 'MainSet9' â†’ 1919.jpg\n",
            "1920: Renamed in 'MainSet9' â†’ 1920.jpg\n",
            "1921: Renamed in 'MainSet9' â†’ 1921.jpg\n",
            "1922: Renamed in 'MainSet9' â†’ 1922.jpg\n",
            "1923: Renamed in 'MainSet9' â†’ 1923.jpg\n",
            "1924: Renamed in 'MainSet9' â†’ 1924.jpg\n",
            "1925: Renamed in 'MainSet9' â†’ 1925.jpg\n",
            "1926: Renamed in 'MainSet9' â†’ 1926.jpg\n",
            "1927: Renamed in 'MainSet9' â†’ 1927.jpg\n",
            "1928: Renamed in 'MainSet9' â†’ 1928.jpg\n",
            "1929: Renamed in 'MainSet9' â†’ 1929.jpg\n",
            "1930: Renamed in 'MainSet9' â†’ 1930.jpg\n",
            "1931: Renamed in 'MainSet9' â†’ 1931.jpg\n",
            "1932: Renamed in 'MainSet9' â†’ 1932.jpg\n",
            "1933: Renamed in 'MainSet9' â†’ 1933.jpg\n",
            "1934: Renamed in 'MainSet9' â†’ 1934.jpg\n",
            "1935: Renamed in 'MainSet9' â†’ 1935.jpg\n",
            "1936: Renamed in 'MainSet9' â†’ 1936.jpg\n",
            "1937: Renamed in 'MainSet9' â†’ 1937.jpg\n",
            "1938: Renamed in 'MainSet9' â†’ 1938.jpg\n",
            "1939: Renamed in 'MainSet9' â†’ 1939.jpg\n",
            "1940: Renamed in 'MainSet9' â†’ 1940.jpg\n",
            "1941: Renamed in 'MainSet9' â†’ 1941.jpg\n",
            "1942: Renamed in 'MainSet9' â†’ 1942.jpg\n",
            "1943: Renamed in 'MainSet9' â†’ 1943.jpg\n",
            "1944: Renamed in 'MainSet9' â†’ 1944.jpg\n",
            "1945: Renamed in 'MainSet9' â†’ 1945.jpg\n",
            "1946: Renamed in 'MainSet9' â†’ 1946.jpg\n",
            "1947: Renamed in 'MainSet9' â†’ 1947.jpg\n",
            "1948: Renamed in 'MainSet9' â†’ 1948.jpg\n",
            "1949: Renamed in 'MainSet9' â†’ 1949.jpg\n",
            "1950: Renamed in 'MainSet9' â†’ 1950.jpg\n",
            "1951: Renamed in 'MainSet9' â†’ 1951.jpg\n",
            "1952: Renamed in 'MainSet9' â†’ 1952.jpg\n",
            "1953: Renamed in 'MainSet9' â†’ 1953.jpg\n",
            "1954: Renamed in 'MainSet9' â†’ 1954.jpg\n",
            "1955: Renamed in 'MainSet9' â†’ 1955.jpg\n",
            "1956: Renamed in 'MainSet9' â†’ 1956.jpg\n",
            "1957: Renamed in 'MainSet9' â†’ 1957.jpg\n",
            "1958: Renamed in 'MainSet9' â†’ 1958.jpg\n",
            "1959: Renamed in 'MainSet9' â†’ 1959.jpg\n",
            "1960: Renamed in 'MainSet9' â†’ 1960.jpg\n",
            "1961: Renamed in 'MainSet9' â†’ 1961.jpg\n",
            "1962: Renamed in 'MainSet9' â†’ 1962.jpg\n",
            "1963: Renamed in 'MainSet9' â†’ 1963.jpg\n",
            "1964: Renamed in 'MainSet9' â†’ 1964.jpg\n",
            "1965: Renamed in 'MainSet9' â†’ 1965.jpg\n",
            "1966: Renamed in 'MainSet9' â†’ 1966.jpg\n",
            "1967: Renamed in 'MainSet9' â†’ 1967.jpg\n",
            "1968: Renamed in 'MainSet9' â†’ 1968.jpg\n",
            "1969: Renamed in 'MainSet9' â†’ 1969.jpg\n",
            "1970: Renamed in 'MainSet9' â†’ 1970.jpg\n",
            "1971: Renamed in 'MainSet9' â†’ 1971.jpg\n",
            "1972: Renamed in 'MainSet9' â†’ 1972.jpg\n",
            "1973: Renamed in 'MainSet9' â†’ 1973.jpg\n",
            "1974: Renamed in 'MainSet9' â†’ 1974.jpg\n",
            "1975: Renamed in 'MainSet9' â†’ 1975.jpg\n",
            "1976: Renamed in 'MainSet9' â†’ 1976.jpg\n",
            "1977: Renamed in 'MainSet9' â†’ 1977.jpg\n",
            "1978: Renamed in 'MainSet9' â†’ 1978.jpg\n",
            "1979: Renamed in 'MainSet9' â†’ 1979.jpg\n",
            "1980: Renamed in 'MainSet9' â†’ 1980.jpg\n",
            "1981: Renamed in 'MainSet9' â†’ 1981.jpg\n",
            "1982: Renamed in 'MainSet9' â†’ 1982.jpg\n",
            "1983: Renamed in 'MainSet9' â†’ 1983.jpg\n",
            "1984: Renamed in 'MainSet9' â†’ 1984.jpg\n",
            "1985: Renamed in 'MainSet9' â†’ 1985.jpg\n",
            "1986: Renamed in 'MainSet9' â†’ 1986.jpg\n",
            "1987: Renamed in 'MainSet9' â†’ 1987.jpg\n",
            "1988: Renamed in 'MainSet9' â†’ 1988.jpg\n",
            "1989: Renamed in 'MainSet9' â†’ 1989.jpg\n",
            "1990: Renamed in 'MainSet9' â†’ 1990.jpg\n",
            "1991: Renamed in 'MainSet9' â†’ 1991.jpg\n",
            "1992: Renamed in 'MainSet9' â†’ 1992.jpg\n",
            "1993: Renamed in 'MainSet9' â†’ 1993.jpg\n",
            "1994: Renamed in 'MainSet9' â†’ 1994.jpg\n",
            "1995: Renamed in 'MainSet9' â†’ 1995.jpg\n",
            "1996: Renamed in 'MainSet9' â†’ 1996.jpg\n",
            "1997: Renamed in 'MainSet9' â†’ 1997.jpg\n",
            "1998: Renamed in 'MainSet9' â†’ 1998.jpg\n",
            "1999: Renamed in 'MainSet9' â†’ 1999.jpg\n",
            "2000: Renamed in 'MainSet9' â†’ 2000.jpg\n",
            "2001: Renamed in 'MainSet9' â†’ 2001.jpg\n",
            "2002: Renamed in 'MainSet9' â†’ 2002.jpg\n",
            "2003: Renamed in 'MainSet9' â†’ 2003.jpg\n",
            "2004: Renamed in 'MainSet9' â†’ 2004.jpg\n",
            "2005: Renamed in 'MainSet9' â†’ 2005.jpg\n",
            "2006: Renamed in 'MainSet9' â†’ 2006.jpg\n",
            "2007: Renamed in 'MainSet9' â†’ 2007.jpg\n",
            "2008: Renamed in 'MainSet9' â†’ 2008.jpg\n",
            "2009: Renamed in 'MainSet9' â†’ 2009.jpg\n",
            "2010: Renamed in 'MainSet9' â†’ 2010.jpg\n",
            "2011: Renamed in 'MainSet9' â†’ 2011.jpg\n",
            "2012: Renamed in 'MainSet9' â†’ 2012.jpg\n",
            "2013: Renamed in 'MainSet9' â†’ 2013.jpg\n",
            "2014: Renamed in 'MainSet9' â†’ 2014.jpg\n",
            "2015: Renamed in 'MainSet9' â†’ 2015.jpg\n",
            "2016: Renamed in 'MainSet9' â†’ 2016.jpg\n",
            "2017: Renamed in 'MainSet9' â†’ 2017.jpg\n",
            "2018: Renamed in 'MainSet9' â†’ 2018.jpg\n",
            "2019: Renamed in 'MainSet9' â†’ 2019.jpg\n",
            "2020: Renamed in 'MainSet9' â†’ 2020.jpg\n",
            "2021: Renamed in 'MainSet9' â†’ 2021.jpg\n",
            "2022: Renamed in 'MainSet9' â†’ 2022.jpg\n",
            "2023: Renamed in 'MainSet9' â†’ 2023.jpg\n",
            "2024: Renamed in 'MainSet9' â†’ 2024.jpg\n",
            "2025: Renamed in 'MainSet9' â†’ 2025.jpg\n",
            "2026: Renamed in 'MainSet9' â†’ 2026.jpg\n",
            "2027: Renamed in 'MainSet9' â†’ 2027.jpg\n",
            "2028: Renamed in 'MainSet9' â†’ 2028.jpg\n",
            "2029: Renamed in 'MainSet9' â†’ 2029.jpg\n",
            "2030: Renamed in 'MainSet9' â†’ 2030.jpg\n",
            "2031: Renamed in 'MainSet9' â†’ 2031.jpg\n",
            "2032: Renamed in 'MainSet9' â†’ 2032.jpg\n",
            "2033: Renamed in 'MainSet9' â†’ 2033.jpg\n",
            "2034: Renamed in 'MainSet9' â†’ 2034.jpg\n",
            "2035: Renamed in 'MainSet9' â†’ 2035.jpg\n",
            "2036: Renamed in 'MainSet9' â†’ 2036.jpg\n",
            "2037: Renamed in 'MainSet9' â†’ 2037.jpg\n",
            "2038: Renamed in 'MainSet9' â†’ 2038.jpg\n",
            "\n",
            "âœ… Total images renamed: 2038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# ğŸ” Replace these with the actual 6 folder paths\n",
        "source_folders = [\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET01',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET02',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET03',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET04',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET05',\n",
        "    '/content/drive/MyDrive/clear_student_frames/SET06'\n",
        "]\n",
        "\n",
        "# ğŸ—‚ï¸ Target folder where all images will be copied\n",
        "target_folder = '/content/drive/MyDrive/clear_student_frames/merged_set'\n",
        "os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "# ğŸ“¦ Copy files from each folder\n",
        "for folder in source_folders:\n",
        "    for file in os.listdir(folder):\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            src = os.path.join(folder, file)\n",
        "            dst = os.path.join(target_folder, file)\n",
        "            if not os.path.exists(dst):  # Avoid overwriting duplicates\n",
        "                shutil.copy(src, dst)\n",
        "            else:\n",
        "                print(f\"âš ï¸ Skipped duplicate: {file}\")\n",
        "\n",
        "print(\"âœ… All images merged into:\", target_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22TbrNLKlSV",
        "outputId": "d32e3ada-c15b-420d-8574-8bc0b90a9e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All images merged into: /content/drive/MyDrive/clear_student_frames/merged_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Set source parent folder and target merge folder\n",
        "source_parent = '/content/drive/MyDrive/clear_student_frames'  # â¬…ï¸ contains the 10 folders\n",
        "target_folder = '/content/drive/MyDrive/MMimages'               # â¬…ï¸ all images will go here\n",
        "\n",
        "# Step 3: Create target folder if it doesn't exist\n",
        "os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "# Step 4: Collect all images from the 10 folders\n",
        "image_extensions = ('*.jpg', '*.jpeg', '*.png')  # Add others if needed\n",
        "all_images = []\n",
        "\n",
        "for ext in image_extensions:\n",
        "    all_images.extend(glob.glob(os.path.join(source_parent, '*', ext)))\n",
        "\n",
        "# Optional: Sort for consistent order\n",
        "all_images.sort()\n",
        "\n",
        "# Step 5: Copy and rename to the target folder\n",
        "start_serial = 1  # Change if needed\n",
        "copied_count = 0\n",
        "\n",
        "for idx, img_path in enumerate(all_images, start_serial):\n",
        "    ext = os.path.splitext(img_path)[1]\n",
        "    new_name = f\"{idx}{ext}\"\n",
        "    new_path = os.path.join(target_folder, new_name)\n",
        "\n",
        "    try:\n",
        "        shutil.copy(img_path, new_path)\n",
        "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
        "        print(f\"{idx}: Copied from '{folder_name}' â†’ {new_name}\")\n",
        "        copied_count += 1\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error copying '{img_path}': {e}\")\n",
        "\n",
        "# Step 6: Output total copied images\n",
        "print(f\"\\nâœ… Total images copied and renamed: {copied_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHvBxv3X0fr-",
        "outputId": "8a3e7f05-36c7-4ddb-bbf4-8dc483a6f6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "1: Copied from 'MainSet1' â†’ 1.jpg\n",
            "2: Copied from 'MainSet1' â†’ 2.jpg\n",
            "3: Copied from 'MainSet1' â†’ 3.jpg\n",
            "4: Copied from 'MainSet1' â†’ 4.jpg\n",
            "5: Copied from 'MainSet1' â†’ 5.jpg\n",
            "6: Copied from 'MainSet1' â†’ 6.jpg\n",
            "7: Copied from 'MainSet1' â†’ 7.jpg\n",
            "8: Copied from 'MainSet1' â†’ 8.jpg\n",
            "9: Copied from 'MainSet1' â†’ 9.jpg\n",
            "10: Copied from 'MainSet1' â†’ 10.jpg\n",
            "11: Copied from 'MainSet1' â†’ 11.jpg\n",
            "12: Copied from 'MainSet1' â†’ 12.jpg\n",
            "13: Copied from 'MainSet1' â†’ 13.jpg\n",
            "14: Copied from 'MainSet1' â†’ 14.jpg\n",
            "15: Copied from 'MainSet1' â†’ 15.jpg\n",
            "16: Copied from 'MainSet1' â†’ 16.jpg\n",
            "17: Copied from 'MainSet1' â†’ 17.jpg\n",
            "18: Copied from 'MainSet1' â†’ 18.jpg\n",
            "19: Copied from 'MainSet1' â†’ 19.jpg\n",
            "20: Copied from 'MainSet1' â†’ 20.jpg\n",
            "21: Copied from 'MainSet1' â†’ 21.jpg\n",
            "22: Copied from 'MainSet1' â†’ 22.jpg\n",
            "23: Copied from 'MainSet1' â†’ 23.jpg\n",
            "24: Copied from 'MainSet1' â†’ 24.jpg\n",
            "25: Copied from 'MainSet1' â†’ 25.jpg\n",
            "26: Copied from 'MainSet1' â†’ 26.jpg\n",
            "27: Copied from 'MainSet1' â†’ 27.jpg\n",
            "28: Copied from 'MainSet1' â†’ 28.jpg\n",
            "29: Copied from 'MainSet1' â†’ 29.jpg\n",
            "30: Copied from 'MainSet1' â†’ 30.jpg\n",
            "31: Copied from 'MainSet1' â†’ 31.jpg\n",
            "32: Copied from 'MainSet1' â†’ 32.jpg\n",
            "33: Copied from 'MainSet1' â†’ 33.jpg\n",
            "34: Copied from 'MainSet1' â†’ 34.jpg\n",
            "35: Copied from 'MainSet1' â†’ 35.jpg\n",
            "36: Copied from 'MainSet1' â†’ 36.jpg\n",
            "37: Copied from 'MainSet1' â†’ 37.jpg\n",
            "38: Copied from 'MainSet1' â†’ 38.jpg\n",
            "39: Copied from 'MainSet1' â†’ 39.jpg\n",
            "40: Copied from 'MainSet1' â†’ 40.jpg\n",
            "41: Copied from 'MainSet1' â†’ 41.jpg\n",
            "42: Copied from 'MainSet1' â†’ 42.jpg\n",
            "43: Copied from 'MainSet1' â†’ 43.jpg\n",
            "44: Copied from 'MainSet1' â†’ 44.jpg\n",
            "45: Copied from 'MainSet1' â†’ 45.jpg\n",
            "46: Copied from 'MainSet1' â†’ 46.jpg\n",
            "47: Copied from 'MainSet1' â†’ 47.jpg\n",
            "48: Copied from 'MainSet1' â†’ 48.jpg\n",
            "49: Copied from 'MainSet1' â†’ 49.jpg\n",
            "50: Copied from 'MainSet1' â†’ 50.jpg\n",
            "51: Copied from 'MainSet1' â†’ 51.jpg\n",
            "52: Copied from 'MainSet1' â†’ 52.jpg\n",
            "53: Copied from 'MainSet1' â†’ 53.jpg\n",
            "54: Copied from 'MainSet1' â†’ 54.jpg\n",
            "55: Copied from 'MainSet1' â†’ 55.jpg\n",
            "56: Copied from 'MainSet1' â†’ 56.jpg\n",
            "57: Copied from 'MainSet1' â†’ 57.jpg\n",
            "58: Copied from 'MainSet1' â†’ 58.jpg\n",
            "59: Copied from 'MainSet1' â†’ 59.jpg\n",
            "60: Copied from 'MainSet1' â†’ 60.jpg\n",
            "61: Copied from 'MainSet1' â†’ 61.jpg\n",
            "62: Copied from 'MainSet1' â†’ 62.jpg\n",
            "63: Copied from 'MainSet1' â†’ 63.jpg\n",
            "64: Copied from 'MainSet1' â†’ 64.jpg\n",
            "65: Copied from 'MainSet1' â†’ 65.jpg\n",
            "66: Copied from 'MainSet1' â†’ 66.jpg\n",
            "67: Copied from 'MainSet1' â†’ 67.jpg\n",
            "68: Copied from 'MainSet1' â†’ 68.jpg\n",
            "69: Copied from 'MainSet1' â†’ 69.jpg\n",
            "70: Copied from 'MainSet1' â†’ 70.jpg\n",
            "71: Copied from 'MainSet1' â†’ 71.jpg\n",
            "72: Copied from 'MainSet1' â†’ 72.jpg\n",
            "73: Copied from 'MainSet1' â†’ 73.jpg\n",
            "74: Copied from 'MainSet1' â†’ 74.jpg\n",
            "75: Copied from 'MainSet1' â†’ 75.jpg\n",
            "76: Copied from 'MainSet1' â†’ 76.jpg\n",
            "77: Copied from 'MainSet1' â†’ 77.jpg\n",
            "78: Copied from 'MainSet1' â†’ 78.jpg\n",
            "79: Copied from 'MainSet1' â†’ 79.jpg\n",
            "80: Copied from 'MainSet1' â†’ 80.jpg\n",
            "81: Copied from 'MainSet1' â†’ 81.jpg\n",
            "82: Copied from 'MainSet1' â†’ 82.jpg\n",
            "83: Copied from 'MainSet1' â†’ 83.jpg\n",
            "84: Copied from 'MainSet1' â†’ 84.jpg\n",
            "85: Copied from 'MainSet1' â†’ 85.jpg\n",
            "86: Copied from 'MainSet1' â†’ 86.jpg\n",
            "87: Copied from 'MainSet1' â†’ 87.jpg\n",
            "88: Copied from 'MainSet1' â†’ 88.jpg\n",
            "89: Copied from 'MainSet1' â†’ 89.jpg\n",
            "90: Copied from 'MainSet1' â†’ 90.jpg\n",
            "91: Copied from 'MainSet1' â†’ 91.jpg\n",
            "92: Copied from 'MainSet1' â†’ 92.jpg\n",
            "93: Copied from 'MainSet1' â†’ 93.jpg\n",
            "94: Copied from 'MainSet1' â†’ 94.jpg\n",
            "95: Copied from 'MainSet1' â†’ 95.jpg\n",
            "96: Copied from 'MainSet1' â†’ 96.jpg\n",
            "97: Copied from 'MainSet1' â†’ 97.jpg\n",
            "98: Copied from 'MainSet1' â†’ 98.jpg\n",
            "99: Copied from 'MainSet1' â†’ 99.jpg\n",
            "100: Copied from 'MainSet1' â†’ 100.jpg\n",
            "101: Copied from 'MainSet1' â†’ 101.jpg\n",
            "102: Copied from 'MainSet1' â†’ 102.jpg\n",
            "103: Copied from 'MainSet1' â†’ 103.jpg\n",
            "104: Copied from 'MainSet1' â†’ 104.jpg\n",
            "105: Copied from 'MainSet1' â†’ 105.jpg\n",
            "106: Copied from 'MainSet1' â†’ 106.jpg\n",
            "107: Copied from 'MainSet1' â†’ 107.jpg\n",
            "108: Copied from 'MainSet1' â†’ 108.jpg\n",
            "109: Copied from 'MainSet1' â†’ 109.jpg\n",
            "110: Copied from 'MainSet1' â†’ 110.jpg\n",
            "111: Copied from 'MainSet1' â†’ 111.jpg\n",
            "112: Copied from 'MainSet1' â†’ 112.jpg\n",
            "113: Copied from 'MainSet1' â†’ 113.jpg\n",
            "114: Copied from 'MainSet1' â†’ 114.jpg\n",
            "115: Copied from 'MainSet1' â†’ 115.jpg\n",
            "116: Copied from 'MainSet1' â†’ 116.jpg\n",
            "117: Copied from 'MainSet1' â†’ 117.jpg\n",
            "118: Copied from 'MainSet1' â†’ 118.jpg\n",
            "119: Copied from 'MainSet1' â†’ 119.jpg\n",
            "120: Copied from 'MainSet1' â†’ 120.jpg\n",
            "121: Copied from 'MainSet1' â†’ 121.jpg\n",
            "122: Copied from 'MainSet1' â†’ 122.jpg\n",
            "123: Copied from 'MainSet1' â†’ 123.jpg\n",
            "124: Copied from 'MainSet1' â†’ 124.jpg\n",
            "125: Copied from 'MainSet1' â†’ 125.jpg\n",
            "126: Copied from 'MainSet1' â†’ 126.jpg\n",
            "127: Copied from 'MainSet1' â†’ 127.jpg\n",
            "128: Copied from 'MainSet1' â†’ 128.jpg\n",
            "129: Copied from 'MainSet1' â†’ 129.jpg\n",
            "130: Copied from 'MainSet1' â†’ 130.jpg\n",
            "131: Copied from 'MainSet1' â†’ 131.jpg\n",
            "132: Copied from 'MainSet1' â†’ 132.jpg\n",
            "133: Copied from 'MainSet1' â†’ 133.jpg\n",
            "134: Copied from 'MainSet1' â†’ 134.jpg\n",
            "135: Copied from 'MainSet1' â†’ 135.jpg\n",
            "136: Copied from 'MainSet1' â†’ 136.jpg\n",
            "137: Copied from 'MainSet1' â†’ 137.jpg\n",
            "138: Copied from 'MainSet1' â†’ 138.jpg\n",
            "139: Copied from 'MainSet1' â†’ 139.jpg\n",
            "140: Copied from 'MainSet1' â†’ 140.jpg\n",
            "141: Copied from 'MainSet1' â†’ 141.jpg\n",
            "142: Copied from 'MainSet1' â†’ 142.jpg\n",
            "143: Copied from 'MainSet1' â†’ 143.jpg\n",
            "144: Copied from 'MainSet1' â†’ 144.jpg\n",
            "145: Copied from 'MainSet1' â†’ 145.jpg\n",
            "146: Copied from 'MainSet1' â†’ 146.jpg\n",
            "147: Copied from 'MainSet1' â†’ 147.jpg\n",
            "148: Copied from 'MainSet1' â†’ 148.jpg\n",
            "149: Copied from 'MainSet1' â†’ 149.jpg\n",
            "150: Copied from 'MainSet1' â†’ 150.jpg\n",
            "151: Copied from 'MainSet1' â†’ 151.jpg\n",
            "152: Copied from 'MainSet1' â†’ 152.jpg\n",
            "153: Copied from 'MainSet1' â†’ 153.jpg\n",
            "154: Copied from 'MainSet1' â†’ 154.jpg\n",
            "155: Copied from 'MainSet1' â†’ 155.jpg\n",
            "156: Copied from 'MainSet1' â†’ 156.jpg\n",
            "157: Copied from 'MainSet1' â†’ 157.jpg\n",
            "158: Copied from 'MainSet1' â†’ 158.jpg\n",
            "159: Copied from 'MainSet1' â†’ 159.jpg\n",
            "160: Copied from 'MainSet1' â†’ 160.jpg\n",
            "161: Copied from 'MainSet1' â†’ 161.jpg\n",
            "162: Copied from 'MainSet1' â†’ 162.jpg\n",
            "163: Copied from 'MainSet1' â†’ 163.jpg\n",
            "164: Copied from 'MainSet1' â†’ 164.jpg\n",
            "165: Copied from 'MainSet1' â†’ 165.jpg\n",
            "166: Copied from 'MainSet1' â†’ 166.jpg\n",
            "167: Copied from 'MainSet1' â†’ 167.jpg\n",
            "168: Copied from 'MainSet1' â†’ 168.jpg\n",
            "169: Copied from 'MainSet1' â†’ 169.jpg\n",
            "170: Copied from 'MainSet1' â†’ 170.jpg\n",
            "171: Copied from 'MainSet1' â†’ 171.jpg\n",
            "172: Copied from 'MainSet1' â†’ 172.jpg\n",
            "173: Copied from 'MainSet1' â†’ 173.jpg\n",
            "174: Copied from 'MainSet1' â†’ 174.jpg\n",
            "175: Copied from 'MainSet1' â†’ 175.jpg\n",
            "176: Copied from 'MainSet1' â†’ 176.jpg\n",
            "177: Copied from 'MainSet1' â†’ 177.jpg\n",
            "178: Copied from 'MainSet1' â†’ 178.jpg\n",
            "179: Copied from 'MainSet1' â†’ 179.jpg\n",
            "180: Copied from 'MainSet1' â†’ 180.jpg\n",
            "181: Copied from 'MainSet1' â†’ 181.jpg\n",
            "182: Copied from 'MainSet1' â†’ 182.jpg\n",
            "183: Copied from 'MainSet1' â†’ 183.jpg\n",
            "184: Copied from 'MainSet1' â†’ 184.jpg\n",
            "185: Copied from 'MainSet1' â†’ 185.jpg\n",
            "186: Copied from 'MainSet1' â†’ 186.jpg\n",
            "187: Copied from 'MainSet1' â†’ 187.jpg\n",
            "188: Copied from 'MainSet1' â†’ 188.jpg\n",
            "189: Copied from 'MainSet1' â†’ 189.jpg\n",
            "190: Copied from 'MainSet1' â†’ 190.jpg\n",
            "191: Copied from 'MainSet1' â†’ 191.jpg\n",
            "192: Copied from 'MainSet1' â†’ 192.jpg\n",
            "193: Copied from 'MainSet1' â†’ 193.jpg\n",
            "194: Copied from 'MainSet1' â†’ 194.jpg\n",
            "195: Copied from 'MainSet1' â†’ 195.jpg\n",
            "196: Copied from 'MainSet1' â†’ 196.jpg\n",
            "197: Copied from 'MainSet1' â†’ 197.jpg\n",
            "198: Copied from 'MainSet1' â†’ 198.jpg\n",
            "199: Copied from 'MainSet1' â†’ 199.jpg\n",
            "200: Copied from 'MainSet1' â†’ 200.jpg\n",
            "201: Copied from 'MainSet1' â†’ 201.jpg\n",
            "202: Copied from 'MainSet1' â†’ 202.jpg\n",
            "203: Copied from 'MainSet1' â†’ 203.jpg\n",
            "204: Copied from 'MainSet1' â†’ 204.jpg\n",
            "205: Copied from 'MainSet1' â†’ 205.jpg\n",
            "206: Copied from 'MainSet1' â†’ 206.jpg\n",
            "207: Copied from 'MainSet1' â†’ 207.jpg\n",
            "208: Copied from 'MainSet1' â†’ 208.jpg\n",
            "209: Copied from 'MainSet1' â†’ 209.jpg\n",
            "210: Copied from 'MainSet1' â†’ 210.jpg\n",
            "211: Copied from 'MainSet1' â†’ 211.jpg\n",
            "212: Copied from 'MainSet1' â†’ 212.jpg\n",
            "213: Copied from 'MainSet10' â†’ 213.jpg\n",
            "214: Copied from 'MainSet10' â†’ 214.jpg\n",
            "215: Copied from 'MainSet10' â†’ 215.jpg\n",
            "216: Copied from 'MainSet10' â†’ 216.jpg\n",
            "217: Copied from 'MainSet10' â†’ 217.jpg\n",
            "218: Copied from 'MainSet10' â†’ 218.jpg\n",
            "219: Copied from 'MainSet10' â†’ 219.jpg\n",
            "220: Copied from 'MainSet10' â†’ 220.jpg\n",
            "221: Copied from 'MainSet10' â†’ 221.jpg\n",
            "222: Copied from 'MainSet10' â†’ 222.jpg\n",
            "223: Copied from 'MainSet10' â†’ 223.jpg\n",
            "224: Copied from 'MainSet10' â†’ 224.jpg\n",
            "225: Copied from 'MainSet10' â†’ 225.jpg\n",
            "226: Copied from 'MainSet10' â†’ 226.jpg\n",
            "227: Copied from 'MainSet10' â†’ 227.jpg\n",
            "228: Copied from 'MainSet10' â†’ 228.jpg\n",
            "229: Copied from 'MainSet10' â†’ 229.jpg\n",
            "230: Copied from 'MainSet10' â†’ 230.jpg\n",
            "231: Copied from 'MainSet10' â†’ 231.jpg\n",
            "232: Copied from 'MainSet10' â†’ 232.jpg\n",
            "233: Copied from 'MainSet10' â†’ 233.jpg\n",
            "234: Copied from 'MainSet10' â†’ 234.jpg\n",
            "235: Copied from 'MainSet10' â†’ 235.jpg\n",
            "236: Copied from 'MainSet10' â†’ 236.jpg\n",
            "237: Copied from 'MainSet10' â†’ 237.jpg\n",
            "238: Copied from 'MainSet10' â†’ 238.jpg\n",
            "239: Copied from 'MainSet10' â†’ 239.jpg\n",
            "240: Copied from 'MainSet10' â†’ 240.jpg\n",
            "241: Copied from 'MainSet10' â†’ 241.jpg\n",
            "242: Copied from 'MainSet10' â†’ 242.jpg\n",
            "243: Copied from 'MainSet10' â†’ 243.jpg\n",
            "244: Copied from 'MainSet10' â†’ 244.jpg\n",
            "245: Copied from 'MainSet10' â†’ 245.jpg\n",
            "246: Copied from 'MainSet10' â†’ 246.jpg\n",
            "247: Copied from 'MainSet10' â†’ 247.jpg\n",
            "248: Copied from 'MainSet10' â†’ 248.jpg\n",
            "249: Copied from 'MainSet10' â†’ 249.jpg\n",
            "250: Copied from 'MainSet10' â†’ 250.jpg\n",
            "251: Copied from 'MainSet10' â†’ 251.jpg\n",
            "252: Copied from 'MainSet10' â†’ 252.jpg\n",
            "253: Copied from 'MainSet10' â†’ 253.jpg\n",
            "254: Copied from 'MainSet10' â†’ 254.jpg\n",
            "255: Copied from 'MainSet10' â†’ 255.jpg\n",
            "256: Copied from 'MainSet10' â†’ 256.jpg\n",
            "257: Copied from 'MainSet10' â†’ 257.jpg\n",
            "258: Copied from 'MainSet10' â†’ 258.jpg\n",
            "259: Copied from 'MainSet10' â†’ 259.jpg\n",
            "260: Copied from 'MainSet10' â†’ 260.jpg\n",
            "261: Copied from 'MainSet10' â†’ 261.jpg\n",
            "262: Copied from 'MainSet10' â†’ 262.jpg\n",
            "263: Copied from 'MainSet10' â†’ 263.jpg\n",
            "264: Copied from 'MainSet10' â†’ 264.jpg\n",
            "265: Copied from 'MainSet10' â†’ 265.jpg\n",
            "266: Copied from 'MainSet10' â†’ 266.jpg\n",
            "267: Copied from 'MainSet10' â†’ 267.jpg\n",
            "268: Copied from 'MainSet10' â†’ 268.jpg\n",
            "269: Copied from 'MainSet10' â†’ 269.jpg\n",
            "270: Copied from 'MainSet10' â†’ 270.jpg\n",
            "271: Copied from 'MainSet10' â†’ 271.jpg\n",
            "272: Copied from 'MainSet10' â†’ 272.jpg\n",
            "273: Copied from 'MainSet10' â†’ 273.jpg\n",
            "274: Copied from 'MainSet10' â†’ 274.jpg\n",
            "275: Copied from 'MainSet10' â†’ 275.jpg\n",
            "276: Copied from 'MainSet10' â†’ 276.jpg\n",
            "277: Copied from 'MainSet10' â†’ 277.jpg\n",
            "278: Copied from 'MainSet10' â†’ 278.jpg\n",
            "279: Copied from 'MainSet10' â†’ 279.jpg\n",
            "280: Copied from 'MainSet10' â†’ 280.jpg\n",
            "281: Copied from 'MainSet10' â†’ 281.jpg\n",
            "282: Copied from 'MainSet10' â†’ 282.jpg\n",
            "283: Copied from 'MainSet10' â†’ 283.jpg\n",
            "284: Copied from 'MainSet10' â†’ 284.jpg\n",
            "285: Copied from 'MainSet10' â†’ 285.jpg\n",
            "286: Copied from 'MainSet10' â†’ 286.jpg\n",
            "287: Copied from 'MainSet10' â†’ 287.jpg\n",
            "288: Copied from 'MainSet10' â†’ 288.jpg\n",
            "289: Copied from 'MainSet10' â†’ 289.jpg\n",
            "290: Copied from 'MainSet10' â†’ 290.jpg\n",
            "291: Copied from 'MainSet10' â†’ 291.jpg\n",
            "292: Copied from 'MainSet10' â†’ 292.jpg\n",
            "293: Copied from 'MainSet10' â†’ 293.jpg\n",
            "294: Copied from 'MainSet10' â†’ 294.jpg\n",
            "295: Copied from 'MainSet10' â†’ 295.jpg\n",
            "296: Copied from 'MainSet10' â†’ 296.jpg\n",
            "297: Copied from 'MainSet10' â†’ 297.jpg\n",
            "298: Copied from 'MainSet10' â†’ 298.jpg\n",
            "299: Copied from 'MainSet10' â†’ 299.jpg\n",
            "300: Copied from 'MainSet10' â†’ 300.jpg\n",
            "301: Copied from 'MainSet10' â†’ 301.jpg\n",
            "302: Copied from 'MainSet10' â†’ 302.jpg\n",
            "303: Copied from 'MainSet10' â†’ 303.jpg\n",
            "304: Copied from 'MainSet10' â†’ 304.jpg\n",
            "305: Copied from 'MainSet10' â†’ 305.jpg\n",
            "306: Copied from 'MainSet10' â†’ 306.jpg\n",
            "307: Copied from 'MainSet10' â†’ 307.jpg\n",
            "308: Copied from 'MainSet10' â†’ 308.jpg\n",
            "309: Copied from 'MainSet10' â†’ 309.jpg\n",
            "310: Copied from 'MainSet10' â†’ 310.jpg\n",
            "311: Copied from 'MainSet10' â†’ 311.jpg\n",
            "312: Copied from 'MainSet10' â†’ 312.jpg\n",
            "313: Copied from 'MainSet10' â†’ 313.jpg\n",
            "314: Copied from 'MainSet10' â†’ 314.jpg\n",
            "315: Copied from 'MainSet10' â†’ 315.jpg\n",
            "316: Copied from 'MainSet10' â†’ 316.jpg\n",
            "317: Copied from 'MainSet10' â†’ 317.jpg\n",
            "318: Copied from 'MainSet10' â†’ 318.jpg\n",
            "319: Copied from 'MainSet10' â†’ 319.jpg\n",
            "320: Copied from 'MainSet10' â†’ 320.jpg\n",
            "321: Copied from 'MainSet10' â†’ 321.jpg\n",
            "322: Copied from 'MainSet10' â†’ 322.jpg\n",
            "323: Copied from 'MainSet10' â†’ 323.jpg\n",
            "324: Copied from 'MainSet10' â†’ 324.jpg\n",
            "325: Copied from 'MainSet10' â†’ 325.jpg\n",
            "326: Copied from 'MainSet10' â†’ 326.jpg\n",
            "327: Copied from 'MainSet10' â†’ 327.jpg\n",
            "328: Copied from 'MainSet10' â†’ 328.jpg\n",
            "329: Copied from 'MainSet10' â†’ 329.jpg\n",
            "330: Copied from 'MainSet10' â†’ 330.jpg\n",
            "331: Copied from 'MainSet10' â†’ 331.jpg\n",
            "332: Copied from 'MainSet10' â†’ 332.jpg\n",
            "333: Copied from 'MainSet10' â†’ 333.jpg\n",
            "334: Copied from 'MainSet10' â†’ 334.jpg\n",
            "335: Copied from 'MainSet10' â†’ 335.jpg\n",
            "336: Copied from 'MainSet10' â†’ 336.jpg\n",
            "337: Copied from 'MainSet10' â†’ 337.jpg\n",
            "338: Copied from 'MainSet10' â†’ 338.jpg\n",
            "339: Copied from 'MainSet10' â†’ 339.jpg\n",
            "340: Copied from 'MainSet10' â†’ 340.jpg\n",
            "341: Copied from 'MainSet10' â†’ 341.jpg\n",
            "342: Copied from 'MainSet10' â†’ 342.jpg\n",
            "343: Copied from 'MainSet10' â†’ 343.jpg\n",
            "344: Copied from 'MainSet10' â†’ 344.jpg\n",
            "345: Copied from 'MainSet10' â†’ 345.jpg\n",
            "346: Copied from 'MainSet10' â†’ 346.jpg\n",
            "347: Copied from 'MainSet10' â†’ 347.jpg\n",
            "348: Copied from 'MainSet10' â†’ 348.jpg\n",
            "349: Copied from 'MainSet10' â†’ 349.jpg\n",
            "350: Copied from 'MainSet10' â†’ 350.jpg\n",
            "351: Copied from 'MainSet10' â†’ 351.jpg\n",
            "352: Copied from 'MainSet10' â†’ 352.jpg\n",
            "353: Copied from 'MainSet10' â†’ 353.jpg\n",
            "354: Copied from 'MainSet10' â†’ 354.jpg\n",
            "355: Copied from 'MainSet10' â†’ 355.jpg\n",
            "356: Copied from 'MainSet10' â†’ 356.jpg\n",
            "357: Copied from 'MainSet10' â†’ 357.jpg\n",
            "358: Copied from 'MainSet10' â†’ 358.jpg\n",
            "359: Copied from 'MainSet10' â†’ 359.jpg\n",
            "360: Copied from 'MainSet10' â†’ 360.jpg\n",
            "361: Copied from 'MainSet10' â†’ 361.jpg\n",
            "362: Copied from 'MainSet10' â†’ 362.jpg\n",
            "363: Copied from 'MainSet10' â†’ 363.jpg\n",
            "364: Copied from 'MainSet11' â†’ 364.jpg\n",
            "365: Copied from 'MainSet11' â†’ 365.jpg\n",
            "366: Copied from 'MainSet11' â†’ 366.jpg\n",
            "367: Copied from 'MainSet11' â†’ 367.jpg\n",
            "368: Copied from 'MainSet11' â†’ 368.jpg\n",
            "369: Copied from 'MainSet11' â†’ 369.jpg\n",
            "370: Copied from 'MainSet11' â†’ 370.jpg\n",
            "371: Copied from 'MainSet11' â†’ 371.jpg\n",
            "372: Copied from 'MainSet11' â†’ 372.jpg\n",
            "373: Copied from 'MainSet11' â†’ 373.jpg\n",
            "374: Copied from 'MainSet11' â†’ 374.jpg\n",
            "375: Copied from 'MainSet11' â†’ 375.jpg\n",
            "376: Copied from 'MainSet11' â†’ 376.jpg\n",
            "377: Copied from 'MainSet11' â†’ 377.jpg\n",
            "378: Copied from 'MainSet11' â†’ 378.jpg\n",
            "379: Copied from 'MainSet11' â†’ 379.jpg\n",
            "380: Copied from 'MainSet11' â†’ 380.jpg\n",
            "381: Copied from 'MainSet11' â†’ 381.jpg\n",
            "382: Copied from 'MainSet11' â†’ 382.jpg\n",
            "383: Copied from 'MainSet11' â†’ 383.jpg\n",
            "384: Copied from 'MainSet11' â†’ 384.jpg\n",
            "385: Copied from 'MainSet11' â†’ 385.jpg\n",
            "386: Copied from 'MainSet11' â†’ 386.jpg\n",
            "387: Copied from 'MainSet11' â†’ 387.jpg\n",
            "388: Copied from 'MainSet11' â†’ 388.jpg\n",
            "389: Copied from 'MainSet11' â†’ 389.jpg\n",
            "390: Copied from 'MainSet11' â†’ 390.jpg\n",
            "391: Copied from 'MainSet11' â†’ 391.jpg\n",
            "392: Copied from 'MainSet11' â†’ 392.jpg\n",
            "393: Copied from 'MainSet11' â†’ 393.jpg\n",
            "394: Copied from 'MainSet11' â†’ 394.jpg\n",
            "395: Copied from 'MainSet11' â†’ 395.jpg\n",
            "396: Copied from 'MainSet11' â†’ 396.jpg\n",
            "397: Copied from 'MainSet11' â†’ 397.jpg\n",
            "398: Copied from 'MainSet11' â†’ 398.jpg\n",
            "399: Copied from 'MainSet11' â†’ 399.jpg\n",
            "400: Copied from 'MainSet11' â†’ 400.jpg\n",
            "401: Copied from 'MainSet11' â†’ 401.jpg\n",
            "402: Copied from 'MainSet11' â†’ 402.jpg\n",
            "403: Copied from 'MainSet11' â†’ 403.jpg\n",
            "404: Copied from 'MainSet11' â†’ 404.jpg\n",
            "405: Copied from 'MainSet11' â†’ 405.jpg\n",
            "406: Copied from 'MainSet11' â†’ 406.jpg\n",
            "407: Copied from 'MainSet11' â†’ 407.jpg\n",
            "408: Copied from 'MainSet11' â†’ 408.jpg\n",
            "409: Copied from 'MainSet11' â†’ 409.jpg\n",
            "410: Copied from 'MainSet11' â†’ 410.jpg\n",
            "411: Copied from 'MainSet11' â†’ 411.jpg\n",
            "412: Copied from 'MainSet11' â†’ 412.jpg\n",
            "413: Copied from 'MainSet11' â†’ 413.jpg\n",
            "414: Copied from 'MainSet11' â†’ 414.jpg\n",
            "415: Copied from 'MainSet11' â†’ 415.jpg\n",
            "416: Copied from 'MainSet11' â†’ 416.jpg\n",
            "417: Copied from 'MainSet11' â†’ 417.jpg\n",
            "418: Copied from 'MainSet11' â†’ 418.jpg\n",
            "419: Copied from 'MainSet11' â†’ 419.jpg\n",
            "420: Copied from 'MainSet11' â†’ 420.jpg\n",
            "421: Copied from 'MainSet11' â†’ 421.jpg\n",
            "422: Copied from 'MainSet11' â†’ 422.jpg\n",
            "423: Copied from 'MainSet11' â†’ 423.jpg\n",
            "424: Copied from 'MainSet11' â†’ 424.jpg\n",
            "425: Copied from 'MainSet11' â†’ 425.jpg\n",
            "426: Copied from 'MainSet11' â†’ 426.jpg\n",
            "427: Copied from 'MainSet11' â†’ 427.jpg\n",
            "428: Copied from 'MainSet11' â†’ 428.jpg\n",
            "429: Copied from 'MainSet11' â†’ 429.jpg\n",
            "430: Copied from 'MainSet11' â†’ 430.jpg\n",
            "431: Copied from 'MainSet11' â†’ 431.jpg\n",
            "432: Copied from 'MainSet11' â†’ 432.jpg\n",
            "433: Copied from 'MainSet11' â†’ 433.jpg\n",
            "434: Copied from 'MainSet11' â†’ 434.jpg\n",
            "435: Copied from 'MainSet11' â†’ 435.jpg\n",
            "436: Copied from 'MainSet11' â†’ 436.jpg\n",
            "437: Copied from 'MainSet11' â†’ 437.jpg\n",
            "438: Copied from 'MainSet11' â†’ 438.jpg\n",
            "439: Copied from 'MainSet11' â†’ 439.jpg\n",
            "440: Copied from 'MainSet11' â†’ 440.jpg\n",
            "441: Copied from 'MainSet11' â†’ 441.jpg\n",
            "442: Copied from 'MainSet11' â†’ 442.jpg\n",
            "443: Copied from 'MainSet11' â†’ 443.jpg\n",
            "444: Copied from 'MainSet11' â†’ 444.jpg\n",
            "445: Copied from 'MainSet11' â†’ 445.jpg\n",
            "446: Copied from 'MainSet11' â†’ 446.jpg\n",
            "447: Copied from 'MainSet11' â†’ 447.jpg\n",
            "448: Copied from 'MainSet11' â†’ 448.jpg\n",
            "449: Copied from 'MainSet11' â†’ 449.jpg\n",
            "450: Copied from 'MainSet11' â†’ 450.jpg\n",
            "451: Copied from 'MainSet11' â†’ 451.jpg\n",
            "452: Copied from 'MainSet11' â†’ 452.jpg\n",
            "453: Copied from 'MainSet11' â†’ 453.jpg\n",
            "454: Copied from 'MainSet11' â†’ 454.jpg\n",
            "455: Copied from 'MainSet11' â†’ 455.jpg\n",
            "456: Copied from 'MainSet11' â†’ 456.jpg\n",
            "457: Copied from 'MainSet11' â†’ 457.jpg\n",
            "458: Copied from 'MainSet11' â†’ 458.jpg\n",
            "459: Copied from 'MainSet11' â†’ 459.jpg\n",
            "460: Copied from 'MainSet11' â†’ 460.jpg\n",
            "461: Copied from 'MainSet11' â†’ 461.jpg\n",
            "462: Copied from 'MainSet11' â†’ 462.jpg\n",
            "463: Copied from 'MainSet11' â†’ 463.jpg\n",
            "464: Copied from 'MainSet11' â†’ 464.jpg\n",
            "465: Copied from 'MainSet11' â†’ 465.jpg\n",
            "466: Copied from 'MainSet11' â†’ 466.jpg\n",
            "467: Copied from 'MainSet11' â†’ 467.jpg\n",
            "468: Copied from 'MainSet11' â†’ 468.jpg\n",
            "469: Copied from 'MainSet11' â†’ 469.jpg\n",
            "470: Copied from 'MainSet11' â†’ 470.jpg\n",
            "471: Copied from 'MainSet11' â†’ 471.jpg\n",
            "472: Copied from 'MainSet11' â†’ 472.jpg\n",
            "473: Copied from 'MainSet11' â†’ 473.jpg\n",
            "474: Copied from 'MainSet11' â†’ 474.jpg\n",
            "475: Copied from 'MainSet11' â†’ 475.jpg\n",
            "476: Copied from 'MainSet11' â†’ 476.jpg\n",
            "477: Copied from 'MainSet11' â†’ 477.jpg\n",
            "478: Copied from 'MainSet11' â†’ 478.jpg\n",
            "479: Copied from 'MainSet11' â†’ 479.jpg\n",
            "480: Copied from 'MainSet11' â†’ 480.jpg\n",
            "481: Copied from 'MainSet11' â†’ 481.jpg\n",
            "482: Copied from 'MainSet11' â†’ 482.jpg\n",
            "483: Copied from 'MainSet11' â†’ 483.jpg\n",
            "484: Copied from 'MainSet11' â†’ 484.jpg\n",
            "485: Copied from 'MainSet11' â†’ 485.jpg\n",
            "486: Copied from 'MainSet11' â†’ 486.jpg\n",
            "487: Copied from 'MainSet11' â†’ 487.jpg\n",
            "488: Copied from 'MainSet11' â†’ 488.jpg\n",
            "489: Copied from 'MainSet11' â†’ 489.jpg\n",
            "490: Copied from 'MainSet11' â†’ 490.jpg\n",
            "491: Copied from 'MainSet11' â†’ 491.jpg\n",
            "492: Copied from 'MainSet11' â†’ 492.jpg\n",
            "493: Copied from 'MainSet11' â†’ 493.jpg\n",
            "494: Copied from 'MainSet11' â†’ 494.jpg\n",
            "495: Copied from 'MainSet11' â†’ 495.jpg\n",
            "496: Copied from 'MainSet11' â†’ 496.jpg\n",
            "497: Copied from 'MainSet11' â†’ 497.jpg\n",
            "498: Copied from 'MainSet11' â†’ 498.jpg\n",
            "499: Copied from 'MainSet11' â†’ 499.jpg\n",
            "500: Copied from 'MainSet12' â†’ 500.jpg\n",
            "501: Copied from 'MainSet12' â†’ 501.jpg\n",
            "502: Copied from 'MainSet12' â†’ 502.jpg\n",
            "503: Copied from 'MainSet12' â†’ 503.jpg\n",
            "504: Copied from 'MainSet12' â†’ 504.jpg\n",
            "505: Copied from 'MainSet12' â†’ 505.jpg\n",
            "506: Copied from 'MainSet12' â†’ 506.jpg\n",
            "507: Copied from 'MainSet12' â†’ 507.jpg\n",
            "508: Copied from 'MainSet12' â†’ 508.jpg\n",
            "509: Copied from 'MainSet12' â†’ 509.jpg\n",
            "510: Copied from 'MainSet12' â†’ 510.jpg\n",
            "511: Copied from 'MainSet12' â†’ 511.jpg\n",
            "512: Copied from 'MainSet12' â†’ 512.jpg\n",
            "513: Copied from 'MainSet12' â†’ 513.jpg\n",
            "514: Copied from 'MainSet12' â†’ 514.jpg\n",
            "515: Copied from 'MainSet12' â†’ 515.jpg\n",
            "516: Copied from 'MainSet12' â†’ 516.jpg\n",
            "517: Copied from 'MainSet12' â†’ 517.jpg\n",
            "518: Copied from 'MainSet12' â†’ 518.jpg\n",
            "519: Copied from 'MainSet12' â†’ 519.jpg\n",
            "520: Copied from 'MainSet12' â†’ 520.jpg\n",
            "521: Copied from 'MainSet12' â†’ 521.jpg\n",
            "522: Copied from 'MainSet12' â†’ 522.jpg\n",
            "523: Copied from 'MainSet12' â†’ 523.jpg\n",
            "524: Copied from 'MainSet12' â†’ 524.jpg\n",
            "525: Copied from 'MainSet12' â†’ 525.jpg\n",
            "526: Copied from 'MainSet12' â†’ 526.jpg\n",
            "527: Copied from 'MainSet12' â†’ 527.jpg\n",
            "528: Copied from 'MainSet12' â†’ 528.jpg\n",
            "529: Copied from 'MainSet12' â†’ 529.jpg\n",
            "530: Copied from 'MainSet12' â†’ 530.jpg\n",
            "531: Copied from 'MainSet12' â†’ 531.jpg\n",
            "532: Copied from 'MainSet12' â†’ 532.jpg\n",
            "533: Copied from 'MainSet12' â†’ 533.jpg\n",
            "534: Copied from 'MainSet12' â†’ 534.jpg\n",
            "535: Copied from 'MainSet12' â†’ 535.jpg\n",
            "536: Copied from 'MainSet12' â†’ 536.jpg\n",
            "537: Copied from 'MainSet12' â†’ 537.jpg\n",
            "538: Copied from 'MainSet12' â†’ 538.jpg\n",
            "539: Copied from 'MainSet12' â†’ 539.jpg\n",
            "540: Copied from 'MainSet12' â†’ 540.jpg\n",
            "541: Copied from 'MainSet12' â†’ 541.jpg\n",
            "542: Copied from 'MainSet12' â†’ 542.jpg\n",
            "543: Copied from 'MainSet12' â†’ 543.jpg\n",
            "544: Copied from 'MainSet12' â†’ 544.jpg\n",
            "545: Copied from 'MainSet12' â†’ 545.jpg\n",
            "546: Copied from 'MainSet12' â†’ 546.jpg\n",
            "547: Copied from 'MainSet12' â†’ 547.jpg\n",
            "548: Copied from 'MainSet12' â†’ 548.jpg\n",
            "549: Copied from 'MainSet12' â†’ 549.jpg\n",
            "550: Copied from 'MainSet12' â†’ 550.jpg\n",
            "551: Copied from 'MainSet12' â†’ 551.jpg\n",
            "552: Copied from 'MainSet12' â†’ 552.jpg\n",
            "553: Copied from 'MainSet12' â†’ 553.jpg\n",
            "554: Copied from 'MainSet12' â†’ 554.jpg\n",
            "555: Copied from 'MainSet12' â†’ 555.jpg\n",
            "556: Copied from 'MainSet12' â†’ 556.jpg\n",
            "557: Copied from 'MainSet12' â†’ 557.jpg\n",
            "558: Copied from 'MainSet12' â†’ 558.jpg\n",
            "559: Copied from 'MainSet12' â†’ 559.jpg\n",
            "560: Copied from 'MainSet12' â†’ 560.jpg\n",
            "561: Copied from 'MainSet12' â†’ 561.jpg\n",
            "562: Copied from 'MainSet12' â†’ 562.jpg\n",
            "563: Copied from 'MainSet12' â†’ 563.jpg\n",
            "564: Copied from 'MainSet12' â†’ 564.jpg\n",
            "565: Copied from 'MainSet12' â†’ 565.jpg\n",
            "566: Copied from 'MainSet12' â†’ 566.jpg\n",
            "567: Copied from 'MainSet12' â†’ 567.jpg\n",
            "568: Copied from 'MainSet12' â†’ 568.jpg\n",
            "569: Copied from 'MainSet12' â†’ 569.jpg\n",
            "570: Copied from 'MainSet12' â†’ 570.jpg\n",
            "571: Copied from 'MainSet12' â†’ 571.jpg\n",
            "572: Copied from 'MainSet12' â†’ 572.jpg\n",
            "573: Copied from 'MainSet12' â†’ 573.jpg\n",
            "574: Copied from 'MainSet12' â†’ 574.jpg\n",
            "575: Copied from 'MainSet12' â†’ 575.jpg\n",
            "576: Copied from 'MainSet12' â†’ 576.jpg\n",
            "577: Copied from 'MainSet12' â†’ 577.jpg\n",
            "578: Copied from 'MainSet12' â†’ 578.jpg\n",
            "579: Copied from 'MainSet12' â†’ 579.jpg\n",
            "580: Copied from 'MainSet12' â†’ 580.jpg\n",
            "581: Copied from 'MainSet12' â†’ 581.jpg\n",
            "582: Copied from 'MainSet12' â†’ 582.jpg\n",
            "583: Copied from 'MainSet12' â†’ 583.jpg\n",
            "584: Copied from 'MainSet12' â†’ 584.jpg\n",
            "585: Copied from 'MainSet12' â†’ 585.jpg\n",
            "586: Copied from 'MainSet12' â†’ 586.jpg\n",
            "587: Copied from 'MainSet12' â†’ 587.jpg\n",
            "588: Copied from 'MainSet12' â†’ 588.jpg\n",
            "589: Copied from 'MainSet12' â†’ 589.jpg\n",
            "590: Copied from 'MainSet12' â†’ 590.jpg\n",
            "591: Copied from 'MainSet12' â†’ 591.jpg\n",
            "592: Copied from 'MainSet12' â†’ 592.jpg\n",
            "593: Copied from 'MainSet12' â†’ 593.jpg\n",
            "594: Copied from 'MainSet12' â†’ 594.jpg\n",
            "595: Copied from 'MainSet12' â†’ 595.jpg\n",
            "596: Copied from 'MainSet12' â†’ 596.jpg\n",
            "597: Copied from 'MainSet12' â†’ 597.jpg\n",
            "598: Copied from 'MainSet12' â†’ 598.jpg\n",
            "599: Copied from 'MainSet12' â†’ 599.jpg\n",
            "600: Copied from 'MainSet12' â†’ 600.jpg\n",
            "601: Copied from 'MainSet12' â†’ 601.jpg\n",
            "602: Copied from 'MainSet12' â†’ 602.jpg\n",
            "603: Copied from 'MainSet12' â†’ 603.jpg\n",
            "604: Copied from 'MainSet12' â†’ 604.jpg\n",
            "605: Copied from 'MainSet12' â†’ 605.jpg\n",
            "606: Copied from 'MainSet12' â†’ 606.jpg\n",
            "607: Copied from 'MainSet12' â†’ 607.jpg\n",
            "608: Copied from 'MainSet12' â†’ 608.jpg\n",
            "609: Copied from 'MainSet12' â†’ 609.jpg\n",
            "610: Copied from 'MainSet12' â†’ 610.jpg\n",
            "611: Copied from 'MainSet12' â†’ 611.jpg\n",
            "612: Copied from 'MainSet12' â†’ 612.jpg\n",
            "613: Copied from 'MainSet12' â†’ 613.jpg\n",
            "614: Copied from 'MainSet12' â†’ 614.jpg\n",
            "615: Copied from 'MainSet12' â†’ 615.jpg\n",
            "616: Copied from 'MainSet12' â†’ 616.jpg\n",
            "617: Copied from 'MainSet13' â†’ 617.jpg\n",
            "618: Copied from 'MainSet13' â†’ 618.jpg\n",
            "619: Copied from 'MainSet13' â†’ 619.jpg\n",
            "620: Copied from 'MainSet13' â†’ 620.jpg\n",
            "621: Copied from 'MainSet13' â†’ 621.jpg\n",
            "622: Copied from 'MainSet13' â†’ 622.jpg\n",
            "623: Copied from 'MainSet13' â†’ 623.jpg\n",
            "624: Copied from 'MainSet13' â†’ 624.jpg\n",
            "625: Copied from 'MainSet13' â†’ 625.jpg\n",
            "626: Copied from 'MainSet13' â†’ 626.jpg\n",
            "627: Copied from 'MainSet13' â†’ 627.jpg\n",
            "628: Copied from 'MainSet13' â†’ 628.jpg\n",
            "629: Copied from 'MainSet13' â†’ 629.jpg\n",
            "630: Copied from 'MainSet13' â†’ 630.jpg\n",
            "631: Copied from 'MainSet13' â†’ 631.jpg\n",
            "632: Copied from 'MainSet13' â†’ 632.jpg\n",
            "633: Copied from 'MainSet13' â†’ 633.jpg\n",
            "634: Copied from 'MainSet13' â†’ 634.jpg\n",
            "635: Copied from 'MainSet13' â†’ 635.jpg\n",
            "636: Copied from 'MainSet13' â†’ 636.jpg\n",
            "637: Copied from 'MainSet13' â†’ 637.jpg\n",
            "638: Copied from 'MainSet13' â†’ 638.jpg\n",
            "639: Copied from 'MainSet13' â†’ 639.jpg\n",
            "640: Copied from 'MainSet13' â†’ 640.jpg\n",
            "641: Copied from 'MainSet13' â†’ 641.jpg\n",
            "642: Copied from 'MainSet13' â†’ 642.jpg\n",
            "643: Copied from 'MainSet13' â†’ 643.jpg\n",
            "644: Copied from 'MainSet13' â†’ 644.jpg\n",
            "645: Copied from 'MainSet13' â†’ 645.jpg\n",
            "646: Copied from 'MainSet13' â†’ 646.jpg\n",
            "647: Copied from 'MainSet13' â†’ 647.jpg\n",
            "648: Copied from 'MainSet13' â†’ 648.jpg\n",
            "649: Copied from 'MainSet13' â†’ 649.jpg\n",
            "650: Copied from 'MainSet13' â†’ 650.jpg\n",
            "651: Copied from 'MainSet13' â†’ 651.jpg\n",
            "652: Copied from 'MainSet13' â†’ 652.jpg\n",
            "653: Copied from 'MainSet13' â†’ 653.jpg\n",
            "654: Copied from 'MainSet13' â†’ 654.jpg\n",
            "655: Copied from 'MainSet13' â†’ 655.jpg\n",
            "656: Copied from 'MainSet13' â†’ 656.jpg\n",
            "657: Copied from 'MainSet13' â†’ 657.jpg\n",
            "658: Copied from 'MainSet13' â†’ 658.jpg\n",
            "659: Copied from 'MainSet13' â†’ 659.jpg\n",
            "660: Copied from 'MainSet13' â†’ 660.jpg\n",
            "661: Copied from 'MainSet13' â†’ 661.jpg\n",
            "662: Copied from 'MainSet13' â†’ 662.jpg\n",
            "663: Copied from 'MainSet13' â†’ 663.jpg\n",
            "664: Copied from 'MainSet13' â†’ 664.jpg\n",
            "665: Copied from 'MainSet13' â†’ 665.jpg\n",
            "666: Copied from 'MainSet13' â†’ 666.jpg\n",
            "667: Copied from 'MainSet13' â†’ 667.jpg\n",
            "668: Copied from 'MainSet13' â†’ 668.jpg\n",
            "669: Copied from 'MainSet13' â†’ 669.jpg\n",
            "670: Copied from 'MainSet13' â†’ 670.jpg\n",
            "671: Copied from 'MainSet13' â†’ 671.jpg\n",
            "672: Copied from 'MainSet13' â†’ 672.jpg\n",
            "673: Copied from 'MainSet13' â†’ 673.jpg\n",
            "674: Copied from 'MainSet13' â†’ 674.jpg\n",
            "675: Copied from 'MainSet13' â†’ 675.jpg\n",
            "676: Copied from 'MainSet13' â†’ 676.jpg\n",
            "677: Copied from 'MainSet13' â†’ 677.jpg\n",
            "678: Copied from 'MainSet13' â†’ 678.jpg\n",
            "679: Copied from 'MainSet13' â†’ 679.jpg\n",
            "680: Copied from 'MainSet13' â†’ 680.jpg\n",
            "681: Copied from 'MainSet13' â†’ 681.jpg\n",
            "682: Copied from 'MainSet13' â†’ 682.jpg\n",
            "683: Copied from 'MainSet13' â†’ 683.jpg\n",
            "684: Copied from 'MainSet13' â†’ 684.jpg\n",
            "685: Copied from 'MainSet13' â†’ 685.jpg\n",
            "686: Copied from 'MainSet13' â†’ 686.jpg\n",
            "687: Copied from 'MainSet13' â†’ 687.jpg\n",
            "688: Copied from 'MainSet13' â†’ 688.jpg\n",
            "689: Copied from 'MainSet13' â†’ 689.jpg\n",
            "690: Copied from 'MainSet13' â†’ 690.jpg\n",
            "691: Copied from 'MainSet13' â†’ 691.jpg\n",
            "692: Copied from 'MainSet13' â†’ 692.jpg\n",
            "693: Copied from 'MainSet13' â†’ 693.jpg\n",
            "694: Copied from 'MainSet13' â†’ 694.jpg\n",
            "695: Copied from 'MainSet13' â†’ 695.jpg\n",
            "696: Copied from 'MainSet13' â†’ 696.jpg\n",
            "697: Copied from 'MainSet13' â†’ 697.jpg\n",
            "698: Copied from 'MainSet13' â†’ 698.jpg\n",
            "699: Copied from 'MainSet13' â†’ 699.jpg\n",
            "700: Copied from 'MainSet13' â†’ 700.jpg\n",
            "701: Copied from 'MainSet13' â†’ 701.jpg\n",
            "702: Copied from 'MainSet13' â†’ 702.jpg\n",
            "703: Copied from 'MainSet13' â†’ 703.jpg\n",
            "704: Copied from 'MainSet13' â†’ 704.jpg\n",
            "705: Copied from 'MainSet13' â†’ 705.jpg\n",
            "706: Copied from 'MainSet13' â†’ 706.jpg\n",
            "707: Copied from 'MainSet13' â†’ 707.jpg\n",
            "708: Copied from 'MainSet13' â†’ 708.jpg\n",
            "709: Copied from 'MainSet13' â†’ 709.jpg\n",
            "710: Copied from 'MainSet13' â†’ 710.jpg\n",
            "711: Copied from 'MainSet13' â†’ 711.jpg\n",
            "712: Copied from 'MainSet13' â†’ 712.jpg\n",
            "713: Copied from 'MainSet13' â†’ 713.jpg\n",
            "714: Copied from 'MainSet13' â†’ 714.jpg\n",
            "715: Copied from 'MainSet13' â†’ 715.jpg\n",
            "716: Copied from 'MainSet13' â†’ 716.jpg\n",
            "717: Copied from 'MainSet13' â†’ 717.jpg\n",
            "718: Copied from 'MainSet13' â†’ 718.jpg\n",
            "719: Copied from 'MainSet13' â†’ 719.jpg\n",
            "720: Copied from 'MainSet13' â†’ 720.jpg\n",
            "721: Copied from 'MainSet13' â†’ 721.jpg\n",
            "722: Copied from 'MainSet13' â†’ 722.jpg\n",
            "723: Copied from 'MainSet13' â†’ 723.jpg\n",
            "724: Copied from 'MainSet13' â†’ 724.jpg\n",
            "725: Copied from 'MainSet13' â†’ 725.jpg\n",
            "726: Copied from 'MainSet13' â†’ 726.jpg\n",
            "727: Copied from 'MainSet13' â†’ 727.jpg\n",
            "728: Copied from 'MainSet13' â†’ 728.jpg\n",
            "729: Copied from 'MainSet13' â†’ 729.jpg\n",
            "730: Copied from 'MainSet13' â†’ 730.jpg\n",
            "731: Copied from 'MainSet13' â†’ 731.jpg\n",
            "732: Copied from 'MainSet13' â†’ 732.jpg\n",
            "733: Copied from 'MainSet13' â†’ 733.jpg\n",
            "734: Copied from 'MainSet13' â†’ 734.jpg\n",
            "735: Copied from 'MainSet13' â†’ 735.jpg\n",
            "736: Copied from 'MainSet13' â†’ 736.jpg\n",
            "737: Copied from 'MainSet13' â†’ 737.jpg\n",
            "738: Copied from 'MainSet13' â†’ 738.jpg\n",
            "739: Copied from 'MainSet13' â†’ 739.jpg\n",
            "740: Copied from 'MainSet13' â†’ 740.jpg\n",
            "741: Copied from 'MainSet13' â†’ 741.jpg\n",
            "742: Copied from 'MainSet13' â†’ 742.jpg\n",
            "743: Copied from 'MainSet13' â†’ 743.jpg\n",
            "744: Copied from 'MainSet13' â†’ 744.jpg\n",
            "745: Copied from 'MainSet13' â†’ 745.jpg\n",
            "746: Copied from 'MainSet13' â†’ 746.jpg\n",
            "747: Copied from 'MainSet13' â†’ 747.jpg\n",
            "748: Copied from 'MainSet13' â†’ 748.jpg\n",
            "749: Copied from 'MainSet13' â†’ 749.jpg\n",
            "750: Copied from 'MainSet13' â†’ 750.jpg\n",
            "751: Copied from 'MainSet13' â†’ 751.jpg\n",
            "752: Copied from 'MainSet13' â†’ 752.jpg\n",
            "753: Copied from 'MainSet13' â†’ 753.jpg\n",
            "754: Copied from 'MainSet13' â†’ 754.jpg\n",
            "755: Copied from 'MainSet13' â†’ 755.jpg\n",
            "756: Copied from 'MainSet13' â†’ 756.jpg\n",
            "757: Copied from 'MainSet13' â†’ 757.jpg\n",
            "758: Copied from 'MainSet13' â†’ 758.jpg\n",
            "759: Copied from 'MainSet13' â†’ 759.jpg\n",
            "760: Copied from 'MainSet13' â†’ 760.jpg\n",
            "761: Copied from 'MainSet13' â†’ 761.jpg\n",
            "762: Copied from 'MainSet13' â†’ 762.jpg\n",
            "763: Copied from 'MainSet13' â†’ 763.jpg\n",
            "764: Copied from 'MainSet13' â†’ 764.jpg\n",
            "765: Copied from 'MainSet13' â†’ 765.jpg\n",
            "766: Copied from 'MainSet13' â†’ 766.jpg\n",
            "767: Copied from 'MainSet13' â†’ 767.jpg\n",
            "768: Copied from 'MainSet13' â†’ 768.jpg\n",
            "769: Copied from 'MainSet13' â†’ 769.jpg\n",
            "770: Copied from 'MainSet13' â†’ 770.jpg\n",
            "771: Copied from 'MainSet13' â†’ 771.jpg\n",
            "772: Copied from 'MainSet13' â†’ 772.jpg\n",
            "773: Copied from 'MainSet13' â†’ 773.jpg\n",
            "774: Copied from 'MainSet13' â†’ 774.jpg\n",
            "775: Copied from 'MainSet13' â†’ 775.jpg\n",
            "776: Copied from 'MainSet13' â†’ 776.jpg\n",
            "777: Copied from 'MainSet13' â†’ 777.jpg\n",
            "778: Copied from 'MainSet13' â†’ 778.jpg\n",
            "779: Copied from 'MainSet13' â†’ 779.jpg\n",
            "780: Copied from 'MainSet13' â†’ 780.jpg\n",
            "781: Copied from 'MainSet13' â†’ 781.jpg\n",
            "782: Copied from 'MainSet13' â†’ 782.jpg\n",
            "783: Copied from 'MainSet13' â†’ 783.jpg\n",
            "784: Copied from 'MainSet13' â†’ 784.jpg\n",
            "785: Copied from 'MainSet13' â†’ 785.jpg\n",
            "786: Copied from 'MainSet13' â†’ 786.jpg\n",
            "787: Copied from 'MainSet13' â†’ 787.jpg\n",
            "788: Copied from 'MainSet13' â†’ 788.jpg\n",
            "789: Copied from 'MainSet13' â†’ 789.jpg\n",
            "790: Copied from 'MainSet13' â†’ 790.jpg\n",
            "791: Copied from 'MainSet13' â†’ 791.jpg\n",
            "792: Copied from 'MainSet13' â†’ 792.jpg\n",
            "793: Copied from 'MainSet13' â†’ 793.jpg\n",
            "794: Copied from 'MainSet13' â†’ 794.jpg\n",
            "795: Copied from 'MainSet13' â†’ 795.jpg\n",
            "796: Copied from 'MainSet13' â†’ 796.jpg\n",
            "797: Copied from 'MainSet13' â†’ 797.jpg\n",
            "798: Copied from 'MainSet13' â†’ 798.jpg\n",
            "799: Copied from 'MainSet13' â†’ 799.jpg\n",
            "800: Copied from 'MainSet13' â†’ 800.jpg\n",
            "801: Copied from 'MainSet13' â†’ 801.jpg\n",
            "802: Copied from 'MainSet13' â†’ 802.jpg\n",
            "803: Copied from 'MainSet13' â†’ 803.jpg\n",
            "804: Copied from 'MainSet13' â†’ 804.jpg\n",
            "805: Copied from 'MainSet13' â†’ 805.jpg\n",
            "806: Copied from 'MainSet13' â†’ 806.jpg\n",
            "807: Copied from 'MainSet13' â†’ 807.jpg\n",
            "808: Copied from 'MainSet13' â†’ 808.jpg\n",
            "809: Copied from 'MainSet13' â†’ 809.jpg\n",
            "810: Copied from 'MainSet13' â†’ 810.jpg\n",
            "811: Copied from 'MainSet13' â†’ 811.jpg\n",
            "812: Copied from 'MainSet13' â†’ 812.jpg\n",
            "813: Copied from 'MainSet13' â†’ 813.jpg\n",
            "814: Copied from 'MainSet13' â†’ 814.jpg\n",
            "815: Copied from 'MainSet13' â†’ 815.jpg\n",
            "816: Copied from 'MainSet13' â†’ 816.jpg\n",
            "817: Copied from 'MainSet13' â†’ 817.jpg\n",
            "818: Copied from 'MainSet13' â†’ 818.jpg\n",
            "819: Copied from 'MainSet13' â†’ 819.jpg\n",
            "820: Copied from 'MainSet13' â†’ 820.jpg\n",
            "821: Copied from 'MainSet13' â†’ 821.jpg\n",
            "822: Copied from 'MainSet13' â†’ 822.jpg\n",
            "823: Copied from 'MainSet13' â†’ 823.jpg\n",
            "824: Copied from 'MainSet13' â†’ 824.jpg\n",
            "825: Copied from 'MainSet13' â†’ 825.jpg\n",
            "826: Copied from 'MainSet13' â†’ 826.jpg\n",
            "827: Copied from 'MainSet13' â†’ 827.jpg\n",
            "828: Copied from 'MainSet13' â†’ 828.jpg\n",
            "829: Copied from 'MainSet14' â†’ 829.jpg\n",
            "830: Copied from 'MainSet14' â†’ 830.jpg\n",
            "831: Copied from 'MainSet14' â†’ 831.jpg\n",
            "832: Copied from 'MainSet14' â†’ 832.jpg\n",
            "833: Copied from 'MainSet14' â†’ 833.jpg\n",
            "834: Copied from 'MainSet14' â†’ 834.jpg\n",
            "835: Copied from 'MainSet14' â†’ 835.jpg\n",
            "836: Copied from 'MainSet14' â†’ 836.jpg\n",
            "837: Copied from 'MainSet14' â†’ 837.jpg\n",
            "838: Copied from 'MainSet14' â†’ 838.jpg\n",
            "839: Copied from 'MainSet14' â†’ 839.jpg\n",
            "840: Copied from 'MainSet14' â†’ 840.jpg\n",
            "841: Copied from 'MainSet14' â†’ 841.jpg\n",
            "842: Copied from 'MainSet14' â†’ 842.jpg\n",
            "843: Copied from 'MainSet14' â†’ 843.jpg\n",
            "844: Copied from 'MainSet14' â†’ 844.jpg\n",
            "845: Copied from 'MainSet14' â†’ 845.jpg\n",
            "846: Copied from 'MainSet14' â†’ 846.jpg\n",
            "847: Copied from 'MainSet14' â†’ 847.jpg\n",
            "848: Copied from 'MainSet14' â†’ 848.jpg\n",
            "849: Copied from 'MainSet14' â†’ 849.jpg\n",
            "850: Copied from 'MainSet14' â†’ 850.jpg\n",
            "851: Copied from 'MainSet14' â†’ 851.jpg\n",
            "852: Copied from 'MainSet14' â†’ 852.jpg\n",
            "853: Copied from 'MainSet14' â†’ 853.jpg\n",
            "854: Copied from 'MainSet14' â†’ 854.jpg\n",
            "855: Copied from 'MainSet14' â†’ 855.jpg\n",
            "856: Copied from 'MainSet14' â†’ 856.jpg\n",
            "857: Copied from 'MainSet14' â†’ 857.jpg\n",
            "858: Copied from 'MainSet14' â†’ 858.jpg\n",
            "859: Copied from 'MainSet14' â†’ 859.jpg\n",
            "860: Copied from 'MainSet14' â†’ 860.jpg\n",
            "861: Copied from 'MainSet14' â†’ 861.jpg\n",
            "862: Copied from 'MainSet14' â†’ 862.jpg\n",
            "863: Copied from 'MainSet14' â†’ 863.jpg\n",
            "864: Copied from 'MainSet14' â†’ 864.jpg\n",
            "865: Copied from 'MainSet14' â†’ 865.jpg\n",
            "866: Copied from 'MainSet14' â†’ 866.jpg\n",
            "867: Copied from 'MainSet14' â†’ 867.jpg\n",
            "868: Copied from 'MainSet14' â†’ 868.jpg\n",
            "869: Copied from 'MainSet14' â†’ 869.jpg\n",
            "870: Copied from 'MainSet14' â†’ 870.jpg\n",
            "871: Copied from 'MainSet14' â†’ 871.jpg\n",
            "872: Copied from 'MainSet14' â†’ 872.jpg\n",
            "873: Copied from 'MainSet14' â†’ 873.jpg\n",
            "874: Copied from 'MainSet14' â†’ 874.jpg\n",
            "875: Copied from 'MainSet14' â†’ 875.jpg\n",
            "876: Copied from 'MainSet14' â†’ 876.jpg\n",
            "877: Copied from 'MainSet14' â†’ 877.jpg\n",
            "878: Copied from 'MainSet14' â†’ 878.jpg\n",
            "879: Copied from 'MainSet14' â†’ 879.jpg\n",
            "880: Copied from 'MainSet14' â†’ 880.jpg\n",
            "881: Copied from 'MainSet14' â†’ 881.jpg\n",
            "882: Copied from 'MainSet14' â†’ 882.jpg\n",
            "883: Copied from 'MainSet14' â†’ 883.jpg\n",
            "884: Copied from 'MainSet14' â†’ 884.jpg\n",
            "885: Copied from 'MainSet14' â†’ 885.jpg\n",
            "886: Copied from 'MainSet14' â†’ 886.jpg\n",
            "887: Copied from 'MainSet14' â†’ 887.jpg\n",
            "888: Copied from 'MainSet14' â†’ 888.jpg\n",
            "889: Copied from 'MainSet14' â†’ 889.jpg\n",
            "890: Copied from 'MainSet14' â†’ 890.jpg\n",
            "891: Copied from 'MainSet14' â†’ 891.jpg\n",
            "892: Copied from 'MainSet14' â†’ 892.jpg\n",
            "893: Copied from 'MainSet14' â†’ 893.jpg\n",
            "894: Copied from 'MainSet14' â†’ 894.jpg\n",
            "895: Copied from 'MainSet14' â†’ 895.jpg\n",
            "896: Copied from 'MainSet14' â†’ 896.jpg\n",
            "897: Copied from 'MainSet14' â†’ 897.jpg\n",
            "898: Copied from 'MainSet14' â†’ 898.jpg\n",
            "899: Copied from 'MainSet14' â†’ 899.jpg\n",
            "900: Copied from 'MainSet14' â†’ 900.jpg\n",
            "901: Copied from 'MainSet14' â†’ 901.jpg\n",
            "902: Copied from 'MainSet14' â†’ 902.jpg\n",
            "903: Copied from 'MainSet14' â†’ 903.jpg\n",
            "904: Copied from 'MainSet14' â†’ 904.jpg\n",
            "905: Copied from 'MainSet14' â†’ 905.jpg\n",
            "906: Copied from 'MainSet14' â†’ 906.jpg\n",
            "907: Copied from 'MainSet14' â†’ 907.jpg\n",
            "908: Copied from 'MainSet14' â†’ 908.jpg\n",
            "909: Copied from 'MainSet14' â†’ 909.jpg\n",
            "910: Copied from 'MainSet14' â†’ 910.jpg\n",
            "911: Copied from 'MainSet14' â†’ 911.jpg\n",
            "912: Copied from 'MainSet14' â†’ 912.jpg\n",
            "913: Copied from 'MainSet14' â†’ 913.jpg\n",
            "914: Copied from 'MainSet14' â†’ 914.jpg\n",
            "915: Copied from 'MainSet14' â†’ 915.jpg\n",
            "916: Copied from 'MainSet14' â†’ 916.jpg\n",
            "917: Copied from 'MainSet14' â†’ 917.jpg\n",
            "918: Copied from 'MainSet14' â†’ 918.jpg\n",
            "919: Copied from 'MainSet14' â†’ 919.jpg\n",
            "920: Copied from 'MainSet14' â†’ 920.jpg\n",
            "921: Copied from 'MainSet14' â†’ 921.jpg\n",
            "922: Copied from 'MainSet14' â†’ 922.jpg\n",
            "923: Copied from 'MainSet14' â†’ 923.jpg\n",
            "924: Copied from 'MainSet14' â†’ 924.jpg\n",
            "925: Copied from 'MainSet14' â†’ 925.jpg\n",
            "926: Copied from 'MainSet14' â†’ 926.jpg\n",
            "927: Copied from 'MainSet14' â†’ 927.jpg\n",
            "928: Copied from 'MainSet14' â†’ 928.jpg\n",
            "929: Copied from 'MainSet14' â†’ 929.jpg\n",
            "930: Copied from 'MainSet14' â†’ 930.jpg\n",
            "931: Copied from 'MainSet14' â†’ 931.jpg\n",
            "932: Copied from 'MainSet14' â†’ 932.jpg\n",
            "933: Copied from 'MainSet14' â†’ 933.jpg\n",
            "934: Copied from 'MainSet14' â†’ 934.jpg\n",
            "935: Copied from 'MainSet14' â†’ 935.jpg\n",
            "936: Copied from 'MainSet14' â†’ 936.jpg\n",
            "937: Copied from 'MainSet14' â†’ 937.jpg\n",
            "938: Copied from 'MainSet14' â†’ 938.jpg\n",
            "939: Copied from 'MainSet14' â†’ 939.jpg\n",
            "940: Copied from 'MainSet14' â†’ 940.jpg\n",
            "941: Copied from 'MainSet14' â†’ 941.jpg\n",
            "942: Copied from 'MainSet14' â†’ 942.jpg\n",
            "943: Copied from 'MainSet14' â†’ 943.jpg\n",
            "944: Copied from 'MainSet14' â†’ 944.jpg\n",
            "945: Copied from 'MainSet14' â†’ 945.jpg\n",
            "946: Copied from 'MainSet14' â†’ 946.jpg\n",
            "947: Copied from 'MainSet14' â†’ 947.jpg\n",
            "948: Copied from 'MainSet14' â†’ 948.jpg\n",
            "949: Copied from 'MainSet14' â†’ 949.jpg\n",
            "950: Copied from 'MainSet14' â†’ 950.jpg\n",
            "951: Copied from 'MainSet14' â†’ 951.jpg\n",
            "952: Copied from 'MainSet14' â†’ 952.jpg\n",
            "953: Copied from 'MainSet14' â†’ 953.jpg\n",
            "954: Copied from 'MainSet14' â†’ 954.jpg\n",
            "955: Copied from 'MainSet14' â†’ 955.jpg\n",
            "956: Copied from 'MainSet14' â†’ 956.jpg\n",
            "957: Copied from 'MainSet14' â†’ 957.jpg\n",
            "958: Copied from 'MainSet14' â†’ 958.jpg\n",
            "959: Copied from 'MainSet14' â†’ 959.jpg\n",
            "960: Copied from 'MainSet14' â†’ 960.jpg\n",
            "961: Copied from 'MainSet14' â†’ 961.jpg\n",
            "962: Copied from 'MainSet14' â†’ 962.jpg\n",
            "963: Copied from 'MainSet14' â†’ 963.jpg\n",
            "964: Copied from 'MainSet14' â†’ 964.jpg\n",
            "965: Copied from 'MainSet14' â†’ 965.jpg\n",
            "966: Copied from 'MainSet14' â†’ 966.jpg\n",
            "967: Copied from 'MainSet14' â†’ 967.jpg\n",
            "968: Copied from 'MainSet14' â†’ 968.jpg\n",
            "969: Copied from 'MainSet14' â†’ 969.jpg\n",
            "970: Copied from 'MainSet14' â†’ 970.jpg\n",
            "971: Copied from 'MainSet14' â†’ 971.jpg\n",
            "972: Copied from 'MainSet14' â†’ 972.jpg\n",
            "973: Copied from 'MainSet14' â†’ 973.jpg\n",
            "974: Copied from 'MainSet14' â†’ 974.jpg\n",
            "975: Copied from 'MainSet14' â†’ 975.jpg\n",
            "976: Copied from 'MainSet14' â†’ 976.jpg\n",
            "977: Copied from 'MainSet14' â†’ 977.jpg\n",
            "978: Copied from 'MainSet14' â†’ 978.jpg\n",
            "979: Copied from 'MainSet14' â†’ 979.jpg\n",
            "980: Copied from 'MainSet14' â†’ 980.jpg\n",
            "981: Copied from 'MainSet14' â†’ 981.jpg\n",
            "982: Copied from 'MainSet14' â†’ 982.jpg\n",
            "983: Copied from 'MainSet14' â†’ 983.jpg\n",
            "984: Copied from 'MainSet14' â†’ 984.jpg\n",
            "985: Copied from 'MainSet14' â†’ 985.jpg\n",
            "986: Copied from 'MainSet14' â†’ 986.jpg\n",
            "987: Copied from 'MainSet14' â†’ 987.jpg\n",
            "988: Copied from 'MainSet14' â†’ 988.jpg\n",
            "989: Copied from 'MainSet14' â†’ 989.jpg\n",
            "990: Copied from 'MainSet14' â†’ 990.jpg\n",
            "991: Copied from 'MainSet14' â†’ 991.jpg\n",
            "992: Copied from 'MainSet14' â†’ 992.jpg\n",
            "993: Copied from 'MainSet14' â†’ 993.jpg\n",
            "994: Copied from 'MainSet14' â†’ 994.jpg\n",
            "995: Copied from 'MainSet14' â†’ 995.jpg\n",
            "996: Copied from 'MainSet14' â†’ 996.jpg\n",
            "997: Copied from 'MainSet14' â†’ 997.jpg\n",
            "998: Copied from 'MainSet14' â†’ 998.jpg\n",
            "999: Copied from 'MainSet14' â†’ 999.jpg\n",
            "1000: Copied from 'MainSet14' â†’ 1000.jpg\n",
            "1001: Copied from 'MainSet14' â†’ 1001.jpg\n",
            "1002: Copied from 'MainSet14' â†’ 1002.jpg\n",
            "1003: Copied from 'MainSet14' â†’ 1003.jpg\n",
            "1004: Copied from 'MainSet14' â†’ 1004.jpg\n",
            "1005: Copied from 'MainSet14' â†’ 1005.jpg\n",
            "1006: Copied from 'MainSet14' â†’ 1006.jpg\n",
            "1007: Copied from 'MainSet14' â†’ 1007.jpg\n",
            "1008: Copied from 'MainSet14' â†’ 1008.jpg\n",
            "1009: Copied from 'MainSet14' â†’ 1009.jpg\n",
            "1010: Copied from 'MainSet14' â†’ 1010.jpg\n",
            "1011: Copied from 'MainSet14' â†’ 1011.jpg\n",
            "1012: Copied from 'MainSet14' â†’ 1012.jpg\n",
            "1013: Copied from 'MainSet14' â†’ 1013.jpg\n",
            "1014: Copied from 'MainSet14' â†’ 1014.jpg\n",
            "1015: Copied from 'MainSet14' â†’ 1015.jpg\n",
            "1016: Copied from 'MainSet14' â†’ 1016.jpg\n",
            "1017: Copied from 'MainSet14' â†’ 1017.jpg\n",
            "1018: Copied from 'MainSet14' â†’ 1018.jpg\n",
            "1019: Copied from 'MainSet14' â†’ 1019.jpg\n",
            "1020: Copied from 'MainSet14' â†’ 1020.jpg\n",
            "1021: Copied from 'MainSet14' â†’ 1021.jpg\n",
            "1022: Copied from 'MainSet14' â†’ 1022.jpg\n",
            "1023: Copied from 'MainSet14' â†’ 1023.jpg\n",
            "1024: Copied from 'MainSet14' â†’ 1024.jpg\n",
            "1025: Copied from 'MainSet14' â†’ 1025.jpg\n",
            "1026: Copied from 'MainSet14' â†’ 1026.jpg\n",
            "1027: Copied from 'MainSet14' â†’ 1027.jpg\n",
            "1028: Copied from 'MainSet14' â†’ 1028.jpg\n",
            "1029: Copied from 'MainSet14' â†’ 1029.jpg\n",
            "1030: Copied from 'MainSet14' â†’ 1030.jpg\n",
            "1031: Copied from 'MainSet14' â†’ 1031.jpg\n",
            "1032: Copied from 'MainSet14' â†’ 1032.jpg\n",
            "1033: Copied from 'MainSet14' â†’ 1033.jpg\n",
            "1034: Copied from 'MainSet14' â†’ 1034.jpg\n",
            "1035: Copied from 'MainSet14' â†’ 1035.jpg\n",
            "1036: Copied from 'MainSet14' â†’ 1036.jpg\n",
            "1037: Copied from 'MainSet14' â†’ 1037.jpg\n",
            "1038: Copied from 'MainSet14' â†’ 1038.jpg\n",
            "1039: Copied from 'MainSet14' â†’ 1039.jpg\n",
            "1040: Copied from 'MainSet14' â†’ 1040.jpg\n",
            "1041: Copied from 'MainSet14' â†’ 1041.jpg\n",
            "1042: Copied from 'MainSet14' â†’ 1042.jpg\n",
            "1043: Copied from 'MainSet14' â†’ 1043.jpg\n",
            "1044: Copied from 'MainSet14' â†’ 1044.jpg\n",
            "1045: Copied from 'MainSet14' â†’ 1045.jpg\n",
            "1046: Copied from 'MainSet14' â†’ 1046.jpg\n",
            "1047: Copied from 'MainSet14' â†’ 1047.jpg\n",
            "1048: Copied from 'MainSet14' â†’ 1048.jpg\n",
            "1049: Copied from 'MainSet14' â†’ 1049.jpg\n",
            "1050: Copied from 'MainSet14' â†’ 1050.jpg\n",
            "1051: Copied from 'MainSet14' â†’ 1051.jpg\n",
            "1052: Copied from 'MainSet14' â†’ 1052.jpg\n",
            "1053: Copied from 'MainSet14' â†’ 1053.jpg\n",
            "1054: Copied from 'MainSet14' â†’ 1054.jpg\n",
            "1055: Copied from 'MainSet14' â†’ 1055.jpg\n",
            "1056: Copied from 'MainSet14' â†’ 1056.jpg\n",
            "1057: Copied from 'MainSet14' â†’ 1057.jpg\n",
            "1058: Copied from 'MainSet2' â†’ 1058.jpg\n",
            "1059: Copied from 'MainSet2' â†’ 1059.jpg\n",
            "1060: Copied from 'MainSet2' â†’ 1060.jpg\n",
            "1061: Copied from 'MainSet2' â†’ 1061.jpg\n",
            "1062: Copied from 'MainSet2' â†’ 1062.jpg\n",
            "1063: Copied from 'MainSet2' â†’ 1063.jpg\n",
            "1064: Copied from 'MainSet2' â†’ 1064.jpg\n",
            "1065: Copied from 'MainSet2' â†’ 1065.jpg\n",
            "1066: Copied from 'MainSet2' â†’ 1066.jpg\n",
            "1067: Copied from 'MainSet2' â†’ 1067.jpg\n",
            "1068: Copied from 'MainSet2' â†’ 1068.jpg\n",
            "1069: Copied from 'MainSet2' â†’ 1069.jpg\n",
            "1070: Copied from 'MainSet2' â†’ 1070.jpg\n",
            "1071: Copied from 'MainSet2' â†’ 1071.jpg\n",
            "1072: Copied from 'MainSet2' â†’ 1072.jpg\n",
            "1073: Copied from 'MainSet2' â†’ 1073.jpg\n",
            "1074: Copied from 'MainSet2' â†’ 1074.jpg\n",
            "1075: Copied from 'MainSet2' â†’ 1075.jpg\n",
            "1076: Copied from 'MainSet2' â†’ 1076.jpg\n",
            "1077: Copied from 'MainSet2' â†’ 1077.jpg\n",
            "1078: Copied from 'MainSet2' â†’ 1078.jpg\n",
            "1079: Copied from 'MainSet2' â†’ 1079.jpg\n",
            "1080: Copied from 'MainSet2' â†’ 1080.jpg\n",
            "1081: Copied from 'MainSet2' â†’ 1081.jpg\n",
            "1082: Copied from 'MainSet2' â†’ 1082.jpg\n",
            "1083: Copied from 'MainSet2' â†’ 1083.jpg\n",
            "1084: Copied from 'MainSet2' â†’ 1084.jpg\n",
            "1085: Copied from 'MainSet2' â†’ 1085.jpg\n",
            "1086: Copied from 'MainSet2' â†’ 1086.jpg\n",
            "1087: Copied from 'MainSet2' â†’ 1087.jpg\n",
            "1088: Copied from 'MainSet2' â†’ 1088.jpg\n",
            "1089: Copied from 'MainSet2' â†’ 1089.jpg\n",
            "1090: Copied from 'MainSet2' â†’ 1090.jpg\n",
            "1091: Copied from 'MainSet2' â†’ 1091.jpg\n",
            "1092: Copied from 'MainSet2' â†’ 1092.jpg\n",
            "1093: Copied from 'MainSet2' â†’ 1093.jpg\n",
            "1094: Copied from 'MainSet2' â†’ 1094.jpg\n",
            "1095: Copied from 'MainSet2' â†’ 1095.jpg\n",
            "1096: Copied from 'MainSet2' â†’ 1096.jpg\n",
            "1097: Copied from 'MainSet2' â†’ 1097.jpg\n",
            "1098: Copied from 'MainSet2' â†’ 1098.jpg\n",
            "1099: Copied from 'MainSet2' â†’ 1099.jpg\n",
            "1100: Copied from 'MainSet2' â†’ 1100.jpg\n",
            "1101: Copied from 'MainSet2' â†’ 1101.jpg\n",
            "1102: Copied from 'MainSet2' â†’ 1102.jpg\n",
            "1103: Copied from 'MainSet2' â†’ 1103.jpg\n",
            "1104: Copied from 'MainSet2' â†’ 1104.jpg\n",
            "1105: Copied from 'MainSet2' â†’ 1105.jpg\n",
            "1106: Copied from 'MainSet2' â†’ 1106.jpg\n",
            "1107: Copied from 'MainSet2' â†’ 1107.jpg\n",
            "1108: Copied from 'MainSet2' â†’ 1108.jpg\n",
            "1109: Copied from 'MainSet2' â†’ 1109.jpg\n",
            "1110: Copied from 'MainSet2' â†’ 1110.jpg\n",
            "1111: Copied from 'MainSet2' â†’ 1111.jpg\n",
            "1112: Copied from 'MainSet2' â†’ 1112.jpg\n",
            "1113: Copied from 'MainSet2' â†’ 1113.jpg\n",
            "1114: Copied from 'MainSet2' â†’ 1114.jpg\n",
            "1115: Copied from 'MainSet2' â†’ 1115.jpg\n",
            "1116: Copied from 'MainSet2' â†’ 1116.jpg\n",
            "1117: Copied from 'MainSet2' â†’ 1117.jpg\n",
            "1118: Copied from 'MainSet2' â†’ 1118.jpg\n",
            "1119: Copied from 'MainSet2' â†’ 1119.jpg\n",
            "1120: Copied from 'MainSet2' â†’ 1120.jpg\n",
            "1121: Copied from 'MainSet2' â†’ 1121.jpg\n",
            "1122: Copied from 'MainSet2' â†’ 1122.jpg\n",
            "1123: Copied from 'MainSet2' â†’ 1123.jpg\n",
            "1124: Copied from 'MainSet2' â†’ 1124.jpg\n",
            "1125: Copied from 'MainSet2' â†’ 1125.jpg\n",
            "1126: Copied from 'MainSet2' â†’ 1126.jpg\n",
            "1127: Copied from 'MainSet2' â†’ 1127.jpg\n",
            "1128: Copied from 'MainSet2' â†’ 1128.jpg\n",
            "1129: Copied from 'MainSet2' â†’ 1129.jpg\n",
            "1130: Copied from 'MainSet2' â†’ 1130.jpg\n",
            "1131: Copied from 'MainSet2' â†’ 1131.jpg\n",
            "1132: Copied from 'MainSet2' â†’ 1132.jpg\n",
            "1133: Copied from 'MainSet2' â†’ 1133.jpg\n",
            "1134: Copied from 'MainSet2' â†’ 1134.jpg\n",
            "1135: Copied from 'MainSet2' â†’ 1135.jpg\n",
            "1136: Copied from 'MainSet2' â†’ 1136.jpg\n",
            "1137: Copied from 'MainSet2' â†’ 1137.jpg\n",
            "1138: Copied from 'MainSet2' â†’ 1138.jpg\n",
            "1139: Copied from 'MainSet2' â†’ 1139.jpg\n",
            "1140: Copied from 'MainSet2' â†’ 1140.jpg\n",
            "1141: Copied from 'MainSet2' â†’ 1141.jpg\n",
            "1142: Copied from 'MainSet2' â†’ 1142.jpg\n",
            "1143: Copied from 'MainSet2' â†’ 1143.jpg\n",
            "1144: Copied from 'MainSet2' â†’ 1144.jpg\n",
            "1145: Copied from 'MainSet2' â†’ 1145.jpg\n",
            "1146: Copied from 'MainSet2' â†’ 1146.jpg\n",
            "1147: Copied from 'MainSet2' â†’ 1147.jpg\n",
            "1148: Copied from 'MainSet2' â†’ 1148.jpg\n",
            "1149: Copied from 'MainSet2' â†’ 1149.jpg\n",
            "1150: Copied from 'MainSet2' â†’ 1150.jpg\n",
            "1151: Copied from 'MainSet2' â†’ 1151.jpg\n",
            "1152: Copied from 'MainSet2' â†’ 1152.jpg\n",
            "1153: Copied from 'MainSet2' â†’ 1153.jpg\n",
            "1154: Copied from 'MainSet2' â†’ 1154.jpg\n",
            "1155: Copied from 'MainSet2' â†’ 1155.jpg\n",
            "1156: Copied from 'MainSet2' â†’ 1156.jpg\n",
            "1157: Copied from 'MainSet2' â†’ 1157.jpg\n",
            "1158: Copied from 'MainSet2' â†’ 1158.jpg\n",
            "1159: Copied from 'MainSet2' â†’ 1159.jpg\n",
            "1160: Copied from 'MainSet2' â†’ 1160.jpg\n",
            "1161: Copied from 'MainSet2' â†’ 1161.jpg\n",
            "1162: Copied from 'MainSet2' â†’ 1162.jpg\n",
            "1163: Copied from 'MainSet2' â†’ 1163.jpg\n",
            "1164: Copied from 'MainSet2' â†’ 1164.jpg\n",
            "1165: Copied from 'MainSet2' â†’ 1165.jpg\n",
            "1166: Copied from 'MainSet2' â†’ 1166.jpg\n",
            "1167: Copied from 'MainSet2' â†’ 1167.jpg\n",
            "1168: Copied from 'MainSet2' â†’ 1168.jpg\n",
            "1169: Copied from 'MainSet2' â†’ 1169.jpg\n",
            "1170: Copied from 'MainSet2' â†’ 1170.jpg\n",
            "1171: Copied from 'MainSet2' â†’ 1171.jpg\n",
            "1172: Copied from 'MainSet2' â†’ 1172.jpg\n",
            "1173: Copied from 'MainSet2' â†’ 1173.jpg\n",
            "1174: Copied from 'MainSet2' â†’ 1174.jpg\n",
            "1175: Copied from 'MainSet2' â†’ 1175.jpg\n",
            "1176: Copied from 'MainSet2' â†’ 1176.jpg\n",
            "1177: Copied from 'MainSet2' â†’ 1177.jpg\n",
            "1178: Copied from 'MainSet2' â†’ 1178.jpg\n",
            "1179: Copied from 'MainSet2' â†’ 1179.jpg\n",
            "1180: Copied from 'MainSet2' â†’ 1180.jpg\n",
            "1181: Copied from 'MainSet2' â†’ 1181.jpg\n",
            "1182: Copied from 'MainSet2' â†’ 1182.jpg\n",
            "1183: Copied from 'MainSet2' â†’ 1183.jpg\n",
            "1184: Copied from 'MainSet2' â†’ 1184.jpg\n",
            "1185: Copied from 'MainSet2' â†’ 1185.jpg\n",
            "1186: Copied from 'MainSet2' â†’ 1186.jpg\n",
            "1187: Copied from 'MainSet2' â†’ 1187.jpg\n",
            "1188: Copied from 'MainSet2' â†’ 1188.jpg\n",
            "1189: Copied from 'MainSet2' â†’ 1189.jpg\n",
            "1190: Copied from 'MainSet2' â†’ 1190.jpg\n",
            "1191: Copied from 'MainSet2' â†’ 1191.jpg\n",
            "1192: Copied from 'MainSet2' â†’ 1192.jpg\n",
            "1193: Copied from 'MainSet2' â†’ 1193.jpg\n",
            "1194: Copied from 'MainSet2' â†’ 1194.jpg\n",
            "1195: Copied from 'MainSet2' â†’ 1195.jpg\n",
            "1196: Copied from 'MainSet2' â†’ 1196.jpg\n",
            "1197: Copied from 'MainSet2' â†’ 1197.jpg\n",
            "1198: Copied from 'MainSet2' â†’ 1198.jpg\n",
            "1199: Copied from 'MainSet2' â†’ 1199.jpg\n",
            "1200: Copied from 'MainSet2' â†’ 1200.jpg\n",
            "1201: Copied from 'MainSet2' â†’ 1201.jpg\n",
            "1202: Copied from 'MainSet2' â†’ 1202.jpg\n",
            "1203: Copied from 'MainSet2' â†’ 1203.jpg\n",
            "1204: Copied from 'MainSet2' â†’ 1204.jpg\n",
            "1205: Copied from 'MainSet2' â†’ 1205.jpg\n",
            "1206: Copied from 'MainSet2' â†’ 1206.jpg\n",
            "1207: Copied from 'MainSet2' â†’ 1207.jpg\n",
            "1208: Copied from 'MainSet2' â†’ 1208.jpg\n",
            "1209: Copied from 'MainSet2' â†’ 1209.jpg\n",
            "1210: Copied from 'MainSet2' â†’ 1210.jpg\n",
            "1211: Copied from 'MainSet2' â†’ 1211.jpg\n",
            "1212: Copied from 'MainSet2' â†’ 1212.jpg\n",
            "1213: Copied from 'MainSet2' â†’ 1213.jpg\n",
            "1214: Copied from 'MainSet2' â†’ 1214.jpg\n",
            "1215: Copied from 'MainSet2' â†’ 1215.jpg\n",
            "1216: Copied from 'MainSet2' â†’ 1216.jpg\n",
            "1217: Copied from 'MainSet2' â†’ 1217.jpg\n",
            "1218: Copied from 'MainSet2' â†’ 1218.jpg\n",
            "1219: Copied from 'MainSet2' â†’ 1219.jpg\n",
            "1220: Copied from 'MainSet2' â†’ 1220.jpg\n",
            "1221: Copied from 'MainSet2' â†’ 1221.jpg\n",
            "1222: Copied from 'MainSet2' â†’ 1222.jpg\n",
            "1223: Copied from 'MainSet2' â†’ 1223.jpg\n",
            "1224: Copied from 'MainSet2' â†’ 1224.jpg\n",
            "1225: Copied from 'MainSet2' â†’ 1225.jpg\n",
            "1226: Copied from 'MainSet2' â†’ 1226.jpg\n",
            "1227: Copied from 'MainSet2' â†’ 1227.jpg\n",
            "1228: Copied from 'MainSet2' â†’ 1228.jpg\n",
            "1229: Copied from 'MainSet2' â†’ 1229.jpg\n",
            "1230: Copied from 'MainSet2' â†’ 1230.jpg\n",
            "1231: Copied from 'MainSet2' â†’ 1231.jpg\n",
            "1232: Copied from 'MainSet2' â†’ 1232.jpg\n",
            "1233: Copied from 'MainSet2' â†’ 1233.jpg\n",
            "1234: Copied from 'MainSet2' â†’ 1234.jpg\n",
            "1235: Copied from 'MainSet2' â†’ 1235.jpg\n",
            "1236: Copied from 'MainSet2' â†’ 1236.jpg\n",
            "1237: Copied from 'MainSet2' â†’ 1237.jpg\n",
            "1238: Copied from 'MainSet2' â†’ 1238.jpg\n",
            "1239: Copied from 'MainSet2' â†’ 1239.jpg\n",
            "1240: Copied from 'MainSet2' â†’ 1240.jpg\n",
            "1241: Copied from 'MainSet2' â†’ 1241.jpg\n",
            "1242: Copied from 'MainSet3' â†’ 1242.jpg\n",
            "1243: Copied from 'MainSet3' â†’ 1243.jpg\n",
            "1244: Copied from 'MainSet3' â†’ 1244.jpg\n",
            "1245: Copied from 'MainSet3' â†’ 1245.jpg\n",
            "1246: Copied from 'MainSet3' â†’ 1246.jpg\n",
            "1247: Copied from 'MainSet3' â†’ 1247.jpg\n",
            "1248: Copied from 'MainSet3' â†’ 1248.jpg\n",
            "1249: Copied from 'MainSet3' â†’ 1249.jpg\n",
            "1250: Copied from 'MainSet3' â†’ 1250.jpg\n",
            "1251: Copied from 'MainSet3' â†’ 1251.jpg\n",
            "1252: Copied from 'MainSet3' â†’ 1252.jpg\n",
            "1253: Copied from 'MainSet3' â†’ 1253.jpg\n",
            "1254: Copied from 'MainSet3' â†’ 1254.jpg\n",
            "1255: Copied from 'MainSet3' â†’ 1255.jpg\n",
            "1256: Copied from 'MainSet3' â†’ 1256.jpg\n",
            "1257: Copied from 'MainSet3' â†’ 1257.jpg\n",
            "1258: Copied from 'MainSet3' â†’ 1258.jpg\n",
            "1259: Copied from 'MainSet3' â†’ 1259.jpg\n",
            "1260: Copied from 'MainSet3' â†’ 1260.jpg\n",
            "1261: Copied from 'MainSet3' â†’ 1261.jpg\n",
            "1262: Copied from 'MainSet3' â†’ 1262.jpg\n",
            "1263: Copied from 'MainSet3' â†’ 1263.jpg\n",
            "1264: Copied from 'MainSet3' â†’ 1264.jpg\n",
            "1265: Copied from 'MainSet3' â†’ 1265.jpg\n",
            "1266: Copied from 'MainSet3' â†’ 1266.jpg\n",
            "1267: Copied from 'MainSet3' â†’ 1267.jpg\n",
            "1268: Copied from 'MainSet3' â†’ 1268.jpg\n",
            "1269: Copied from 'MainSet3' â†’ 1269.jpg\n",
            "1270: Copied from 'MainSet3' â†’ 1270.jpg\n",
            "1271: Copied from 'MainSet3' â†’ 1271.jpg\n",
            "1272: Copied from 'MainSet3' â†’ 1272.jpg\n",
            "1273: Copied from 'MainSet3' â†’ 1273.jpg\n",
            "1274: Copied from 'MainSet3' â†’ 1274.jpg\n",
            "1275: Copied from 'MainSet3' â†’ 1275.jpg\n",
            "1276: Copied from 'MainSet3' â†’ 1276.jpg\n",
            "1277: Copied from 'MainSet3' â†’ 1277.jpg\n",
            "1278: Copied from 'MainSet3' â†’ 1278.jpg\n",
            "1279: Copied from 'MainSet3' â†’ 1279.jpg\n",
            "1280: Copied from 'MainSet3' â†’ 1280.jpg\n",
            "1281: Copied from 'MainSet3' â†’ 1281.jpg\n",
            "1282: Copied from 'MainSet3' â†’ 1282.jpg\n",
            "1283: Copied from 'MainSet3' â†’ 1283.jpg\n",
            "1284: Copied from 'MainSet3' â†’ 1284.jpg\n",
            "1285: Copied from 'MainSet3' â†’ 1285.jpg\n",
            "1286: Copied from 'MainSet3' â†’ 1286.jpg\n",
            "1287: Copied from 'MainSet3' â†’ 1287.jpg\n",
            "1288: Copied from 'MainSet3' â†’ 1288.jpg\n",
            "1289: Copied from 'MainSet3' â†’ 1289.jpg\n",
            "1290: Copied from 'MainSet3' â†’ 1290.jpg\n",
            "1291: Copied from 'MainSet3' â†’ 1291.jpg\n",
            "1292: Copied from 'MainSet3' â†’ 1292.jpg\n",
            "1293: Copied from 'MainSet3' â†’ 1293.jpg\n",
            "1294: Copied from 'MainSet3' â†’ 1294.jpg\n",
            "1295: Copied from 'MainSet3' â†’ 1295.jpg\n",
            "1296: Copied from 'MainSet3' â†’ 1296.jpg\n",
            "1297: Copied from 'MainSet3' â†’ 1297.jpg\n",
            "1298: Copied from 'MainSet3' â†’ 1298.jpg\n",
            "1299: Copied from 'MainSet3' â†’ 1299.jpg\n",
            "1300: Copied from 'MainSet3' â†’ 1300.jpg\n",
            "1301: Copied from 'MainSet3' â†’ 1301.jpg\n",
            "1302: Copied from 'MainSet3' â†’ 1302.jpg\n",
            "1303: Copied from 'MainSet3' â†’ 1303.jpg\n",
            "1304: Copied from 'MainSet3' â†’ 1304.jpg\n",
            "1305: Copied from 'MainSet3' â†’ 1305.jpg\n",
            "1306: Copied from 'MainSet3' â†’ 1306.jpg\n",
            "1307: Copied from 'MainSet3' â†’ 1307.jpg\n",
            "1308: Copied from 'MainSet3' â†’ 1308.jpg\n",
            "1309: Copied from 'MainSet3' â†’ 1309.jpg\n",
            "1310: Copied from 'MainSet3' â†’ 1310.jpg\n",
            "1311: Copied from 'MainSet3' â†’ 1311.jpg\n",
            "1312: Copied from 'MainSet3' â†’ 1312.jpg\n",
            "1313: Copied from 'MainSet3' â†’ 1313.jpg\n",
            "1314: Copied from 'MainSet3' â†’ 1314.jpg\n",
            "1315: Copied from 'MainSet3' â†’ 1315.jpg\n",
            "1316: Copied from 'MainSet3' â†’ 1316.jpg\n",
            "1317: Copied from 'MainSet3' â†’ 1317.jpg\n",
            "1318: Copied from 'MainSet3' â†’ 1318.jpg\n",
            "1319: Copied from 'MainSet4' â†’ 1319.jpg\n",
            "1320: Copied from 'MainSet4' â†’ 1320.jpg\n",
            "1321: Copied from 'MainSet4' â†’ 1321.jpg\n",
            "1322: Copied from 'MainSet4' â†’ 1322.jpg\n",
            "1323: Copied from 'MainSet4' â†’ 1323.jpg\n",
            "1324: Copied from 'MainSet4' â†’ 1324.jpg\n",
            "1325: Copied from 'MainSet4' â†’ 1325.jpg\n",
            "1326: Copied from 'MainSet4' â†’ 1326.jpg\n",
            "1327: Copied from 'MainSet4' â†’ 1327.jpg\n",
            "1328: Copied from 'MainSet4' â†’ 1328.jpg\n",
            "1329: Copied from 'MainSet4' â†’ 1329.jpg\n",
            "1330: Copied from 'MainSet4' â†’ 1330.jpg\n",
            "1331: Copied from 'MainSet4' â†’ 1331.jpg\n",
            "1332: Copied from 'MainSet4' â†’ 1332.jpg\n",
            "1333: Copied from 'MainSet4' â†’ 1333.jpg\n",
            "1334: Copied from 'MainSet4' â†’ 1334.jpg\n",
            "1335: Copied from 'MainSet4' â†’ 1335.jpg\n",
            "1336: Copied from 'MainSet4' â†’ 1336.jpg\n",
            "1337: Copied from 'MainSet4' â†’ 1337.jpg\n",
            "1338: Copied from 'MainSet4' â†’ 1338.jpg\n",
            "1339: Copied from 'MainSet4' â†’ 1339.jpg\n",
            "1340: Copied from 'MainSet4' â†’ 1340.jpg\n",
            "1341: Copied from 'MainSet4' â†’ 1341.jpg\n",
            "1342: Copied from 'MainSet4' â†’ 1342.jpg\n",
            "1343: Copied from 'MainSet4' â†’ 1343.jpg\n",
            "1344: Copied from 'MainSet4' â†’ 1344.jpg\n",
            "1345: Copied from 'MainSet4' â†’ 1345.jpg\n",
            "1346: Copied from 'MainSet4' â†’ 1346.jpg\n",
            "1347: Copied from 'MainSet4' â†’ 1347.jpg\n",
            "1348: Copied from 'MainSet4' â†’ 1348.jpg\n",
            "1349: Copied from 'MainSet4' â†’ 1349.jpg\n",
            "1350: Copied from 'MainSet4' â†’ 1350.jpg\n",
            "1351: Copied from 'MainSet4' â†’ 1351.jpg\n",
            "1352: Copied from 'MainSet4' â†’ 1352.jpg\n",
            "1353: Copied from 'MainSet4' â†’ 1353.jpg\n",
            "1354: Copied from 'MainSet4' â†’ 1354.jpg\n",
            "1355: Copied from 'MainSet4' â†’ 1355.jpg\n",
            "1356: Copied from 'MainSet4' â†’ 1356.jpg\n",
            "1357: Copied from 'MainSet4' â†’ 1357.jpg\n",
            "1358: Copied from 'MainSet4' â†’ 1358.jpg\n",
            "1359: Copied from 'MainSet4' â†’ 1359.jpg\n",
            "1360: Copied from 'MainSet4' â†’ 1360.jpg\n",
            "1361: Copied from 'MainSet4' â†’ 1361.jpg\n",
            "1362: Copied from 'MainSet4' â†’ 1362.jpg\n",
            "1363: Copied from 'MainSet4' â†’ 1363.jpg\n",
            "1364: Copied from 'MainSet4' â†’ 1364.jpg\n",
            "1365: Copied from 'MainSet4' â†’ 1365.jpg\n",
            "1366: Copied from 'MainSet4' â†’ 1366.jpg\n",
            "1367: Copied from 'MainSet4' â†’ 1367.jpg\n",
            "1368: Copied from 'MainSet4' â†’ 1368.jpg\n",
            "1369: Copied from 'MainSet4' â†’ 1369.jpg\n",
            "1370: Copied from 'MainSet4' â†’ 1370.jpg\n",
            "1371: Copied from 'MainSet4' â†’ 1371.jpg\n",
            "1372: Copied from 'MainSet4' â†’ 1372.jpg\n",
            "1373: Copied from 'MainSet4' â†’ 1373.jpg\n",
            "1374: Copied from 'MainSet4' â†’ 1374.jpg\n",
            "1375: Copied from 'MainSet4' â†’ 1375.jpg\n",
            "1376: Copied from 'MainSet4' â†’ 1376.jpg\n",
            "1377: Copied from 'MainSet4' â†’ 1377.jpg\n",
            "1378: Copied from 'MainSet4' â†’ 1378.jpg\n",
            "1379: Copied from 'MainSet4' â†’ 1379.jpg\n",
            "1380: Copied from 'MainSet4' â†’ 1380.jpg\n",
            "1381: Copied from 'MainSet4' â†’ 1381.jpg\n",
            "1382: Copied from 'MainSet4' â†’ 1382.jpg\n",
            "1383: Copied from 'MainSet4' â†’ 1383.jpg\n",
            "1384: Copied from 'MainSet4' â†’ 1384.jpg\n",
            "1385: Copied from 'MainSet4' â†’ 1385.jpg\n",
            "1386: Copied from 'MainSet4' â†’ 1386.jpg\n",
            "1387: Copied from 'MainSet4' â†’ 1387.jpg\n",
            "1388: Copied from 'MainSet4' â†’ 1388.jpg\n",
            "1389: Copied from 'MainSet4' â†’ 1389.jpg\n",
            "1390: Copied from 'MainSet4' â†’ 1390.jpg\n",
            "1391: Copied from 'MainSet4' â†’ 1391.jpg\n",
            "1392: Copied from 'MainSet4' â†’ 1392.jpg\n",
            "1393: Copied from 'MainSet4' â†’ 1393.jpg\n",
            "1394: Copied from 'MainSet4' â†’ 1394.jpg\n",
            "1395: Copied from 'MainSet4' â†’ 1395.jpg\n",
            "1396: Copied from 'MainSet4' â†’ 1396.jpg\n",
            "1397: Copied from 'MainSet4' â†’ 1397.jpg\n",
            "1398: Copied from 'MainSet4' â†’ 1398.jpg\n",
            "1399: Copied from 'MainSet4' â†’ 1399.jpg\n",
            "1400: Copied from 'MainSet4' â†’ 1400.jpg\n",
            "1401: Copied from 'MainSet4' â†’ 1401.jpg\n",
            "1402: Copied from 'MainSet4' â†’ 1402.jpg\n",
            "1403: Copied from 'MainSet4' â†’ 1403.jpg\n",
            "1404: Copied from 'MainSet4' â†’ 1404.jpg\n",
            "1405: Copied from 'MainSet4' â†’ 1405.jpg\n",
            "1406: Copied from 'MainSet4' â†’ 1406.jpg\n",
            "1407: Copied from 'MainSet4' â†’ 1407.jpg\n",
            "1408: Copied from 'MainSet4' â†’ 1408.jpg\n",
            "1409: Copied from 'MainSet4' â†’ 1409.jpg\n",
            "1410: Copied from 'MainSet4' â†’ 1410.jpg\n",
            "1411: Copied from 'MainSet4' â†’ 1411.jpg\n",
            "1412: Copied from 'MainSet4' â†’ 1412.jpg\n",
            "1413: Copied from 'MainSet4' â†’ 1413.jpg\n",
            "1414: Copied from 'MainSet4' â†’ 1414.jpg\n",
            "1415: Copied from 'MainSet4' â†’ 1415.jpg\n",
            "1416: Copied from 'MainSet4' â†’ 1416.jpg\n",
            "1417: Copied from 'MainSet4' â†’ 1417.jpg\n",
            "1418: Copied from 'MainSet4' â†’ 1418.jpg\n",
            "1419: Copied from 'MainSet4' â†’ 1419.jpg\n",
            "1420: Copied from 'MainSet4' â†’ 1420.jpg\n",
            "1421: Copied from 'MainSet4' â†’ 1421.jpg\n",
            "1422: Copied from 'MainSet4' â†’ 1422.jpg\n",
            "1423: Copied from 'MainSet4' â†’ 1423.jpg\n",
            "1424: Copied from 'MainSet4' â†’ 1424.jpg\n",
            "1425: Copied from 'MainSet4' â†’ 1425.jpg\n",
            "1426: Copied from 'MainSet4' â†’ 1426.jpg\n",
            "1427: Copied from 'MainSet4' â†’ 1427.jpg\n",
            "1428: Copied from 'MainSet4' â†’ 1428.jpg\n",
            "1429: Copied from 'MainSet4' â†’ 1429.jpg\n",
            "1430: Copied from 'MainSet4' â†’ 1430.jpg\n",
            "1431: Copied from 'MainSet4' â†’ 1431.jpg\n",
            "1432: Copied from 'MainSet4' â†’ 1432.jpg\n",
            "1433: Copied from 'MainSet4' â†’ 1433.jpg\n",
            "1434: Copied from 'MainSet4' â†’ 1434.jpg\n",
            "1435: Copied from 'MainSet4' â†’ 1435.jpg\n",
            "1436: Copied from 'MainSet4' â†’ 1436.jpg\n",
            "1437: Copied from 'MainSet4' â†’ 1437.jpg\n",
            "1438: Copied from 'MainSet4' â†’ 1438.jpg\n",
            "1439: Copied from 'MainSet5' â†’ 1439.jpg\n",
            "1440: Copied from 'MainSet5' â†’ 1440.jpg\n",
            "1441: Copied from 'MainSet5' â†’ 1441.jpg\n",
            "1442: Copied from 'MainSet5' â†’ 1442.jpg\n",
            "1443: Copied from 'MainSet5' â†’ 1443.jpg\n",
            "1444: Copied from 'MainSet5' â†’ 1444.jpg\n",
            "1445: Copied from 'MainSet5' â†’ 1445.jpg\n",
            "1446: Copied from 'MainSet5' â†’ 1446.jpg\n",
            "1447: Copied from 'MainSet5' â†’ 1447.jpg\n",
            "1448: Copied from 'MainSet5' â†’ 1448.jpg\n",
            "1449: Copied from 'MainSet5' â†’ 1449.jpg\n",
            "1450: Copied from 'MainSet5' â†’ 1450.jpg\n",
            "1451: Copied from 'MainSet5' â†’ 1451.jpg\n",
            "1452: Copied from 'MainSet5' â†’ 1452.jpg\n",
            "1453: Copied from 'MainSet5' â†’ 1453.jpg\n",
            "1454: Copied from 'MainSet5' â†’ 1454.jpg\n",
            "1455: Copied from 'MainSet6' â†’ 1455.jpg\n",
            "1456: Copied from 'MainSet6' â†’ 1456.jpg\n",
            "1457: Copied from 'MainSet6' â†’ 1457.jpg\n",
            "1458: Copied from 'MainSet6' â†’ 1458.jpg\n",
            "1459: Copied from 'MainSet6' â†’ 1459.jpg\n",
            "1460: Copied from 'MainSet6' â†’ 1460.jpg\n",
            "1461: Copied from 'MainSet6' â†’ 1461.jpg\n",
            "1462: Copied from 'MainSet6' â†’ 1462.jpg\n",
            "1463: Copied from 'MainSet7' â†’ 1463.jpg\n",
            "1464: Copied from 'MainSet7' â†’ 1464.jpg\n",
            "1465: Copied from 'MainSet7' â†’ 1465.jpg\n",
            "1466: Copied from 'MainSet7' â†’ 1466.jpg\n",
            "1467: Copied from 'MainSet7' â†’ 1467.jpg\n",
            "1468: Copied from 'MainSet7' â†’ 1468.jpg\n",
            "1469: Copied from 'MainSet7' â†’ 1469.jpg\n",
            "1470: Copied from 'MainSet7' â†’ 1470.jpg\n",
            "1471: Copied from 'MainSet7' â†’ 1471.jpg\n",
            "1472: Copied from 'MainSet7' â†’ 1472.jpg\n",
            "1473: Copied from 'MainSet7' â†’ 1473.jpg\n",
            "1474: Copied from 'MainSet7' â†’ 1474.jpg\n",
            "1475: Copied from 'MainSet7' â†’ 1475.jpg\n",
            "1476: Copied from 'MainSet7' â†’ 1476.jpg\n",
            "1477: Copied from 'MainSet7' â†’ 1477.jpg\n",
            "1478: Copied from 'MainSet7' â†’ 1478.jpg\n",
            "1479: Copied from 'MainSet7' â†’ 1479.jpg\n",
            "1480: Copied from 'MainSet7' â†’ 1480.jpg\n",
            "1481: Copied from 'MainSet7' â†’ 1481.jpg\n",
            "1482: Copied from 'MainSet7' â†’ 1482.jpg\n",
            "1483: Copied from 'MainSet7' â†’ 1483.jpg\n",
            "1484: Copied from 'MainSet7' â†’ 1484.jpg\n",
            "1485: Copied from 'MainSet7' â†’ 1485.jpg\n",
            "1486: Copied from 'MainSet7' â†’ 1486.jpg\n",
            "1487: Copied from 'MainSet7' â†’ 1487.jpg\n",
            "1488: Copied from 'MainSet7' â†’ 1488.jpg\n",
            "1489: Copied from 'MainSet7' â†’ 1489.jpg\n",
            "1490: Copied from 'MainSet7' â†’ 1490.jpg\n",
            "1491: Copied from 'MainSet7' â†’ 1491.jpg\n",
            "1492: Copied from 'MainSet7' â†’ 1492.jpg\n",
            "1493: Copied from 'MainSet7' â†’ 1493.jpg\n",
            "1494: Copied from 'MainSet7' â†’ 1494.jpg\n",
            "1495: Copied from 'MainSet7' â†’ 1495.jpg\n",
            "1496: Copied from 'MainSet7' â†’ 1496.jpg\n",
            "1497: Copied from 'MainSet7' â†’ 1497.jpg\n",
            "1498: Copied from 'MainSet7' â†’ 1498.jpg\n",
            "1499: Copied from 'MainSet7' â†’ 1499.jpg\n",
            "1500: Copied from 'MainSet7' â†’ 1500.jpg\n",
            "1501: Copied from 'MainSet7' â†’ 1501.jpg\n",
            "1502: Copied from 'MainSet7' â†’ 1502.jpg\n",
            "1503: Copied from 'MainSet7' â†’ 1503.jpg\n",
            "1504: Copied from 'MainSet7' â†’ 1504.jpg\n",
            "1505: Copied from 'MainSet7' â†’ 1505.jpg\n",
            "1506: Copied from 'MainSet7' â†’ 1506.jpg\n",
            "1507: Copied from 'MainSet7' â†’ 1507.jpg\n",
            "1508: Copied from 'MainSet7' â†’ 1508.jpg\n",
            "1509: Copied from 'MainSet7' â†’ 1509.jpg\n",
            "1510: Copied from 'MainSet7' â†’ 1510.jpg\n",
            "1511: Copied from 'MainSet7' â†’ 1511.jpg\n",
            "1512: Copied from 'MainSet7' â†’ 1512.jpg\n",
            "1513: Copied from 'MainSet7' â†’ 1513.jpg\n",
            "1514: Copied from 'MainSet7' â†’ 1514.jpg\n",
            "1515: Copied from 'MainSet7' â†’ 1515.jpg\n",
            "1516: Copied from 'MainSet7' â†’ 1516.jpg\n",
            "1517: Copied from 'MainSet7' â†’ 1517.jpg\n",
            "1518: Copied from 'MainSet7' â†’ 1518.jpg\n",
            "1519: Copied from 'MainSet7' â†’ 1519.jpg\n",
            "1520: Copied from 'MainSet7' â†’ 1520.jpg\n",
            "1521: Copied from 'MainSet7' â†’ 1521.jpg\n",
            "1522: Copied from 'MainSet7' â†’ 1522.jpg\n",
            "1523: Copied from 'MainSet7' â†’ 1523.jpg\n",
            "1524: Copied from 'MainSet7' â†’ 1524.jpg\n",
            "1525: Copied from 'MainSet7' â†’ 1525.jpg\n",
            "1526: Copied from 'MainSet7' â†’ 1526.jpg\n",
            "1527: Copied from 'MainSet7' â†’ 1527.jpg\n",
            "1528: Copied from 'MainSet7' â†’ 1528.jpg\n",
            "1529: Copied from 'MainSet7' â†’ 1529.jpg\n",
            "1530: Copied from 'MainSet7' â†’ 1530.jpg\n",
            "1531: Copied from 'MainSet7' â†’ 1531.jpg\n",
            "1532: Copied from 'MainSet7' â†’ 1532.jpg\n",
            "1533: Copied from 'MainSet7' â†’ 1533.jpg\n",
            "1534: Copied from 'MainSet7' â†’ 1534.jpg\n",
            "1535: Copied from 'MainSet7' â†’ 1535.jpg\n",
            "1536: Copied from 'MainSet7' â†’ 1536.jpg\n",
            "1537: Copied from 'MainSet7' â†’ 1537.jpg\n",
            "1538: Copied from 'MainSet7' â†’ 1538.jpg\n",
            "1539: Copied from 'MainSet7' â†’ 1539.jpg\n",
            "1540: Copied from 'MainSet7' â†’ 1540.jpg\n",
            "1541: Copied from 'MainSet7' â†’ 1541.jpg\n",
            "1542: Copied from 'MainSet7' â†’ 1542.jpg\n",
            "1543: Copied from 'MainSet7' â†’ 1543.jpg\n",
            "1544: Copied from 'MainSet7' â†’ 1544.jpg\n",
            "1545: Copied from 'MainSet7' â†’ 1545.jpg\n",
            "1546: Copied from 'MainSet7' â†’ 1546.jpg\n",
            "1547: Copied from 'MainSet7' â†’ 1547.jpg\n",
            "1548: Copied from 'MainSet7' â†’ 1548.jpg\n",
            "1549: Copied from 'MainSet7' â†’ 1549.jpg\n",
            "1550: Copied from 'MainSet7' â†’ 1550.jpg\n",
            "1551: Copied from 'MainSet7' â†’ 1551.jpg\n",
            "1552: Copied from 'MainSet7' â†’ 1552.jpg\n",
            "1553: Copied from 'MainSet7' â†’ 1553.jpg\n",
            "1554: Copied from 'MainSet7' â†’ 1554.jpg\n",
            "1555: Copied from 'MainSet7' â†’ 1555.jpg\n",
            "1556: Copied from 'MainSet7' â†’ 1556.jpg\n",
            "1557: Copied from 'MainSet7' â†’ 1557.jpg\n",
            "1558: Copied from 'MainSet7' â†’ 1558.jpg\n",
            "1559: Copied from 'MainSet7' â†’ 1559.jpg\n",
            "1560: Copied from 'MainSet7' â†’ 1560.jpg\n",
            "1561: Copied from 'MainSet7' â†’ 1561.jpg\n",
            "1562: Copied from 'MainSet7' â†’ 1562.jpg\n",
            "1563: Copied from 'MainSet7' â†’ 1563.jpg\n",
            "1564: Copied from 'MainSet7' â†’ 1564.jpg\n",
            "1565: Copied from 'MainSet7' â†’ 1565.jpg\n",
            "1566: Copied from 'MainSet7' â†’ 1566.jpg\n",
            "1567: Copied from 'MainSet7' â†’ 1567.jpg\n",
            "1568: Copied from 'MainSet7' â†’ 1568.jpg\n",
            "1569: Copied from 'MainSet7' â†’ 1569.jpg\n",
            "1570: Copied from 'MainSet7' â†’ 1570.jpg\n",
            "1571: Copied from 'MainSet7' â†’ 1571.jpg\n",
            "1572: Copied from 'MainSet7' â†’ 1572.jpg\n",
            "1573: Copied from 'MainSet7' â†’ 1573.jpg\n",
            "1574: Copied from 'MainSet7' â†’ 1574.jpg\n",
            "1575: Copied from 'MainSet7' â†’ 1575.jpg\n",
            "1576: Copied from 'MainSet7' â†’ 1576.jpg\n",
            "1577: Copied from 'MainSet7' â†’ 1577.jpg\n",
            "1578: Copied from 'MainSet7' â†’ 1578.jpg\n",
            "1579: Copied from 'MainSet7' â†’ 1579.jpg\n",
            "1580: Copied from 'MainSet7' â†’ 1580.jpg\n",
            "1581: Copied from 'MainSet7' â†’ 1581.jpg\n",
            "1582: Copied from 'MainSet7' â†’ 1582.jpg\n",
            "1583: Copied from 'MainSet7' â†’ 1583.jpg\n",
            "1584: Copied from 'MainSet7' â†’ 1584.jpg\n",
            "1585: Copied from 'MainSet7' â†’ 1585.jpg\n",
            "1586: Copied from 'MainSet7' â†’ 1586.jpg\n",
            "1587: Copied from 'MainSet7' â†’ 1587.jpg\n",
            "1588: Copied from 'MainSet7' â†’ 1588.jpg\n",
            "1589: Copied from 'MainSet7' â†’ 1589.jpg\n",
            "1590: Copied from 'MainSet7' â†’ 1590.jpg\n",
            "1591: Copied from 'MainSet7' â†’ 1591.jpg\n",
            "1592: Copied from 'MainSet7' â†’ 1592.jpg\n",
            "1593: Copied from 'MainSet7' â†’ 1593.jpg\n",
            "1594: Copied from 'MainSet7' â†’ 1594.jpg\n",
            "1595: Copied from 'MainSet7' â†’ 1595.jpg\n",
            "1596: Copied from 'MainSet7' â†’ 1596.jpg\n",
            "1597: Copied from 'MainSet7' â†’ 1597.jpg\n",
            "1598: Copied from 'MainSet7' â†’ 1598.jpg\n",
            "1599: Copied from 'MainSet7' â†’ 1599.jpg\n",
            "1600: Copied from 'MainSet7' â†’ 1600.jpg\n",
            "1601: Copied from 'MainSet7' â†’ 1601.jpg\n",
            "1602: Copied from 'MainSet7' â†’ 1602.jpg\n",
            "1603: Copied from 'MainSet7' â†’ 1603.jpg\n",
            "1604: Copied from 'MainSet7' â†’ 1604.jpg\n",
            "1605: Copied from 'MainSet7' â†’ 1605.jpg\n",
            "1606: Copied from 'MainSet7' â†’ 1606.jpg\n",
            "1607: Copied from 'MainSet7' â†’ 1607.jpg\n",
            "1608: Copied from 'MainSet7' â†’ 1608.jpg\n",
            "1609: Copied from 'MainSet7' â†’ 1609.jpg\n",
            "1610: Copied from 'MainSet7' â†’ 1610.jpg\n",
            "1611: Copied from 'MainSet7' â†’ 1611.jpg\n",
            "1612: Copied from 'MainSet7' â†’ 1612.jpg\n",
            "1613: Copied from 'MainSet7' â†’ 1613.jpg\n",
            "1614: Copied from 'MainSet7' â†’ 1614.jpg\n",
            "1615: Copied from 'MainSet7' â†’ 1615.jpg\n",
            "1616: Copied from 'MainSet7' â†’ 1616.jpg\n",
            "1617: Copied from 'MainSet7' â†’ 1617.jpg\n",
            "1618: Copied from 'MainSet7' â†’ 1618.jpg\n",
            "1619: Copied from 'MainSet7' â†’ 1619.jpg\n",
            "1620: Copied from 'MainSet7' â†’ 1620.jpg\n",
            "1621: Copied from 'MainSet7' â†’ 1621.jpg\n",
            "1622: Copied from 'MainSet7' â†’ 1622.jpg\n",
            "1623: Copied from 'MainSet7' â†’ 1623.jpg\n",
            "1624: Copied from 'MainSet7' â†’ 1624.jpg\n",
            "1625: Copied from 'MainSet7' â†’ 1625.jpg\n",
            "1626: Copied from 'MainSet7' â†’ 1626.jpg\n",
            "1627: Copied from 'MainSet7' â†’ 1627.jpg\n",
            "1628: Copied from 'MainSet7' â†’ 1628.jpg\n",
            "1629: Copied from 'MainSet7' â†’ 1629.jpg\n",
            "1630: Copied from 'MainSet7' â†’ 1630.jpg\n",
            "1631: Copied from 'MainSet7' â†’ 1631.jpg\n",
            "1632: Copied from 'MainSet7' â†’ 1632.jpg\n",
            "1633: Copied from 'MainSet7' â†’ 1633.jpg\n",
            "1634: Copied from 'MainSet7' â†’ 1634.jpg\n",
            "1635: Copied from 'MainSet7' â†’ 1635.jpg\n",
            "1636: Copied from 'MainSet7' â†’ 1636.jpg\n",
            "1637: Copied from 'MainSet7' â†’ 1637.jpg\n",
            "1638: Copied from 'MainSet7' â†’ 1638.jpg\n",
            "1639: Copied from 'MainSet7' â†’ 1639.jpg\n",
            "1640: Copied from 'MainSet7' â†’ 1640.jpg\n",
            "1641: Copied from 'MainSet7' â†’ 1641.jpg\n",
            "1642: Copied from 'MainSet7' â†’ 1642.jpg\n",
            "1643: Copied from 'MainSet7' â†’ 1643.jpg\n",
            "1644: Copied from 'MainSet7' â†’ 1644.jpg\n",
            "1645: Copied from 'MainSet7' â†’ 1645.jpg\n",
            "1646: Copied from 'MainSet7' â†’ 1646.jpg\n",
            "1647: Copied from 'MainSet7' â†’ 1647.jpg\n",
            "1648: Copied from 'MainSet7' â†’ 1648.jpg\n",
            "1649: Copied from 'MainSet7' â†’ 1649.jpg\n",
            "1650: Copied from 'MainSet7' â†’ 1650.jpg\n",
            "1651: Copied from 'MainSet7' â†’ 1651.jpg\n",
            "1652: Copied from 'MainSet7' â†’ 1652.jpg\n",
            "1653: Copied from 'MainSet7' â†’ 1653.jpg\n",
            "1654: Copied from 'MainSet7' â†’ 1654.jpg\n",
            "1655: Copied from 'MainSet7' â†’ 1655.jpg\n",
            "1656: Copied from 'MainSet7' â†’ 1656.jpg\n",
            "1657: Copied from 'MainSet7' â†’ 1657.jpg\n",
            "1658: Copied from 'MainSet7' â†’ 1658.jpg\n",
            "1659: Copied from 'MainSet7' â†’ 1659.jpg\n",
            "1660: Copied from 'MainSet7' â†’ 1660.jpg\n",
            "1661: Copied from 'MainSet7' â†’ 1661.jpg\n",
            "1662: Copied from 'MainSet7' â†’ 1662.jpg\n",
            "1663: Copied from 'MainSet7' â†’ 1663.jpg\n",
            "1664: Copied from 'MainSet7' â†’ 1664.jpg\n",
            "1665: Copied from 'MainSet8' â†’ 1665.jpg\n",
            "1666: Copied from 'MainSet8' â†’ 1666.jpg\n",
            "1667: Copied from 'MainSet8' â†’ 1667.jpg\n",
            "1668: Copied from 'MainSet8' â†’ 1668.jpg\n",
            "1669: Copied from 'MainSet8' â†’ 1669.jpg\n",
            "1670: Copied from 'MainSet8' â†’ 1670.jpg\n",
            "1671: Copied from 'MainSet8' â†’ 1671.jpg\n",
            "1672: Copied from 'MainSet8' â†’ 1672.jpg\n",
            "1673: Copied from 'MainSet8' â†’ 1673.jpg\n",
            "1674: Copied from 'MainSet8' â†’ 1674.jpg\n",
            "1675: Copied from 'MainSet8' â†’ 1675.jpg\n",
            "1676: Copied from 'MainSet8' â†’ 1676.jpg\n",
            "1677: Copied from 'MainSet8' â†’ 1677.jpg\n",
            "1678: Copied from 'MainSet8' â†’ 1678.jpg\n",
            "1679: Copied from 'MainSet8' â†’ 1679.jpg\n",
            "1680: Copied from 'MainSet8' â†’ 1680.jpg\n",
            "1681: Copied from 'MainSet8' â†’ 1681.jpg\n",
            "1682: Copied from 'MainSet8' â†’ 1682.jpg\n",
            "1683: Copied from 'MainSet8' â†’ 1683.jpg\n",
            "1684: Copied from 'MainSet8' â†’ 1684.jpg\n",
            "1685: Copied from 'MainSet8' â†’ 1685.jpg\n",
            "1686: Copied from 'MainSet8' â†’ 1686.jpg\n",
            "1687: Copied from 'MainSet8' â†’ 1687.jpg\n",
            "1688: Copied from 'MainSet8' â†’ 1688.jpg\n",
            "1689: Copied from 'MainSet8' â†’ 1689.jpg\n",
            "1690: Copied from 'MainSet8' â†’ 1690.jpg\n",
            "1691: Copied from 'MainSet8' â†’ 1691.jpg\n",
            "1692: Copied from 'MainSet8' â†’ 1692.jpg\n",
            "1693: Copied from 'MainSet8' â†’ 1693.jpg\n",
            "1694: Copied from 'MainSet8' â†’ 1694.jpg\n",
            "1695: Copied from 'MainSet8' â†’ 1695.jpg\n",
            "1696: Copied from 'MainSet8' â†’ 1696.jpg\n",
            "1697: Copied from 'MainSet8' â†’ 1697.jpg\n",
            "1698: Copied from 'MainSet8' â†’ 1698.jpg\n",
            "1699: Copied from 'MainSet8' â†’ 1699.jpg\n",
            "1700: Copied from 'MainSet8' â†’ 1700.jpg\n",
            "1701: Copied from 'MainSet8' â†’ 1701.jpg\n",
            "1702: Copied from 'MainSet8' â†’ 1702.jpg\n",
            "1703: Copied from 'MainSet8' â†’ 1703.jpg\n",
            "1704: Copied from 'MainSet8' â†’ 1704.jpg\n",
            "1705: Copied from 'MainSet8' â†’ 1705.jpg\n",
            "1706: Copied from 'MainSet8' â†’ 1706.jpg\n",
            "1707: Copied from 'MainSet8' â†’ 1707.jpg\n",
            "1708: Copied from 'MainSet8' â†’ 1708.jpg\n",
            "1709: Copied from 'MainSet8' â†’ 1709.jpg\n",
            "1710: Copied from 'MainSet8' â†’ 1710.jpg\n",
            "1711: Copied from 'MainSet8' â†’ 1711.jpg\n",
            "1712: Copied from 'MainSet8' â†’ 1712.jpg\n",
            "1713: Copied from 'MainSet8' â†’ 1713.jpg\n",
            "1714: Copied from 'MainSet8' â†’ 1714.jpg\n",
            "1715: Copied from 'MainSet8' â†’ 1715.jpg\n",
            "1716: Copied from 'MainSet8' â†’ 1716.jpg\n",
            "1717: Copied from 'MainSet8' â†’ 1717.jpg\n",
            "1718: Copied from 'MainSet8' â†’ 1718.jpg\n",
            "1719: Copied from 'MainSet8' â†’ 1719.jpg\n",
            "1720: Copied from 'MainSet8' â†’ 1720.jpg\n",
            "1721: Copied from 'MainSet8' â†’ 1721.jpg\n",
            "1722: Copied from 'MainSet8' â†’ 1722.jpg\n",
            "1723: Copied from 'MainSet8' â†’ 1723.jpg\n",
            "1724: Copied from 'MainSet8' â†’ 1724.jpg\n",
            "1725: Copied from 'MainSet8' â†’ 1725.jpg\n",
            "1726: Copied from 'MainSet8' â†’ 1726.jpg\n",
            "1727: Copied from 'MainSet8' â†’ 1727.jpg\n",
            "1728: Copied from 'MainSet8' â†’ 1728.jpg\n",
            "1729: Copied from 'MainSet8' â†’ 1729.jpg\n",
            "1730: Copied from 'MainSet8' â†’ 1730.jpg\n",
            "1731: Copied from 'MainSet8' â†’ 1731.jpg\n",
            "1732: Copied from 'MainSet8' â†’ 1732.jpg\n",
            "1733: Copied from 'MainSet8' â†’ 1733.jpg\n",
            "1734: Copied from 'MainSet8' â†’ 1734.jpg\n",
            "1735: Copied from 'MainSet8' â†’ 1735.jpg\n",
            "1736: Copied from 'MainSet8' â†’ 1736.jpg\n",
            "1737: Copied from 'MainSet8' â†’ 1737.jpg\n",
            "1738: Copied from 'MainSet8' â†’ 1738.jpg\n",
            "1739: Copied from 'MainSet8' â†’ 1739.jpg\n",
            "1740: Copied from 'MainSet8' â†’ 1740.jpg\n",
            "1741: Copied from 'MainSet8' â†’ 1741.jpg\n",
            "1742: Copied from 'MainSet8' â†’ 1742.jpg\n",
            "1743: Copied from 'MainSet8' â†’ 1743.jpg\n",
            "1744: Copied from 'MainSet8' â†’ 1744.jpg\n",
            "1745: Copied from 'MainSet8' â†’ 1745.jpg\n",
            "1746: Copied from 'MainSet8' â†’ 1746.jpg\n",
            "1747: Copied from 'MainSet8' â†’ 1747.jpg\n",
            "1748: Copied from 'MainSet8' â†’ 1748.jpg\n",
            "1749: Copied from 'MainSet8' â†’ 1749.jpg\n",
            "1750: Copied from 'MainSet8' â†’ 1750.jpg\n",
            "1751: Copied from 'MainSet8' â†’ 1751.jpg\n",
            "1752: Copied from 'MainSet8' â†’ 1752.jpg\n",
            "1753: Copied from 'MainSet8' â†’ 1753.jpg\n",
            "1754: Copied from 'MainSet8' â†’ 1754.jpg\n",
            "1755: Copied from 'MainSet8' â†’ 1755.jpg\n",
            "1756: Copied from 'MainSet8' â†’ 1756.jpg\n",
            "1757: Copied from 'MainSet8' â†’ 1757.jpg\n",
            "1758: Copied from 'MainSet8' â†’ 1758.jpg\n",
            "1759: Copied from 'MainSet8' â†’ 1759.jpg\n",
            "1760: Copied from 'MainSet8' â†’ 1760.jpg\n",
            "1761: Copied from 'MainSet8' â†’ 1761.jpg\n",
            "1762: Copied from 'MainSet8' â†’ 1762.jpg\n",
            "1763: Copied from 'MainSet8' â†’ 1763.jpg\n",
            "1764: Copied from 'MainSet8' â†’ 1764.jpg\n",
            "1765: Copied from 'MainSet8' â†’ 1765.jpg\n",
            "1766: Copied from 'MainSet8' â†’ 1766.jpg\n",
            "1767: Copied from 'MainSet8' â†’ 1767.jpg\n",
            "1768: Copied from 'MainSet8' â†’ 1768.jpg\n",
            "1769: Copied from 'MainSet8' â†’ 1769.jpg\n",
            "1770: Copied from 'MainSet8' â†’ 1770.jpg\n",
            "1771: Copied from 'MainSet8' â†’ 1771.jpg\n",
            "1772: Copied from 'MainSet8' â†’ 1772.jpg\n",
            "1773: Copied from 'MainSet8' â†’ 1773.jpg\n",
            "1774: Copied from 'MainSet8' â†’ 1774.jpg\n",
            "1775: Copied from 'MainSet8' â†’ 1775.jpg\n",
            "1776: Copied from 'MainSet8' â†’ 1776.jpg\n",
            "1777: Copied from 'MainSet8' â†’ 1777.jpg\n",
            "1778: Copied from 'MainSet8' â†’ 1778.jpg\n",
            "1779: Copied from 'MainSet8' â†’ 1779.jpg\n",
            "1780: Copied from 'MainSet8' â†’ 1780.jpg\n",
            "1781: Copied from 'MainSet8' â†’ 1781.jpg\n",
            "1782: Copied from 'MainSet8' â†’ 1782.jpg\n",
            "1783: Copied from 'MainSet8' â†’ 1783.jpg\n",
            "1784: Copied from 'MainSet8' â†’ 1784.jpg\n",
            "1785: Copied from 'MainSet8' â†’ 1785.jpg\n",
            "1786: Copied from 'MainSet8' â†’ 1786.jpg\n",
            "1787: Copied from 'MainSet8' â†’ 1787.jpg\n",
            "1788: Copied from 'MainSet8' â†’ 1788.jpg\n",
            "1789: Copied from 'MainSet8' â†’ 1789.jpg\n",
            "1790: Copied from 'MainSet8' â†’ 1790.jpg\n",
            "1791: Copied from 'MainSet8' â†’ 1791.jpg\n",
            "1792: Copied from 'MainSet8' â†’ 1792.jpg\n",
            "1793: Copied from 'MainSet8' â†’ 1793.jpg\n",
            "1794: Copied from 'MainSet8' â†’ 1794.jpg\n",
            "1795: Copied from 'MainSet8' â†’ 1795.jpg\n",
            "1796: Copied from 'MainSet8' â†’ 1796.jpg\n",
            "1797: Copied from 'MainSet8' â†’ 1797.jpg\n",
            "1798: Copied from 'MainSet8' â†’ 1798.jpg\n",
            "1799: Copied from 'MainSet8' â†’ 1799.jpg\n",
            "1800: Copied from 'MainSet8' â†’ 1800.jpg\n",
            "1801: Copied from 'MainSet8' â†’ 1801.jpg\n",
            "1802: Copied from 'MainSet8' â†’ 1802.jpg\n",
            "1803: Copied from 'MainSet8' â†’ 1803.jpg\n",
            "1804: Copied from 'MainSet8' â†’ 1804.jpg\n",
            "1805: Copied from 'MainSet8' â†’ 1805.jpg\n",
            "1806: Copied from 'MainSet8' â†’ 1806.jpg\n",
            "1807: Copied from 'MainSet8' â†’ 1807.jpg\n",
            "1808: Copied from 'MainSet8' â†’ 1808.jpg\n",
            "1809: Copied from 'MainSet8' â†’ 1809.jpg\n",
            "1810: Copied from 'MainSet8' â†’ 1810.jpg\n",
            "1811: Copied from 'MainSet8' â†’ 1811.jpg\n",
            "1812: Copied from 'MainSet8' â†’ 1812.jpg\n",
            "1813: Copied from 'MainSet8' â†’ 1813.jpg\n",
            "1814: Copied from 'MainSet8' â†’ 1814.jpg\n",
            "1815: Copied from 'MainSet8' â†’ 1815.jpg\n",
            "1816: Copied from 'MainSet8' â†’ 1816.jpg\n",
            "1817: Copied from 'MainSet8' â†’ 1817.jpg\n",
            "1818: Copied from 'MainSet8' â†’ 1818.jpg\n",
            "1819: Copied from 'MainSet9' â†’ 1819.jpg\n",
            "1820: Copied from 'MainSet9' â†’ 1820.jpg\n",
            "1821: Copied from 'MainSet9' â†’ 1821.jpg\n",
            "1822: Copied from 'MainSet9' â†’ 1822.jpg\n",
            "1823: Copied from 'MainSet9' â†’ 1823.jpg\n",
            "1824: Copied from 'MainSet9' â†’ 1824.jpg\n",
            "1825: Copied from 'MainSet9' â†’ 1825.jpg\n",
            "1826: Copied from 'MainSet9' â†’ 1826.jpg\n",
            "1827: Copied from 'MainSet9' â†’ 1827.jpg\n",
            "1828: Copied from 'MainSet9' â†’ 1828.jpg\n",
            "1829: Copied from 'MainSet9' â†’ 1829.jpg\n",
            "1830: Copied from 'MainSet9' â†’ 1830.jpg\n",
            "1831: Copied from 'MainSet9' â†’ 1831.jpg\n",
            "1832: Copied from 'MainSet9' â†’ 1832.jpg\n",
            "1833: Copied from 'MainSet9' â†’ 1833.jpg\n",
            "1834: Copied from 'MainSet9' â†’ 1834.jpg\n",
            "1835: Copied from 'MainSet9' â†’ 1835.jpg\n",
            "1836: Copied from 'MainSet9' â†’ 1836.jpg\n",
            "1837: Copied from 'MainSet9' â†’ 1837.jpg\n",
            "1838: Copied from 'MainSet9' â†’ 1838.jpg\n",
            "1839: Copied from 'MainSet9' â†’ 1839.jpg\n",
            "1840: Copied from 'MainSet9' â†’ 1840.jpg\n",
            "1841: Copied from 'MainSet9' â†’ 1841.jpg\n",
            "1842: Copied from 'MainSet9' â†’ 1842.jpg\n",
            "1843: Copied from 'MainSet9' â†’ 1843.jpg\n",
            "1844: Copied from 'MainSet9' â†’ 1844.jpg\n",
            "1845: Copied from 'MainSet9' â†’ 1845.jpg\n",
            "1846: Copied from 'MainSet9' â†’ 1846.jpg\n",
            "1847: Copied from 'MainSet9' â†’ 1847.jpg\n",
            "1848: Copied from 'MainSet9' â†’ 1848.jpg\n",
            "1849: Copied from 'MainSet9' â†’ 1849.jpg\n",
            "1850: Copied from 'MainSet9' â†’ 1850.jpg\n",
            "1851: Copied from 'MainSet9' â†’ 1851.jpg\n",
            "1852: Copied from 'MainSet9' â†’ 1852.jpg\n",
            "1853: Copied from 'MainSet9' â†’ 1853.jpg\n",
            "1854: Copied from 'MainSet9' â†’ 1854.jpg\n",
            "1855: Copied from 'MainSet9' â†’ 1855.jpg\n",
            "1856: Copied from 'MainSet9' â†’ 1856.jpg\n",
            "1857: Copied from 'MainSet9' â†’ 1857.jpg\n",
            "1858: Copied from 'MainSet9' â†’ 1858.jpg\n",
            "1859: Copied from 'MainSet9' â†’ 1859.jpg\n",
            "1860: Copied from 'MainSet9' â†’ 1860.jpg\n",
            "1861: Copied from 'MainSet9' â†’ 1861.jpg\n",
            "1862: Copied from 'MainSet9' â†’ 1862.jpg\n",
            "1863: Copied from 'MainSet9' â†’ 1863.jpg\n",
            "1864: Copied from 'MainSet9' â†’ 1864.jpg\n",
            "1865: Copied from 'MainSet9' â†’ 1865.jpg\n",
            "1866: Copied from 'MainSet9' â†’ 1866.jpg\n",
            "1867: Copied from 'MainSet9' â†’ 1867.jpg\n",
            "1868: Copied from 'MainSet9' â†’ 1868.jpg\n",
            "1869: Copied from 'MainSet9' â†’ 1869.jpg\n",
            "1870: Copied from 'MainSet9' â†’ 1870.jpg\n",
            "1871: Copied from 'MainSet9' â†’ 1871.jpg\n",
            "1872: Copied from 'MainSet9' â†’ 1872.jpg\n",
            "1873: Copied from 'MainSet9' â†’ 1873.jpg\n",
            "1874: Copied from 'MainSet9' â†’ 1874.jpg\n",
            "1875: Copied from 'MainSet9' â†’ 1875.jpg\n",
            "1876: Copied from 'MainSet9' â†’ 1876.jpg\n",
            "1877: Copied from 'MainSet9' â†’ 1877.jpg\n",
            "1878: Copied from 'MainSet9' â†’ 1878.jpg\n",
            "1879: Copied from 'MainSet9' â†’ 1879.jpg\n",
            "1880: Copied from 'MainSet9' â†’ 1880.jpg\n",
            "1881: Copied from 'MainSet9' â†’ 1881.jpg\n",
            "1882: Copied from 'MainSet9' â†’ 1882.jpg\n",
            "1883: Copied from 'MainSet9' â†’ 1883.jpg\n",
            "1884: Copied from 'MainSet9' â†’ 1884.jpg\n",
            "1885: Copied from 'MainSet9' â†’ 1885.jpg\n",
            "1886: Copied from 'MainSet9' â†’ 1886.jpg\n",
            "1887: Copied from 'MainSet9' â†’ 1887.jpg\n",
            "1888: Copied from 'MainSet9' â†’ 1888.jpg\n",
            "1889: Copied from 'MainSet9' â†’ 1889.jpg\n",
            "1890: Copied from 'MainSet9' â†’ 1890.jpg\n",
            "1891: Copied from 'MainSet9' â†’ 1891.jpg\n",
            "1892: Copied from 'MainSet9' â†’ 1892.jpg\n",
            "1893: Copied from 'MainSet9' â†’ 1893.jpg\n",
            "1894: Copied from 'MainSet9' â†’ 1894.jpg\n",
            "1895: Copied from 'MainSet9' â†’ 1895.jpg\n",
            "1896: Copied from 'MainSet9' â†’ 1896.jpg\n",
            "1897: Copied from 'MainSet9' â†’ 1897.jpg\n",
            "1898: Copied from 'MainSet9' â†’ 1898.jpg\n",
            "1899: Copied from 'MainSet9' â†’ 1899.jpg\n",
            "1900: Copied from 'MainSet9' â†’ 1900.jpg\n",
            "1901: Copied from 'MainSet9' â†’ 1901.jpg\n",
            "1902: Copied from 'MainSet9' â†’ 1902.jpg\n",
            "1903: Copied from 'MainSet9' â†’ 1903.jpg\n",
            "1904: Copied from 'MainSet9' â†’ 1904.jpg\n",
            "1905: Copied from 'MainSet9' â†’ 1905.jpg\n",
            "1906: Copied from 'MainSet9' â†’ 1906.jpg\n",
            "1907: Copied from 'MainSet9' â†’ 1907.jpg\n",
            "1908: Copied from 'MainSet9' â†’ 1908.jpg\n",
            "1909: Copied from 'MainSet9' â†’ 1909.jpg\n",
            "1910: Copied from 'MainSet9' â†’ 1910.jpg\n",
            "1911: Copied from 'MainSet9' â†’ 1911.jpg\n",
            "1912: Copied from 'MainSet9' â†’ 1912.jpg\n",
            "1913: Copied from 'MainSet9' â†’ 1913.jpg\n",
            "1914: Copied from 'MainSet9' â†’ 1914.jpg\n",
            "1915: Copied from 'MainSet9' â†’ 1915.jpg\n",
            "1916: Copied from 'MainSet9' â†’ 1916.jpg\n",
            "1917: Copied from 'MainSet9' â†’ 1917.jpg\n",
            "1918: Copied from 'MainSet9' â†’ 1918.jpg\n",
            "1919: Copied from 'MainSet9' â†’ 1919.jpg\n",
            "1920: Copied from 'MainSet9' â†’ 1920.jpg\n",
            "1921: Copied from 'MainSet9' â†’ 1921.jpg\n",
            "1922: Copied from 'MainSet9' â†’ 1922.jpg\n",
            "1923: Copied from 'MainSet9' â†’ 1923.jpg\n",
            "1924: Copied from 'MainSet9' â†’ 1924.jpg\n",
            "1925: Copied from 'MainSet9' â†’ 1925.jpg\n",
            "1926: Copied from 'MainSet9' â†’ 1926.jpg\n",
            "1927: Copied from 'MainSet9' â†’ 1927.jpg\n",
            "1928: Copied from 'MainSet9' â†’ 1928.jpg\n",
            "1929: Copied from 'MainSet9' â†’ 1929.jpg\n",
            "1930: Copied from 'MainSet9' â†’ 1930.jpg\n",
            "1931: Copied from 'MainSet9' â†’ 1931.jpg\n",
            "1932: Copied from 'MainSet9' â†’ 1932.jpg\n",
            "1933: Copied from 'MainSet9' â†’ 1933.jpg\n",
            "1934: Copied from 'MainSet9' â†’ 1934.jpg\n",
            "1935: Copied from 'MainSet9' â†’ 1935.jpg\n",
            "1936: Copied from 'MainSet9' â†’ 1936.jpg\n",
            "1937: Copied from 'MainSet9' â†’ 1937.jpg\n",
            "1938: Copied from 'MainSet9' â†’ 1938.jpg\n",
            "1939: Copied from 'MainSet9' â†’ 1939.jpg\n",
            "1940: Copied from 'MainSet9' â†’ 1940.jpg\n",
            "1941: Copied from 'MainSet9' â†’ 1941.jpg\n",
            "1942: Copied from 'MainSet9' â†’ 1942.jpg\n",
            "1943: Copied from 'MainSet9' â†’ 1943.jpg\n",
            "1944: Copied from 'MainSet9' â†’ 1944.jpg\n",
            "1945: Copied from 'MainSet9' â†’ 1945.jpg\n",
            "1946: Copied from 'MainSet9' â†’ 1946.jpg\n",
            "1947: Copied from 'MainSet9' â†’ 1947.jpg\n",
            "1948: Copied from 'MainSet9' â†’ 1948.jpg\n",
            "1949: Copied from 'MainSet9' â†’ 1949.jpg\n",
            "1950: Copied from 'MainSet9' â†’ 1950.jpg\n",
            "1951: Copied from 'MainSet9' â†’ 1951.jpg\n",
            "1952: Copied from 'MainSet9' â†’ 1952.jpg\n",
            "1953: Copied from 'MainSet9' â†’ 1953.jpg\n",
            "1954: Copied from 'MainSet9' â†’ 1954.jpg\n",
            "1955: Copied from 'MainSet9' â†’ 1955.jpg\n",
            "1956: Copied from 'MainSet9' â†’ 1956.jpg\n",
            "1957: Copied from 'MainSet9' â†’ 1957.jpg\n",
            "1958: Copied from 'MainSet9' â†’ 1958.jpg\n",
            "1959: Copied from 'MainSet9' â†’ 1959.jpg\n",
            "1960: Copied from 'MainSet9' â†’ 1960.jpg\n",
            "1961: Copied from 'MainSet9' â†’ 1961.jpg\n",
            "1962: Copied from 'MainSet9' â†’ 1962.jpg\n",
            "1963: Copied from 'MainSet9' â†’ 1963.jpg\n",
            "1964: Copied from 'MainSet9' â†’ 1964.jpg\n",
            "1965: Copied from 'MainSet9' â†’ 1965.jpg\n",
            "1966: Copied from 'MainSet9' â†’ 1966.jpg\n",
            "1967: Copied from 'MainSet9' â†’ 1967.jpg\n",
            "1968: Copied from 'MainSet9' â†’ 1968.jpg\n",
            "1969: Copied from 'MainSet9' â†’ 1969.jpg\n",
            "1970: Copied from 'MainSet9' â†’ 1970.jpg\n",
            "1971: Copied from 'MainSet9' â†’ 1971.jpg\n",
            "1972: Copied from 'MainSet9' â†’ 1972.jpg\n",
            "1973: Copied from 'MainSet9' â†’ 1973.jpg\n",
            "1974: Copied from 'MainSet9' â†’ 1974.jpg\n",
            "1975: Copied from 'MainSet9' â†’ 1975.jpg\n",
            "1976: Copied from 'MainSet9' â†’ 1976.jpg\n",
            "1977: Copied from 'MainSet9' â†’ 1977.jpg\n",
            "1978: Copied from 'MainSet9' â†’ 1978.jpg\n",
            "1979: Copied from 'MainSet9' â†’ 1979.jpg\n",
            "1980: Copied from 'MainSet9' â†’ 1980.jpg\n",
            "1981: Copied from 'MainSet9' â†’ 1981.jpg\n",
            "1982: Copied from 'MainSet9' â†’ 1982.jpg\n",
            "1983: Copied from 'MainSet9' â†’ 1983.jpg\n",
            "1984: Copied from 'MainSet9' â†’ 1984.jpg\n",
            "1985: Copied from 'MainSet9' â†’ 1985.jpg\n",
            "1986: Copied from 'MainSet9' â†’ 1986.jpg\n",
            "1987: Copied from 'MainSet9' â†’ 1987.jpg\n",
            "1988: Copied from 'MainSet9' â†’ 1988.jpg\n",
            "1989: Copied from 'MainSet9' â†’ 1989.jpg\n",
            "1990: Copied from 'MainSet9' â†’ 1990.jpg\n",
            "1991: Copied from 'MainSet9' â†’ 1991.jpg\n",
            "1992: Copied from 'MainSet9' â†’ 1992.jpg\n",
            "1993: Copied from 'MainSet9' â†’ 1993.jpg\n",
            "1994: Copied from 'MainSet9' â†’ 1994.jpg\n",
            "1995: Copied from 'MainSet9' â†’ 1995.jpg\n",
            "1996: Copied from 'MainSet9' â†’ 1996.jpg\n",
            "1997: Copied from 'MainSet9' â†’ 1997.jpg\n",
            "1998: Copied from 'MainSet9' â†’ 1998.jpg\n",
            "1999: Copied from 'MainSet9' â†’ 1999.jpg\n",
            "2000: Copied from 'MainSet9' â†’ 2000.jpg\n",
            "2001: Copied from 'MainSet9' â†’ 2001.jpg\n",
            "2002: Copied from 'MainSet9' â†’ 2002.jpg\n",
            "2003: Copied from 'MainSet9' â†’ 2003.jpg\n",
            "2004: Copied from 'MainSet9' â†’ 2004.jpg\n",
            "2005: Copied from 'MainSet9' â†’ 2005.jpg\n",
            "2006: Copied from 'MainSet9' â†’ 2006.jpg\n",
            "2007: Copied from 'MainSet9' â†’ 2007.jpg\n",
            "2008: Copied from 'MainSet9' â†’ 2008.jpg\n",
            "2009: Copied from 'MainSet9' â†’ 2009.jpg\n",
            "2010: Copied from 'MainSet9' â†’ 2010.jpg\n",
            "2011: Copied from 'MainSet9' â†’ 2011.jpg\n",
            "2012: Copied from 'MainSet9' â†’ 2012.jpg\n",
            "2013: Copied from 'MainSet9' â†’ 2013.jpg\n",
            "2014: Copied from 'MainSet9' â†’ 2014.jpg\n",
            "2015: Copied from 'MainSet9' â†’ 2015.jpg\n",
            "2016: Copied from 'MainSet9' â†’ 2016.jpg\n",
            "2017: Copied from 'MainSet9' â†’ 2017.jpg\n",
            "2018: Copied from 'MainSet9' â†’ 2018.jpg\n",
            "2019: Copied from 'MainSet9' â†’ 2019.jpg\n",
            "2020: Copied from 'MainSet9' â†’ 2020.jpg\n",
            "2021: Copied from 'MainSet9' â†’ 2021.jpg\n",
            "2022: Copied from 'MainSet9' â†’ 2022.jpg\n",
            "2023: Copied from 'MainSet9' â†’ 2023.jpg\n",
            "2024: Copied from 'MainSet9' â†’ 2024.jpg\n",
            "2025: Copied from 'MainSet9' â†’ 2025.jpg\n",
            "2026: Copied from 'MainSet9' â†’ 2026.jpg\n",
            "2027: Copied from 'MainSet9' â†’ 2027.jpg\n",
            "2028: Copied from 'MainSet9' â†’ 2028.jpg\n",
            "2029: Copied from 'MainSet9' â†’ 2029.jpg\n",
            "2030: Copied from 'MainSet9' â†’ 2030.jpg\n",
            "2031: Copied from 'MainSet9' â†’ 2031.jpg\n",
            "2032: Copied from 'MainSet9' â†’ 2032.jpg\n",
            "2033: Copied from 'MainSet9' â†’ 2033.jpg\n",
            "2034: Copied from 'MainSet9' â†’ 2034.jpg\n",
            "2035: Copied from 'MainSet9' â†’ 2035.jpg\n",
            "2036: Copied from 'MainSet9' â†’ 2036.jpg\n",
            "2037: Copied from 'MainSet9' â†’ 2037.jpg\n",
            "2038: Copied from 'MainSet9' â†’ 2038.jpg\n",
            "\n",
            "âœ… Total images copied and renamed: 2038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics mediapipe opencv-python"
      ],
      "metadata": {
        "id": "K-SLNVytu5ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "\n",
        "# Paths\n",
        "image_folder = '/content/drive/MyDrive/Saif/images'\n",
        "label_folder = '/content/drive/MyDrive/Saif/labels'\n",
        "visual_folder = '/content/drive/MyDrive/Saif/labeled_images'\n",
        "\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "os.makedirs(visual_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv8 and MediaPipe\n",
        "model = YOLO('yolov8n.pt')\n",
        "pose = mp.solutions.pose.Pose(static_image_mode=True, model_complexity=2)\n",
        "\n",
        "# Class names: 0 = Engaged, 1 = Distracted\n",
        "class_names = ['Engaged', 'Distracted']\n",
        "\n",
        "# Estimate head direction based on eyes\n",
        "def estimate_head_direction(landmarks):\n",
        "    try:\n",
        "        left_eye = landmarks[2]\n",
        "        right_eye = landmarks[5]\n",
        "        dx = left_eye.x - right_eye.x\n",
        "        if dx > 0.04:\n",
        "            return 'left'\n",
        "        elif dx < -0.04:\n",
        "            return 'right'\n",
        "        else:\n",
        "            return 'front'\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "# Classify using head direction compared to majority (teacher_dir)\n",
        "def classify_posture_binary(landmarks, teacher_dir):\n",
        "    direction = estimate_head_direction(landmarks)\n",
        "    if direction == teacher_dir:\n",
        "        return 0  # Engaged\n",
        "    else:\n",
        "        return 1  # Distracted\n",
        "\n",
        "# Process images\n",
        "for file in os.listdir(image_folder):\n",
        "    if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(image_folder, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    img_h, img_w = image.shape[:2]\n",
        "    results = model(image_path)[0]\n",
        "    boxes = results.boxes.data\n",
        "\n",
        "    all_directions = []\n",
        "    temp_landmarks = []\n",
        "    temp_boxes = []\n",
        "\n",
        "    for box in boxes:\n",
        "        cls = int(box[5])\n",
        "        if cls != 0:\n",
        "            continue  # only person class\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
        "\n",
        "        person_crop = image[y1:y2, x1:x2]\n",
        "        if person_crop.size == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
        "            pose_result = pose.process(crop_rgb)\n",
        "        except:\n",
        "            pose_result = None\n",
        "\n",
        "        if pose_result and pose_result.pose_landmarks:\n",
        "            landmarks = pose_result.pose_landmarks.landmark\n",
        "            dir = estimate_head_direction(landmarks)\n",
        "            all_directions.append(dir)\n",
        "            temp_landmarks.append(landmarks)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "        else:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    # Decide teacher direction (majority vote)\n",
        "    teacher_dir = 'front'\n",
        "    if all_directions:\n",
        "        teacher_dir = Counter(all_directions).most_common(1)[0][0]\n",
        "\n",
        "    label_lines = []\n",
        "    engaged_count = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for i, landmarks in enumerate(temp_landmarks):\n",
        "        x1, y1, x2, y2 = temp_boxes[i]\n",
        "\n",
        "        if landmarks:\n",
        "            posture_class = classify_posture_binary(landmarks, teacher_dir)\n",
        "\n",
        "            if posture_class == 0:\n",
        "                engaged_count += 1\n",
        "            total_count += 1\n",
        "\n",
        "            x_center = ((x1 + x2) / 2) / img_w\n",
        "            y_center = ((y1 + y2) / 2) / img_h\n",
        "            w = (x2 - x1) / img_w\n",
        "            h = (y2 - y1) / img_h\n",
        "\n",
        "            label_line = f\"{posture_class} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\"\n",
        "            label_lines.append(label_line)\n",
        "\n",
        "            # Draw bounding box with label\n",
        "            color = (0, 255, 0) if posture_class == 0 else (0, 0, 255)\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(image, class_names[posture_class], (x1, y1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "        else:\n",
        "            # Pose not detected\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (128, 128, 128), 2)\n",
        "            cv2.putText(image, 'no pose', (x1, y1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)\n",
        "\n",
        "    # Save YOLO-format label file\n",
        "    label_file = os.path.join(label_folder, file.rsplit('.', 1)[0] + '.txt')\n",
        "    with open(label_file, 'w') as f:\n",
        "        for line in label_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    # Save annotated image\n",
        "    visual_path = os.path.join(visual_folder, file)\n",
        "    cv2.imwrite(visual_path, image)\n",
        "\n",
        "    # Print engagement stats\n",
        "    engagement_percent = (engaged_count / total_count * 100) if total_count > 0 else 0\n",
        "    print(f\"{file}: {engaged_count}/{total_count} engaged ({engagement_percent:.1f}%) - Teacher direction: {teacher_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC84XBBJVmQo",
        "outputId": "2907ec4e-6b71-484c-f1a5-415883cacb0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img1.jpg: 384x640 23 persons, 2 bottles, 4 chairs, 4 laptops, 436.8ms\n",
            "Speed: 17.9ms preprocess, 436.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img1.jpg: 19/21 engaged (90.5%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img2.jpg: 384x640 24 persons, 2 bottles, 1 cup, 3 chairs, 4 laptops, 151.5ms\n",
            "Speed: 4.5ms preprocess, 151.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img2.jpg: 20/21 engaged (95.2%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img3.jpg: 384x640 24 persons, 2 bottles, 1 cup, 2 chairs, 3 laptops, 154.1ms\n",
            "Speed: 3.2ms preprocess, 154.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img3.jpg: 19/21 engaged (90.5%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img4.jpg: 384x640 24 persons, 2 bottles, 1 cup, 2 chairs, 2 laptops, 216.7ms\n",
            "Speed: 4.5ms preprocess, 216.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img4.jpg: 18/21 engaged (85.7%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img5.jpg: 384x640 24 persons, 2 bottles, 2 chairs, 4 laptops, 251.6ms\n",
            "Speed: 5.1ms preprocess, 251.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img5.jpg: 18/21 engaged (85.7%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img6.jpg: 384x640 24 persons, 2 bottles, 1 cup, 4 chairs, 4 laptops, 146.2ms\n",
            "Speed: 3.2ms preprocess, 146.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img6.jpg: 19/21 engaged (90.5%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img7.jpg: 384x640 6 persons, 151.8ms\n",
            "Speed: 3.2ms preprocess, 151.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img7.jpg: 5/5 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img8.jpg: 384x640 7 persons, 147.3ms\n",
            "Speed: 3.2ms preprocess, 147.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img8.jpg: 6/6 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img9.jpg: 384x640 7 persons, 150.7ms\n",
            "Speed: 3.6ms preprocess, 150.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img9.jpg: 6/6 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img10.jpg: 384x640 6 persons, 154.5ms\n",
            "Speed: 3.2ms preprocess, 154.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img10.jpg: 5/5 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img11.jpg: 384x640 6 persons, 160.0ms\n",
            "Speed: 3.6ms preprocess, 160.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img11.jpg: 5/5 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img12.jpg: 384x640 6 persons, 155.3ms\n",
            "Speed: 5.8ms preprocess, 155.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img12.jpg: 5/5 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img13.jpg: 384x640 6 persons, 161.4ms\n",
            "Speed: 4.7ms preprocess, 161.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img13.jpg: 5/5 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img14.jpg: 384x640 6 persons, 240.1ms\n",
            "Speed: 4.7ms preprocess, 240.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img14.jpg: 5/5 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img15.jpg: 384x640 19 persons, 1 chair, 242.0ms\n",
            "Speed: 4.8ms preprocess, 242.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img15.jpg: 11/15 engaged (73.3%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img16.jpg: 384x640 19 persons, 1 chair, 166.4ms\n",
            "Speed: 3.3ms preprocess, 166.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img16.jpg: 11/14 engaged (78.6%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img4.JPG: 480x640 17 persons, 7 chairs, 202.1ms\n",
            "Speed: 4.4ms preprocess, 202.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img4.JPG: 12/12 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img7.JPG: 480x640 12 persons, 1 surfboard, 5 chairs, 218.6ms\n",
            "Speed: 4.6ms preprocess, 218.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img7.JPG: 6/6 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img19.JPG: 480x640 9 persons, 5 chairs, 1 couch, 1 dining table, 2 tvs, 2 laptops, 182.2ms\n",
            "Speed: 4.5ms preprocess, 182.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img19.JPG: 5/5 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img26.JPG: 480x640 18 persons, 1 tie, 1 chair, 2 laptops, 3 books, 185.8ms\n",
            "Speed: 4.2ms preprocess, 185.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img26.JPG: 15/18 engaged (83.3%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img27.JPG: 480x640 16 persons, 2 ties, 6 chairs, 231.6ms\n",
            "Speed: 5.7ms preprocess, 231.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img27.JPG: 12/14 engaged (85.7%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img30.JPG: 480x640 16 persons, 10 chairs, 184.6ms\n",
            "Speed: 4.2ms preprocess, 184.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img30.JPG: 11/12 engaged (91.7%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img49.jpg: 384x640 12 persons, 8 chairs, 3 dining tables, 1 clock, 154.4ms\n",
            "Speed: 2.9ms preprocess, 154.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img49.jpg: 6/11 engaged (54.5%) - Teacher direction: front\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img50.jpg: 384x640 12 persons, 5 chairs, 1 dining table, 1 clock, 163.7ms\n",
            "Speed: 3.2ms preprocess, 163.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img50.jpg: 9/12 engaged (75.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img51.jpg: 384x640 15 persons, 5 chairs, 1 dining table, 1 clock, 145.0ms\n",
            "Speed: 3.1ms preprocess, 145.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img51.jpg: 6/13 engaged (46.2%) - Teacher direction: front\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/img60.jpg: 384x640 16 persons, 1 backpack, 2 books, 264.9ms\n",
            "Speed: 4.2ms preprocess, 264.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img60.jpg: 13/14 engaged (92.9%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1366.jpg: 384x640 11 persons, 5 chairs, 264.7ms\n",
            "Speed: 5.0ms preprocess, 264.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1366.jpg: 11/11 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/829.jpg: 384x640 16 persons, 14 chairs, 3 dining tables, 147.9ms\n",
            "Speed: 3.1ms preprocess, 147.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "829.jpg: 13/14 engaged (92.9%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/882.jpg: 384x640 12 persons, 14 chairs, 2 dining tables, 1 laptop, 147.3ms\n",
            "Speed: 3.0ms preprocess, 147.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "882.jpg: 10/11 engaged (90.9%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1104.jpg: 384x640 11 persons, 3 chairs, 147.5ms\n",
            "Speed: 2.9ms preprocess, 147.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1104.jpg: 9/11 engaged (81.8%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/884.jpg: 384x640 15 persons, 11 chairs, 2 dining tables, 1 laptop, 145.6ms\n",
            "Speed: 3.0ms preprocess, 145.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "884.jpg: 12/12 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1200.jpg: 384x640 13 persons, 2 chairs, 2 remotes, 142.5ms\n",
            "Speed: 3.0ms preprocess, 142.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1200.jpg: 9/12 engaged (75.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/830.jpg: 384x640 13 persons, 16 chairs, 3 dining tables, 240.2ms\n",
            "Speed: 4.3ms preprocess, 240.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "830.jpg: 12/13 engaged (92.3%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/649.jpg: 384x640 21 persons, 2 bottles, 5 chairs, 3 laptops, 158.6ms\n",
            "Speed: 3.1ms preprocess, 158.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "649.jpg: 14/16 engaged (87.5%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/628.jpg: 384x640 21 persons, 3 bottles, 5 chairs, 1 laptop, 175.8ms\n",
            "Speed: 2.9ms preprocess, 175.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "628.jpg: 14/17 engaged (82.4%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/574.jpg: 384x640 12 persons, 1 chair, 4 tvs, 10 laptops, 2 mouses, 1 clock, 147.7ms\n",
            "Speed: 2.9ms preprocess, 147.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "574.jpg: 3/5 engaged (60.0%) - Teacher direction: front\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1691 (1).jpg: 384x640 15 persons, 14 chairs, 1 laptop, 154.5ms\n",
            "Speed: 3.0ms preprocess, 154.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1691 (1).jpg: 15/15 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1058.jpg: 384x640 12 persons, 4 chairs, 244.6ms\n",
            "Speed: 5.0ms preprocess, 244.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1058.jpg: 9/11 engaged (81.8%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1691.jpg: 384x640 15 persons, 14 chairs, 1 laptop, 247.5ms\n",
            "Speed: 4.8ms preprocess, 247.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1691.jpg: 15/15 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1665.jpg: 384x640 11 persons, 15 chairs, 145.8ms\n",
            "Speed: 3.0ms preprocess, 145.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1665.jpg: 11/11 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1459.jpg: 384x640 11 persons, 2 chairs, 1 book, 149.4ms\n",
            "Speed: 3.1ms preprocess, 149.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1459.jpg: 7/10 engaged (70.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1481.jpg: 384x640 23 persons, 1 suitcase, 4 chairs, 153.8ms\n",
            "Speed: 2.9ms preprocess, 153.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1481.jpg: 22/23 engaged (95.7%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1495.jpg: 384x640 17 persons, 6 chairs, 150.6ms\n",
            "Speed: 3.2ms preprocess, 150.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1495.jpg: 16/17 engaged (94.1%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1886.jpg: 384x640 18 persons, 4 chairs, 251.0ms\n",
            "Speed: 4.6ms preprocess, 251.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1886.jpg: 11/16 engaged (68.8%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1440.jpg: 384x640 13 persons, 1 backpack, 1 suitcase, 1 chair, 155.9ms\n",
            "Speed: 2.9ms preprocess, 155.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1440.jpg: 12/13 engaged (92.3%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1450.jpg: 384x640 12 persons, 1 chair, 170.0ms\n",
            "Speed: 3.0ms preprocess, 170.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1450.jpg: 11/12 engaged (91.7%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/1855.jpg: 384x640 18 persons, 6 chairs, 168.9ms\n",
            "Speed: 3.1ms preprocess, 168.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1855.jpg: 10/14 engaged (71.4%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/370.jpg: 384x640 20 persons, 4 chairs, 2 tvs, 8 laptops, 1 cell phone, 148.4ms\n",
            "Speed: 3.0ms preprocess, 148.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "370.jpg: 19/19 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/239.jpg: 384x640 15 persons, 5 chairs, 12 laptops, 234.3ms\n",
            "Speed: 4.2ms preprocess, 234.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "239.jpg: 11/11 engaged (100.0%) - Teacher direction: left\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/images/556.jpg: 384x640 9 persons, 1 chair, 4 tvs, 4 laptops, 2 mouses, 1 clock, 155.2ms\n",
            "Speed: 3.1ms preprocess, 155.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "556.jpg: 3/7 engaged (42.9%) - Teacher direction: left\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# === Paths ===\n",
        "image_dir = '/content/drive/MyDrive/MMimages'\n",
        "output_base = '/content/drive/MyDrive/image_split'\n",
        "\n",
        "# Create output folders\n",
        "splits = ['train', 'val', 'test']\n",
        "for split in splits:\n",
        "    os.makedirs(os.path.join(output_base, split), exist_ok=True)\n",
        "\n",
        "# Get and shuffle image files\n",
        "all_images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "random.seed(42)  # For reproducibility\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Define splits\n",
        "train_imgs = all_images[:1500]\n",
        "val_imgs = all_images[1500:1900]\n",
        "test_imgs = all_images[1900:]  # all remaining images\n",
        "\n",
        "# Function to move images\n",
        "def move_images(file_list, split_name):\n",
        "    for file in file_list:\n",
        "        src = os.path.join(image_dir, file)\n",
        "        dst = os.path.join(output_base, split_name, file)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Move images to folders\n",
        "move_images(train_imgs, 'train')\n",
        "move_images(val_imgs, 'val')\n",
        "move_images(test_imgs, 'test')\n",
        "\n",
        "# Report\n",
        "print(f\"âœ… Done: {len(train_imgs)} train, {len(val_imgs)} val, {len(test_imgs)} test images MOVED to '{output_base}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_OkJpCMbJ8",
        "outputId": "f1c045b1-21aa-4c6f-fbef-449a52944d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Done: 1500 train, 400 val, 142 test images MOVED to '/content/drive/MyDrive/image_split'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "\n",
        "# Paths\n",
        "image_folder = '/content/drive/MyDrive/Dataset/images/val'\n",
        "label_folder = '/content/drive/MyDrive/Dataset/labels/val'\n",
        "\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv8 and MediaPipe\n",
        "model = YOLO('yolov8n.pt')\n",
        "pose = mp.solutions.pose.Pose(static_image_mode=True, model_complexity=2)\n",
        "\n",
        "# Estimate head direction based on eyes\n",
        "def estimate_head_direction(landmarks):\n",
        "    try:\n",
        "        left_eye = landmarks[2]\n",
        "        right_eye = landmarks[5]\n",
        "        dx = left_eye.x - right_eye.x\n",
        "        if dx > 0.04:\n",
        "            return 'left'\n",
        "        elif dx < -0.04:\n",
        "            return 'right'\n",
        "        else:\n",
        "            return 'front'\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "# Classify using head direction compared to majority (teacher_dir)\n",
        "def classify_posture_binary(landmarks, teacher_dir):\n",
        "    direction = estimate_head_direction(landmarks)\n",
        "    return 0 if direction == teacher_dir else 1  # 0: Engaged, 1: Distracted\n",
        "\n",
        "# Process images\n",
        "for file in os.listdir(image_folder):\n",
        "    if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(image_folder, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    img_h, img_w = image.shape[:2]\n",
        "    results = model(image_path)[0]\n",
        "    boxes = results.boxes.data\n",
        "\n",
        "    all_directions = []\n",
        "    temp_landmarks = []\n",
        "    temp_boxes = []\n",
        "\n",
        "    for box in boxes:\n",
        "        cls = int(box[5])\n",
        "        if cls != 0:\n",
        "            continue  # only person class\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
        "\n",
        "        person_crop = image[y1:y2, x1:x2]\n",
        "        if person_crop.size == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
        "            pose_result = pose.process(crop_rgb)\n",
        "        except:\n",
        "            pose_result = None\n",
        "\n",
        "        if pose_result and pose_result.pose_landmarks:\n",
        "            landmarks = pose_result.pose_landmarks.landmark\n",
        "            dir = estimate_head_direction(landmarks)\n",
        "            all_directions.append(dir)\n",
        "            temp_landmarks.append(landmarks)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "        else:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    # Determine teacher direction by majority\n",
        "    teacher_dir = 'front'\n",
        "    if all_directions:\n",
        "        teacher_dir = Counter(all_directions).most_common(1)[0][0]\n",
        "\n",
        "    label_lines = []\n",
        "\n",
        "    for i, landmarks in enumerate(temp_landmarks):\n",
        "        x1, y1, x2, y2 = temp_boxes[i]\n",
        "\n",
        "        if landmarks:\n",
        "            posture_class = classify_posture_binary(landmarks, teacher_dir)\n",
        "\n",
        "            x_center = ((x1 + x2) / 2) / img_w\n",
        "            y_center = ((y1 + y2) / 2) / img_h\n",
        "            w = (x2 - x1) / img_w\n",
        "            h = (y2 - y1) / img_h\n",
        "\n",
        "            label_line = f\"{posture_class} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\"\n",
        "            label_lines.append(label_line)\n",
        "\n",
        "    # Save YOLO-format label file\n",
        "    label_file = os.path.join(label_folder, file.rsplit('.', 1)[0] + '.txt')\n",
        "    with open(label_file, 'w') as f:\n",
        "        for line in label_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    print(f\"{file}: {len(label_lines)} labels saved (Teacher direction: {teacher_dir})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3koiqVSuUfp8",
        "outputId": "960808c0-d076-4b70-ab52-b22e840a24ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1044.jpg: 384x640 12 persons, 15 chairs, 3 dining tables, 288.1ms\n",
            "Speed: 5.6ms preprocess, 288.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1044.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1047.jpg: 384x640 12 persons, 17 chairs, 3 dining tables, 158.6ms\n",
            "Speed: 3.5ms preprocess, 158.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1047.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1049.jpg: 384x640 14 persons, 16 chairs, 3 dining tables, 145.4ms\n",
            "Speed: 3.4ms preprocess, 145.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1049.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1050.jpg: 384x640 11 persons, 17 chairs, 3 dining tables, 142.7ms\n",
            "Speed: 3.1ms preprocess, 142.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1050.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1057.jpg: 384x640 13 persons, 15 chairs, 3 dining tables, 225.0ms\n",
            "Speed: 5.4ms preprocess, 225.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1057.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1059.jpg: 384x640 12 persons, 4 chairs, 225.7ms\n",
            "Speed: 5.2ms preprocess, 225.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1059.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1062.jpg: 384x640 11 persons, 3 chairs, 159.1ms\n",
            "Speed: 5.2ms preprocess, 159.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1062.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1066.jpg: 384x640 12 persons, 4 chairs, 157.8ms\n",
            "Speed: 3.3ms preprocess, 157.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1066.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1073.jpg: 384x640 10 persons, 6 chairs, 143.2ms\n",
            "Speed: 3.5ms preprocess, 143.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1073.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1082.jpg: 384x640 11 persons, 6 chairs, 137.1ms\n",
            "Speed: 3.3ms preprocess, 137.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1082.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1086.jpg: 384x640 10 persons, 3 chairs, 145.7ms\n",
            "Speed: 3.3ms preprocess, 145.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1086.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1107.jpg: 384x640 11 persons, 1 pizza, 3 chairs, 126.7ms\n",
            "Speed: 3.1ms preprocess, 126.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1107.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1116.jpg: 384x640 13 persons, 4 chairs, 210.0ms\n",
            "Speed: 5.1ms preprocess, 210.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1116.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1124.jpg: 384x640 12 persons, 215.6ms\n",
            "Speed: 4.8ms preprocess, 215.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1124.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1128.jpg: 384x640 13 persons, 1 chair, 154.7ms\n",
            "Speed: 3.4ms preprocess, 154.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1128.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1133.jpg: 384x640 11 persons, 3 chairs, 136.9ms\n",
            "Speed: 4.3ms preprocess, 136.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1133.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1139.jpg: 384x640 12 persons, 2 chairs, 125.9ms\n",
            "Speed: 3.0ms preprocess, 125.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1139.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1145.jpg: 384x640 10 persons, 3 chairs, 140.0ms\n",
            "Speed: 3.3ms preprocess, 140.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1145.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1146.jpg: 384x640 12 persons, 3 chairs, 132.7ms\n",
            "Speed: 3.3ms preprocess, 132.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1146.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1147.jpg: 384x640 12 persons, 1 chair, 125.7ms\n",
            "Speed: 2.9ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1147.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1153.jpg: 384x640 13 persons, 2 chairs, 214.0ms\n",
            "Speed: 5.1ms preprocess, 214.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1153.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1159.jpg: 384x640 11 persons, 4 chairs, 211.2ms\n",
            "Speed: 4.8ms preprocess, 211.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1159.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1160.jpg: 384x640 10 persons, 1 chair, 129.9ms\n",
            "Speed: 3.0ms preprocess, 129.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1160.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1161.jpg: 384x640 12 persons, 1 chair, 127.8ms\n",
            "Speed: 3.0ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1161.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1162.jpg: 384x640 12 persons, 3 chairs, 1 laptop, 1 book, 145.8ms\n",
            "Speed: 5.8ms preprocess, 145.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1162.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1163.jpg: 384x640 11 persons, 1 chair, 1 laptop, 1 book, 139.5ms\n",
            "Speed: 3.6ms preprocess, 139.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1163.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1167.jpg: 384x640 9 persons, 1 chair, 2 remotes, 154.2ms\n",
            "Speed: 3.4ms preprocess, 154.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1167.jpg: 8 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1173.jpg: 384x640 12 persons, 2 chairs, 142.8ms\n",
            "Speed: 3.7ms preprocess, 142.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1173.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1174.jpg: 384x640 12 persons, 1 chair, 211.1ms\n",
            "Speed: 5.9ms preprocess, 211.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1174.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1181.jpg: 384x640 11 persons, 1 handbag, 2 chairs, 232.0ms\n",
            "Speed: 7.0ms preprocess, 232.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1181.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1182.jpg: 384x640 10 persons, 1 chair, 144.9ms\n",
            "Speed: 3.6ms preprocess, 144.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1182.jpg: 10 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1183.jpg: 384x640 11 persons, 3 chairs, 163.8ms\n",
            "Speed: 3.5ms preprocess, 163.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1183.jpg: 11 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1184.jpg: 384x640 10 persons, 1 chair, 129.1ms\n",
            "Speed: 3.1ms preprocess, 129.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1184.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1188.jpg: 384x640 11 persons, 1 wine glass, 2 chairs, 128.8ms\n",
            "Speed: 3.1ms preprocess, 128.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1188.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1191.jpg: 384x640 13 persons, 2 chairs, 135.5ms\n",
            "Speed: 2.8ms preprocess, 135.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1191.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1193.jpg: 384x640 11 persons, 2 chairs, 163.8ms\n",
            "Speed: 3.6ms preprocess, 163.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1193.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1197.jpg: 384x640 12 persons, 3 chairs, 219.7ms\n",
            "Speed: 4.9ms preprocess, 219.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1197.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1207.jpg: 384x640 12 persons, 3 chairs, 2 remotes, 229.7ms\n",
            "Speed: 5.0ms preprocess, 229.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1207.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1210.jpg: 384x640 13 persons, 1 cup, 3 chairs, 144.7ms\n",
            "Speed: 3.3ms preprocess, 144.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1210.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1218.jpg: 384x640 10 persons, 3 chairs, 140.7ms\n",
            "Speed: 3.4ms preprocess, 140.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1218.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1229.jpg: 384x640 13 persons, 1 bench, 2 chairs, 128.4ms\n",
            "Speed: 3.0ms preprocess, 128.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1229.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1236.jpg: 384x640 10 persons, 2 chairs, 131.5ms\n",
            "Speed: 2.9ms preprocess, 131.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1236.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1243.jpg: 384x640 10 persons, 1 chair, 132.8ms\n",
            "Speed: 2.9ms preprocess, 132.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1243.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1244.jpg: 384x640 12 persons, 3 chairs, 139.1ms\n",
            "Speed: 3.4ms preprocess, 139.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1244.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1247.jpg: 384x640 10 persons, 2 chairs, 200.4ms\n",
            "Speed: 4.5ms preprocess, 200.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1247.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1253.jpg: 384x640 11 persons, 1 chair, 193.2ms\n",
            "Speed: 4.4ms preprocess, 193.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1253.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1255.jpg: 384x640 13 persons, 3 chairs, 1 remote, 136.3ms\n",
            "Speed: 3.2ms preprocess, 136.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1255.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1260.jpg: 384x640 13 persons, 4 chairs, 1 remote, 142.0ms\n",
            "Speed: 2.9ms preprocess, 142.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1260.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1262.jpg: 384x640 11 persons, 1 chair, 1 remote, 131.4ms\n",
            "Speed: 3.0ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1262.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1266.jpg: 384x640 11 persons, 142.3ms\n",
            "Speed: 3.4ms preprocess, 142.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1266.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1267.jpg: 384x640 14 persons, 2 chairs, 1 remote, 131.5ms\n",
            "Speed: 3.1ms preprocess, 131.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1267.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1272.jpg: 384x640 12 persons, 1 chair, 141.6ms\n",
            "Speed: 3.4ms preprocess, 141.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1272.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1277.jpg: 384x640 11 persons, 2 chairs, 211.2ms\n",
            "Speed: 5.2ms preprocess, 211.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1277.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1279.jpg: 384x640 12 persons, 1 chair, 229.4ms\n",
            "Speed: 6.0ms preprocess, 229.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1279.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1288.jpg: 384x640 14 persons, 1 chair, 131.3ms\n",
            "Speed: 2.9ms preprocess, 131.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1288.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1290.jpg: 384x640 13 persons, 153.2ms\n",
            "Speed: 3.0ms preprocess, 153.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1290.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1300.jpg: 384x640 12 persons, 4 chairs, 138.5ms\n",
            "Speed: 5.2ms preprocess, 138.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1300.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1304.jpg: 384x640 12 persons, 3 chairs, 136.8ms\n",
            "Speed: 3.3ms preprocess, 136.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1304.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1305.jpg: 384x640 13 persons, 2 chairs, 127.7ms\n",
            "Speed: 4.0ms preprocess, 127.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1305.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1310.jpg: 384x640 10 persons, 4 chairs, 136.6ms\n",
            "Speed: 3.4ms preprocess, 136.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1310.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1311.jpg: 384x640 9 persons, 2 chairs, 220.7ms\n",
            "Speed: 5.0ms preprocess, 220.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1311.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1313.jpg: 384x640 10 persons, 229.5ms\n",
            "Speed: 5.6ms preprocess, 229.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1313.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1314.jpg: 384x640 11 persons, 136.1ms\n",
            "Speed: 3.7ms preprocess, 136.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1314.jpg: 10 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1318.jpg: 384x640 12 persons, 140.1ms\n",
            "Speed: 5.7ms preprocess, 140.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1318.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1326.jpg: 384x640 13 persons, 6 chairs, 159.0ms\n",
            "Speed: 3.8ms preprocess, 159.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1326.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1330.jpg: 384x640 10 persons, 10 chairs, 143.4ms\n",
            "Speed: 3.4ms preprocess, 143.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1330.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1335.jpg: 384x640 11 persons, 8 chairs, 144.2ms\n",
            "Speed: 3.4ms preprocess, 144.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1335.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1346.jpg: 384x640 11 persons, 5 chairs, 142.5ms\n",
            "Speed: 3.5ms preprocess, 142.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1346.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1348.jpg: 384x640 10 persons, 5 chairs, 223.9ms\n",
            "Speed: 5.1ms preprocess, 223.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1348.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1356.jpg: 384x640 11 persons, 5 chairs, 208.8ms\n",
            "Speed: 5.1ms preprocess, 208.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1356.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1359.jpg: 384x640 11 persons, 7 chairs, 158.6ms\n",
            "Speed: 3.4ms preprocess, 158.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1359.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1360.jpg: 384x640 11 persons, 10 chairs, 143.4ms\n",
            "Speed: 2.9ms preprocess, 143.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1360.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1365.jpg: 384x640 12 persons, 10 chairs, 132.1ms\n",
            "Speed: 2.9ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1365.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1367.jpg: 384x640 12 persons, 4 chairs, 142.6ms\n",
            "Speed: 3.0ms preprocess, 142.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1367.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1371.jpg: 384x640 11 persons, 8 chairs, 131.1ms\n",
            "Speed: 3.2ms preprocess, 131.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1371.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1374.jpg: 384x640 11 persons, 6 chairs, 147.3ms\n",
            "Speed: 5.0ms preprocess, 147.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1374.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1381.jpg: 384x640 11 persons, 9 chairs, 204.4ms\n",
            "Speed: 4.9ms preprocess, 204.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1381.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1382.jpg: 384x640 12 persons, 9 chairs, 1 book, 219.1ms\n",
            "Speed: 4.9ms preprocess, 219.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1382.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1384.jpg: 384x640 12 persons, 7 chairs, 2 books, 140.7ms\n",
            "Speed: 3.4ms preprocess, 140.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1384.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1409.jpg: 384x640 12 persons, 1 backpack, 9 chairs, 1 book, 130.4ms\n",
            "Speed: 3.3ms preprocess, 130.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1409.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1419.jpg: 384x640 11 persons, 1 backpack, 1 tie, 9 chairs, 128.5ms\n",
            "Speed: 2.9ms preprocess, 128.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1419.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1424.jpg: 384x640 12 persons, 1 backpack, 1 tie, 10 chairs, 137.5ms\n",
            "Speed: 3.3ms preprocess, 137.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1424.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1432.jpg: 384x640 12 persons, 1 backpack, 9 chairs, 138.8ms\n",
            "Speed: 3.4ms preprocess, 138.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1432.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1433.jpg: 384x640 13 persons, 1 backpack, 8 chairs, 137.8ms\n",
            "Speed: 3.2ms preprocess, 137.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1433.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1436.jpg: 384x640 12 persons, 8 chairs, 228.9ms\n",
            "Speed: 5.0ms preprocess, 228.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1436.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1455.jpg: 384x640 13 persons, 1 cup, 1 chair, 216.0ms\n",
            "Speed: 5.0ms preprocess, 216.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1455.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1460.jpg: 384x640 12 persons, 3 chairs, 1 bed, 3 books, 154.6ms\n",
            "Speed: 3.2ms preprocess, 154.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1460.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1462.jpg: 384x640 9 persons, 2 chairs, 3 books, 150.8ms\n",
            "Speed: 3.0ms preprocess, 150.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1462.jpg: 7 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1474.jpg: 384x640 17 persons, 4 chairs, 127.3ms\n",
            "Speed: 2.9ms preprocess, 127.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1474.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1475.jpg: 384x640 17 persons, 4 chairs, 134.5ms\n",
            "Speed: 3.0ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1475.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1477.jpg: 384x640 16 persons, 1 suitcase, 4 chairs, 144.1ms\n",
            "Speed: 2.9ms preprocess, 144.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1477.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1479.jpg: 384x640 17 persons, 5 chairs, 196.4ms\n",
            "Speed: 4.5ms preprocess, 196.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1479.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1480.jpg: 384x640 17 persons, 1 suitcase, 5 chairs, 241.9ms\n",
            "Speed: 5.3ms preprocess, 241.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1480.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1481.jpg: 384x640 23 persons, 1 suitcase, 4 chairs, 131.8ms\n",
            "Speed: 3.1ms preprocess, 131.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1481.jpg: 23 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1482.jpg: 384x640 18 persons, 1 suitcase, 4 chairs, 135.9ms\n",
            "Speed: 3.4ms preprocess, 135.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1482.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1489.jpg: 384x640 15 persons, 3 chairs, 144.0ms\n",
            "Speed: 3.4ms preprocess, 144.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1489.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1504.jpg: 384x640 12 persons, 4 chairs, 132.0ms\n",
            "Speed: 3.1ms preprocess, 132.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1504.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1512.jpg: 384x640 13 persons, 1 suitcase, 4 chairs, 231.6ms\n",
            "Speed: 5.2ms preprocess, 231.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1512.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1515.jpg: 384x640 14 persons, 1 suitcase, 6 chairs, 200.8ms\n",
            "Speed: 4.7ms preprocess, 200.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1515.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1525.jpg: 384x640 14 persons, 1 handbag, 8 chairs, 135.0ms\n",
            "Speed: 2.9ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1525.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1528.jpg: 384x640 14 persons, 1 suitcase, 5 chairs, 155.5ms\n",
            "Speed: 5.0ms preprocess, 155.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1528.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1531.jpg: 384x640 16 persons, 1 suitcase, 7 chairs, 158.7ms\n",
            "Speed: 3.1ms preprocess, 158.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1531.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1532.jpg: 384x640 15 persons, 1 suitcase, 5 chairs, 145.5ms\n",
            "Speed: 3.0ms preprocess, 145.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1532.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1534.jpg: 384x640 12 persons, 1 backpack, 1 suitcase, 7 chairs, 135.2ms\n",
            "Speed: 2.8ms preprocess, 135.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1534.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1537.jpg: 384x640 13 persons, 4 chairs, 217.7ms\n",
            "Speed: 5.1ms preprocess, 217.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1537.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1541.jpg: 384x640 15 persons, 1 backpack, 5 chairs, 132.3ms\n",
            "Speed: 3.4ms preprocess, 132.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1541.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1544.jpg: 384x640 10 persons, 1 backpack, 1 suitcase, 7 chairs, 127.3ms\n",
            "Speed: 2.9ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1544.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1548.jpg: 384x640 18 persons, 1 backpack, 1 suitcase, 6 chairs, 156.3ms\n",
            "Speed: 5.1ms preprocess, 156.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1548.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1549.jpg: 384x640 17 persons, 8 chairs, 1 book, 140.6ms\n",
            "Speed: 3.4ms preprocess, 140.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1549.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1551.jpg: 384x640 18 persons, 1 backpack, 2 suitcases, 7 chairs, 138.6ms\n",
            "Speed: 3.8ms preprocess, 138.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1551.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1553.jpg: 384x640 17 persons, 1 backpack, 7 chairs, 269.8ms\n",
            "Speed: 5.1ms preprocess, 269.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1553.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1555.jpg: 384x640 17 persons, 1 backpack, 5 chairs, 139.6ms\n",
            "Speed: 3.4ms preprocess, 139.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1555.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1558.jpg: 384x640 17 persons, 1 backpack, 1 suitcase, 6 chairs, 127.1ms\n",
            "Speed: 3.2ms preprocess, 127.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1558.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1578.jpg: 384x640 19 persons, 7 chairs, 137.9ms\n",
            "Speed: 2.9ms preprocess, 137.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1578.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1580.jpg: 384x640 16 persons, 1 handbag, 1 suitcase, 1 chair, 168.1ms\n",
            "Speed: 3.8ms preprocess, 168.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1580.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1582.jpg: 384x640 18 persons, 1 handbag, 1 suitcase, 4 chairs, 129.5ms\n",
            "Speed: 2.9ms preprocess, 129.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1582.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1583.jpg: 384x640 20 persons, 1 handbag, 1 suitcase, 5 chairs, 213.8ms\n",
            "Speed: 5.2ms preprocess, 213.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1583.jpg: 20 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1584.jpg: 384x640 15 persons, 2 suitcases, 5 chairs, 135.7ms\n",
            "Speed: 3.3ms preprocess, 135.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1584.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1586.jpg: 384x640 18 persons, 1 handbag, 1 suitcase, 8 chairs, 131.1ms\n",
            "Speed: 3.1ms preprocess, 131.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1586.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1587.jpg: 384x640 18 persons, 1 handbag, 1 suitcase, 6 chairs, 140.8ms\n",
            "Speed: 3.4ms preprocess, 140.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1587.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1601.jpg: 384x640 18 persons, 1 suitcase, 6 chairs, 132.3ms\n",
            "Speed: 3.1ms preprocess, 132.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1601.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1610.jpg: 384x640 18 persons, 1 suitcase, 6 chairs, 206.0ms\n",
            "Speed: 4.4ms preprocess, 206.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1610.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1614.jpg: 384x640 18 persons, 8 chairs, 134.5ms\n",
            "Speed: 3.2ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1614.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1621.jpg: 384x640 18 persons, 1 suitcase, 4 chairs, 146.4ms\n",
            "Speed: 3.6ms preprocess, 146.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1621.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1627.jpg: 384x640 18 persons, 6 chairs, 140.5ms\n",
            "Speed: 3.3ms preprocess, 140.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1627.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1628.jpg: 384x640 17 persons, 8 chairs, 150.9ms\n",
            "Speed: 3.4ms preprocess, 150.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1628.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1645.jpg: 384x640 17 persons, 1 suitcase, 10 chairs, 1 book, 210.0ms\n",
            "Speed: 4.5ms preprocess, 210.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1645.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1651.jpg: 384x640 17 persons, 1 handbag, 1 suitcase, 5 chairs, 200.3ms\n",
            "Speed: 4.5ms preprocess, 200.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1651.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1655.jpg: 384x640 16 persons, 1 suitcase, 5 chairs, 129.6ms\n",
            "Speed: 3.0ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1655.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1657.jpg: 384x640 19 persons, 1 suitcase, 9 chairs, 127.2ms\n",
            "Speed: 3.0ms preprocess, 127.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1657.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1658.jpg: 384x640 21 persons, 1 suitcase, 9 chairs, 140.6ms\n",
            "Speed: 4.0ms preprocess, 140.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1658.jpg: 21 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1663.jpg: 384x640 17 persons, 1 suitcase, 5 chairs, 133.6ms\n",
            "Speed: 3.6ms preprocess, 133.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1663.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1673.jpg: 384x640 13 persons, 11 chairs, 1 laptop, 221.6ms\n",
            "Speed: 5.1ms preprocess, 221.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1673.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1675.jpg: 384x640 13 persons, 1 bench, 12 chairs, 1 laptop, 160.5ms\n",
            "Speed: 3.6ms preprocess, 160.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1675.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1682.jpg: 384x640 14 persons, 11 chairs, 129.6ms\n",
            "Speed: 3.2ms preprocess, 129.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1682.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1686.jpg: 384x640 15 persons, 8 chairs, 138.7ms\n",
            "Speed: 3.3ms preprocess, 138.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1686.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1687.jpg: 384x640 17 persons, 13 chairs, 128.6ms\n",
            "Speed: 2.8ms preprocess, 128.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1687.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1688.jpg: 384x640 15 persons, 11 chairs, 127.6ms\n",
            "Speed: 3.0ms preprocess, 127.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1688.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1691.jpg: 384x640 15 persons, 14 chairs, 1 laptop, 236.1ms\n",
            "Speed: 6.7ms preprocess, 236.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1691.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1707.jpg: 384x640 15 persons, 13 chairs, 1 laptop, 229.4ms\n",
            "Speed: 5.5ms preprocess, 229.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1707.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1720.jpg: 384x640 14 persons, 11 chairs, 1 laptop, 146.8ms\n",
            "Speed: 3.1ms preprocess, 146.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1720.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1727.jpg: 384x640 12 persons, 17 chairs, 1 dining table, 136.4ms\n",
            "Speed: 3.4ms preprocess, 136.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1727.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1736.jpg: 384x640 11 persons, 11 chairs, 1 dining table, 1 laptop, 137.5ms\n",
            "Speed: 3.4ms preprocess, 137.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1736.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1738.jpg: 384x640 12 persons, 1 bench, 15 chairs, 1 laptop, 128.3ms\n",
            "Speed: 3.0ms preprocess, 128.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1738.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1746.jpg: 384x640 10 persons, 1 bench, 13 chairs, 128.0ms\n",
            "Speed: 3.0ms preprocess, 128.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1746.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1758.jpg: 384x640 14 persons, 15 chairs, 130.5ms\n",
            "Speed: 3.0ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1758.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1768.jpg: 384x640 13 persons, 15 chairs, 1 laptop, 237.3ms\n",
            "Speed: 5.2ms preprocess, 237.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1768.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1769.jpg: 384x640 13 persons, 12 chairs, 1 laptop, 138.4ms\n",
            "Speed: 3.5ms preprocess, 138.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1769.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1776.jpg: 384x640 13 persons, 13 chairs, 1 laptop, 161.7ms\n",
            "Speed: 3.7ms preprocess, 161.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1776.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1785.jpg: 384x640 13 persons, 10 chairs, 2 laptops, 136.6ms\n",
            "Speed: 3.8ms preprocess, 136.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1785.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1787.jpg: 384x640 13 persons, 12 chairs, 1 laptop, 130.3ms\n",
            "Speed: 2.9ms preprocess, 130.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1787.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1790.jpg: 384x640 13 persons, 12 chairs, 1 laptop, 142.7ms\n",
            "Speed: 2.9ms preprocess, 142.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1790.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1800.jpg: 384x640 12 persons, 10 chairs, 2 laptops, 128.7ms\n",
            "Speed: 3.0ms preprocess, 128.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1800.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1808.jpg: 384x640 13 persons, 8 chairs, 2 laptops, 243.4ms\n",
            "Speed: 5.1ms preprocess, 243.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1808.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1809.jpg: 384x640 12 persons, 11 chairs, 2 laptops, 152.1ms\n",
            "Speed: 5.1ms preprocess, 152.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1809.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1820.jpg: 384x640 16 persons, 5 chairs, 139.2ms\n",
            "Speed: 3.0ms preprocess, 139.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1820.jpg: 14 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1825.jpg: 384x640 18 persons, 5 chairs, 1 book, 159.2ms\n",
            "Speed: 6.5ms preprocess, 159.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1825.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1832.jpg: 384x640 14 persons, 6 chairs, 135.3ms\n",
            "Speed: 3.1ms preprocess, 135.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1832.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1843.jpg: 384x640 18 persons, 5 chairs, 138.2ms\n",
            "Speed: 3.5ms preprocess, 138.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1843.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1854.jpg: 384x640 19 persons, 5 chairs, 208.7ms\n",
            "Speed: 5.2ms preprocess, 208.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1854.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1861.jpg: 384x640 17 persons, 6 chairs, 2 books, 223.1ms\n",
            "Speed: 6.1ms preprocess, 223.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1861.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1868.jpg: 384x640 18 persons, 1 backpack, 6 chairs, 1 book, 130.8ms\n",
            "Speed: 2.9ms preprocess, 130.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1868.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1870.jpg: 384x640 17 persons, 1 backpack, 7 chairs, 1 book, 140.3ms\n",
            "Speed: 3.3ms preprocess, 140.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1870.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1876.jpg: 384x640 15 persons, 6 chairs, 1 laptop, 156.2ms\n",
            "Speed: 3.5ms preprocess, 156.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1876.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1877.jpg: 384x640 17 persons, 4 chairs, 1 book, 128.2ms\n",
            "Speed: 2.9ms preprocess, 128.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1877.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1885.jpg: 384x640 15 persons, 5 chairs, 1 laptop, 224.1ms\n",
            "Speed: 5.1ms preprocess, 224.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1885.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1902.jpg: 384x640 15 persons, 6 chairs, 1 laptop, 221.0ms\n",
            "Speed: 5.0ms preprocess, 221.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1902.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1910.jpg: 384x640 16 persons, 3 chairs, 1 laptop, 1 book, 132.1ms\n",
            "Speed: 3.1ms preprocess, 132.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1910.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1911.jpg: 384x640 16 persons, 5 chairs, 144.0ms\n",
            "Speed: 3.3ms preprocess, 144.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1911.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1919.jpg: 384x640 17 persons, 3 chairs, 1 laptop, 1 book, 128.9ms\n",
            "Speed: 2.9ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1919.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1921.jpg: 384x640 16 persons, 1 frisbee, 2 chairs, 1 laptop, 129.5ms\n",
            "Speed: 3.0ms preprocess, 129.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1921.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1924.jpg: 384x640 17 persons, 2 chairs, 1 laptop, 214.4ms\n",
            "Speed: 4.5ms preprocess, 214.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1924.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1926.jpg: 384x640 20 persons, 5 chairs, 238.1ms\n",
            "Speed: 5.0ms preprocess, 238.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1926.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1934.jpg: 384x640 17 persons, 3 chairs, 1 laptop, 129.2ms\n",
            "Speed: 3.1ms preprocess, 129.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1934.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1941.jpg: 384x640 18 persons, 2 chairs, 1 laptop, 1 book, 132.8ms\n",
            "Speed: 2.8ms preprocess, 132.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1941.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1948.jpg: 384x640 19 persons, 2 chairs, 1 laptop, 132.9ms\n",
            "Speed: 3.1ms preprocess, 132.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1948.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1951.jpg: 384x640 19 persons, 2 chairs, 1 laptop, 155.5ms\n",
            "Speed: 3.5ms preprocess, 155.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1951.jpg: 19 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1962.jpg: 384x640 19 persons, 2 chairs, 222.7ms\n",
            "Speed: 5.1ms preprocess, 222.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1962.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1968.jpg: 384x640 17 persons, 2 chairs, 1 laptop, 152.6ms\n",
            "Speed: 3.3ms preprocess, 152.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1968.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1973.jpg: 384x640 17 persons, 3 chairs, 136.2ms\n",
            "Speed: 3.1ms preprocess, 136.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1973.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1975.jpg: 384x640 14 persons, 3 chairs, 160.1ms\n",
            "Speed: 3.3ms preprocess, 160.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1975.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1980.jpg: 384x640 16 persons, 1 backpack, 1 handbag, 2 chairs, 140.4ms\n",
            "Speed: 3.4ms preprocess, 140.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1980.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1982.jpg: 384x640 18 persons, 1 chair, 1 laptop, 130.3ms\n",
            "Speed: 3.0ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1982.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1983.jpg: 384x640 16 persons, 1 chair, 224.7ms\n",
            "Speed: 5.5ms preprocess, 224.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1983.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1991.jpg: 384x640 16 persons, 3 chairs, 1 laptop, 144.0ms\n",
            "Speed: 3.5ms preprocess, 144.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1991.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2000.jpg: 384x640 18 persons, 1 chair, 141.4ms\n",
            "Speed: 3.4ms preprocess, 141.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2000.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2002.jpg: 384x640 17 persons, 1 chair, 141.7ms\n",
            "Speed: 3.4ms preprocess, 141.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2002.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2012.jpg: 384x640 17 persons, 3 chairs, 128.8ms\n",
            "Speed: 3.1ms preprocess, 128.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2012.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2017.jpg: 384x640 17 persons, 1 handbag, 4 chairs, 1 laptop, 127.3ms\n",
            "Speed: 2.8ms preprocess, 127.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2017.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2020.jpg: 384x640 18 persons, 1 handbag, 4 chairs, 1 laptop, 203.5ms\n",
            "Speed: 5.1ms preprocess, 203.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2020.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2029.jpg: 384x640 15 persons, 1 bench, 1 handbag, 2 chairs, 143.1ms\n",
            "Speed: 4.9ms preprocess, 143.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2029.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2038.jpg: 384x640 16 persons, 1 bench, 3 chairs, 1 laptop, 145.7ms\n",
            "Speed: 5.0ms preprocess, 145.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2038.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2040.jpg: 384x640 12 persons, 7 chairs, 135.3ms\n",
            "Speed: 3.2ms preprocess, 135.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2040.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/2039.jpg: 384x640 10 persons, 8 chairs, 137.0ms\n",
            "Speed: 2.9ms preprocess, 137.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "2039.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/43.jpg: 384x640 11 persons, 7 chairs, 146.7ms\n",
            "Speed: 4.2ms preprocess, 146.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "43.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/53.jpg: 384x640 9 persons, 8 chairs, 132.1ms\n",
            "Speed: 2.8ms preprocess, 132.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "53.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/65.jpg: 384x640 14 persons, 9 chairs, 200.2ms\n",
            "Speed: 4.5ms preprocess, 200.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "65.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/68.jpg: 384x640 10 persons, 6 chairs, 239.4ms\n",
            "Speed: 5.0ms preprocess, 239.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "68.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/72.jpg: 384x640 14 persons, 10 chairs, 139.1ms\n",
            "Speed: 3.5ms preprocess, 139.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "72.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/78.jpg: 384x640 12 persons, 7 chairs, 142.5ms\n",
            "Speed: 3.5ms preprocess, 142.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "78.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/79.jpg: 384x640 13 persons, 6 chairs, 135.2ms\n",
            "Speed: 2.8ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "79.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/82.jpg: 384x640 10 persons, 9 chairs, 155.0ms\n",
            "Speed: 5.0ms preprocess, 155.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "82.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/83.jpg: 384x640 11 persons, 7 chairs, 127.6ms\n",
            "Speed: 4.7ms preprocess, 127.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "83.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/86.jpg: 384x640 11 persons, 8 chairs, 143.6ms\n",
            "Speed: 3.4ms preprocess, 143.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "86.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/95.jpg: 384x640 11 persons, 10 chairs, 224.8ms\n",
            "Speed: 5.0ms preprocess, 224.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "95.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/102.jpg: 384x640 13 persons, 7 chairs, 239.1ms\n",
            "Speed: 5.4ms preprocess, 239.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "102.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/113.jpg: 384x640 13 persons, 7 chairs, 2 books, 141.3ms\n",
            "Speed: 3.3ms preprocess, 141.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "113.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/123.jpg: 384x640 13 persons, 7 chairs, 141.2ms\n",
            "Speed: 3.4ms preprocess, 141.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "123.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/126.jpg: 384x640 12 persons, 7 chairs, 1 book, 141.0ms\n",
            "Speed: 3.3ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "126.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/129.jpg: 384x640 10 persons, 6 chairs, 1 book, 161.0ms\n",
            "Speed: 3.4ms preprocess, 161.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "129.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/130.jpg: 384x640 10 persons, 8 chairs, 2 books, 127.6ms\n",
            "Speed: 3.0ms preprocess, 127.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "130.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/133.jpg: 384x640 11 persons, 8 chairs, 1 book, 135.4ms\n",
            "Speed: 2.9ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "133.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/142.jpg: 384x640 12 persons, 6 chairs, 1 book, 238.2ms\n",
            "Speed: 5.1ms preprocess, 238.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "142.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/144.jpg: 384x640 12 persons, 10 chairs, 227.2ms\n",
            "Speed: 4.8ms preprocess, 227.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "144.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/146.jpg: 384x640 12 persons, 10 chairs, 135.6ms\n",
            "Speed: 3.1ms preprocess, 135.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "146.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/147.jpg: 384x640 10 persons, 6 chairs, 144.4ms\n",
            "Speed: 3.4ms preprocess, 144.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "147.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/150.jpg: 384x640 9 persons, 10 chairs, 139.8ms\n",
            "Speed: 3.4ms preprocess, 139.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "150.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/153.jpg: 384x640 11 persons, 9 chairs, 152.5ms\n",
            "Speed: 2.9ms preprocess, 152.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "153.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/155.jpg: 384x640 12 persons, 7 chairs, 138.7ms\n",
            "Speed: 3.4ms preprocess, 138.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "155.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/160.jpg: 384x640 10 persons, 7 chairs, 1 book, 129.7ms\n",
            "Speed: 3.0ms preprocess, 129.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "160.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/168.jpg: 384x640 11 persons, 9 chairs, 223.5ms\n",
            "Speed: 5.5ms preprocess, 223.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "168.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/170.jpg: 384x640 11 persons, 10 chairs, 210.8ms\n",
            "Speed: 4.5ms preprocess, 210.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "170.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/172.jpg: 384x640 10 persons, 9 chairs, 140.5ms\n",
            "Speed: 3.2ms preprocess, 140.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "172.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/174.jpg: 384x640 11 persons, 5 chairs, 156.5ms\n",
            "Speed: 3.3ms preprocess, 156.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "174.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/176.jpg: 384x640 15 persons, 5 chairs, 131.4ms\n",
            "Speed: 2.8ms preprocess, 131.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "176.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/177.jpg: 384x640 12 persons, 6 chairs, 141.2ms\n",
            "Speed: 3.4ms preprocess, 141.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "177.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/178.jpg: 384x640 12 persons, 4 chairs, 1 book, 157.7ms\n",
            "Speed: 3.2ms preprocess, 157.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "178.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/181.jpg: 384x640 10 persons, 4 chairs, 1 book, 145.5ms\n",
            "Speed: 3.2ms preprocess, 145.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "181.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/189.jpg: 384x640 12 persons, 6 chairs, 189.1ms\n",
            "Speed: 3.3ms preprocess, 189.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "189.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/191.jpg: 384x640 11 persons, 5 chairs, 204.2ms\n",
            "Speed: 4.5ms preprocess, 204.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "191.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/196.jpg: 384x640 10 persons, 5 chairs, 136.7ms\n",
            "Speed: 3.6ms preprocess, 136.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "196.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/200.jpg: 384x640 11 persons, 6 chairs, 135.8ms\n",
            "Speed: 2.9ms preprocess, 135.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "200.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/209.jpg: 384x640 10 persons, 7 chairs, 151.2ms\n",
            "Speed: 3.0ms preprocess, 151.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "209.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/212.jpg: 384x640 12 persons, 5 chairs, 143.8ms\n",
            "Speed: 3.3ms preprocess, 143.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "212.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/223.jpg: 384x640 16 persons, 5 chairs, 2 tvs, 11 laptops, 145.8ms\n",
            "Speed: 2.9ms preprocess, 145.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "223.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/228.jpg: 384x640 19 persons, 5 chairs, 1 tv, 11 laptops, 141.9ms\n",
            "Speed: 3.0ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "228.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/229.jpg: 384x640 16 persons, 7 chairs, 2 tvs, 11 laptops, 130.3ms\n",
            "Speed: 2.8ms preprocess, 130.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "229.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/235.jpg: 384x640 17 persons, 4 chairs, 11 laptops, 211.4ms\n",
            "Speed: 4.9ms preprocess, 211.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "235.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/238.jpg: 384x640 18 persons, 4 chairs, 10 laptops, 144.8ms\n",
            "Speed: 3.3ms preprocess, 144.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "238.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/239.jpg: 384x640 15 persons, 5 chairs, 12 laptops, 142.9ms\n",
            "Speed: 4.0ms preprocess, 142.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "239.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/240.jpg: 384x640 17 persons, 5 chairs, 12 laptops, 156.4ms\n",
            "Speed: 3.3ms preprocess, 156.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "240.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/247.jpg: 384x640 19 persons, 5 chairs, 12 laptops, 127.8ms\n",
            "Speed: 3.0ms preprocess, 127.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "247.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/248.jpg: 384x640 19 persons, 6 chairs, 1 tv, 12 laptops, 131.7ms\n",
            "Speed: 3.0ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "248.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/260.jpg: 384x640 17 persons, 6 chairs, 1 tv, 13 laptops, 234.6ms\n",
            "Speed: 5.1ms preprocess, 234.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "260.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/261.jpg: 384x640 17 persons, 6 chairs, 15 laptops, 231.0ms\n",
            "Speed: 4.9ms preprocess, 231.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "261.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/263.jpg: 384x640 16 persons, 3 chairs, 13 laptops, 134.4ms\n",
            "Speed: 3.2ms preprocess, 134.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "263.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/264.jpg: 384x640 16 persons, 5 chairs, 13 laptops, 134.4ms\n",
            "Speed: 3.3ms preprocess, 134.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "264.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/269.jpg: 384x640 16 persons, 5 chairs, 2 tvs, 15 laptops, 134.3ms\n",
            "Speed: 3.7ms preprocess, 134.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "269.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/281.jpg: 384x640 20 persons, 2 chairs, 14 laptops, 130.8ms\n",
            "Speed: 2.8ms preprocess, 130.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "281.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/285.jpg: 384x640 21 persons, 6 chairs, 1 tv, 10 laptops, 144.4ms\n",
            "Speed: 3.7ms preprocess, 144.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "285.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/295.jpg: 384x640 18 persons, 6 chairs, 1 tv, 10 laptops, 224.9ms\n",
            "Speed: 5.3ms preprocess, 224.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "295.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/311.jpg: 384x640 16 persons, 4 chairs, 12 laptops, 144.3ms\n",
            "Speed: 3.7ms preprocess, 144.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "311.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/314.jpg: 384x640 15 persons, 5 chairs, 8 laptops, 129.4ms\n",
            "Speed: 3.3ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "314.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/315.jpg: 384x640 18 persons, 4 chairs, 2 tvs, 13 laptops, 132.8ms\n",
            "Speed: 3.1ms preprocess, 132.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "315.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/323.jpg: 384x640 19 persons, 5 chairs, 1 tv, 13 laptops, 144.6ms\n",
            "Speed: 3.3ms preprocess, 144.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "323.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/328.jpg: 384x640 19 persons, 4 chairs, 12 laptops, 143.8ms\n",
            "Speed: 5.2ms preprocess, 143.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "328.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/335.jpg: 384x640 18 persons, 8 chairs, 11 laptops, 129.5ms\n",
            "Speed: 3.0ms preprocess, 129.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "335.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/341.jpg: 384x640 19 persons, 7 chairs, 1 dining table, 1 tv, 9 laptops, 222.4ms\n",
            "Speed: 4.7ms preprocess, 222.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "341.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/342.jpg: 384x640 19 persons, 5 chairs, 10 laptops, 152.5ms\n",
            "Speed: 3.5ms preprocess, 152.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "342.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/347.jpg: 384x640 21 persons, 5 chairs, 8 laptops, 140.1ms\n",
            "Speed: 3.3ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "347.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/351.jpg: 384x640 18 persons, 3 chairs, 11 laptops, 163.9ms\n",
            "Speed: 3.4ms preprocess, 163.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "351.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/355.jpg: 384x640 21 persons, 2 chairs, 1 tv, 11 laptops, 138.8ms\n",
            "Speed: 3.3ms preprocess, 138.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "355.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/359.jpg: 384x640 18 persons, 3 chairs, 1 tv, 10 laptops, 144.1ms\n",
            "Speed: 3.6ms preprocess, 144.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "359.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/364.jpg: 384x640 18 persons, 2 chairs, 2 tvs, 8 laptops, 1 cell phone, 225.7ms\n",
            "Speed: 4.8ms preprocess, 225.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "364.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/366.jpg: 384x640 15 persons, 2 chairs, 1 tv, 9 laptops, 1 mouse, 1 cell phone, 219.8ms\n",
            "Speed: 5.6ms preprocess, 219.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "366.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/378.jpg: 384x640 19 persons, 3 chairs, 10 laptops, 1 cell phone, 146.8ms\n",
            "Speed: 3.3ms preprocess, 146.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "378.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/381.jpg: 384x640 17 persons, 4 chairs, 1 tv, 9 laptops, 1 cell phone, 143.3ms\n",
            "Speed: 3.7ms preprocess, 143.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "381.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/382.jpg: 384x640 16 persons, 5 chairs, 2 tvs, 8 laptops, 1 cell phone, 132.1ms\n",
            "Speed: 3.0ms preprocess, 132.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "382.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/385.jpg: 384x640 16 persons, 4 chairs, 1 tv, 8 laptops, 1 cell phone, 141.7ms\n",
            "Speed: 3.4ms preprocess, 141.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "385.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/389.jpg: 384x640 17 persons, 4 chairs, 9 laptops, 1 cell phone, 209.5ms\n",
            "Speed: 4.6ms preprocess, 209.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "389.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/392.jpg: 384x640 18 persons, 5 chairs, 8 laptops, 1 cell phone, 207.3ms\n",
            "Speed: 4.5ms preprocess, 207.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "392.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/394.jpg: 384x640 18 persons, 6 chairs, 6 laptops, 1 cell phone, 131.8ms\n",
            "Speed: 3.2ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "394.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/398.jpg: 384x640 20 persons, 5 chairs, 2 tvs, 7 laptops, 1 cell phone, 127.5ms\n",
            "Speed: 2.9ms preprocess, 127.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "398.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/401.jpg: 384x640 16 persons, 4 chairs, 1 tv, 7 laptops, 1 cell phone, 137.6ms\n",
            "Speed: 3.3ms preprocess, 137.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "401.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/408.jpg: 384x640 15 persons, 3 chairs, 5 laptops, 1 cell phone, 131.0ms\n",
            "Speed: 3.1ms preprocess, 131.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "408.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/410.jpg: 384x640 16 persons, 1 umbrella, 1 cup, 4 chairs, 2 tvs, 5 laptops, 1 cell phone, 227.8ms\n",
            "Speed: 3.4ms preprocess, 227.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "410.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/413.jpg: 384x640 12 persons, 3 chairs, 1 bed, 2 tvs, 7 laptops, 1 cell phone, 216.8ms\n",
            "Speed: 5.2ms preprocess, 216.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "413.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/414.jpg: 384x640 12 persons, 2 chairs, 1 bed, 5 laptops, 1 mouse, 1 cell phone, 151.4ms\n",
            "Speed: 3.5ms preprocess, 151.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "414.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/418.jpg: 384x640 17 persons, 1 chair, 1 bed, 1 tv, 7 laptops, 1 mouse, 1 cell phone, 138.2ms\n",
            "Speed: 3.3ms preprocess, 138.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "418.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/422.jpg: 384x640 18 persons, 2 chairs, 1 bed, 1 tv, 4 laptops, 134.7ms\n",
            "Speed: 2.9ms preprocess, 134.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "422.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/425.jpg: 384x640 14 persons, 2 chairs, 1 tv, 8 laptops, 1 cell phone, 132.8ms\n",
            "Speed: 3.0ms preprocess, 132.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "425.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/436.jpg: 384x640 14 persons, 1 wine glass, 2 chairs, 2 tvs, 7 laptops, 1 mouse, 1 cell phone, 130.2ms\n",
            "Speed: 2.8ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "436.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/439.jpg: 384x640 14 persons, 3 chairs, 3 tvs, 12 laptops, 1 cell phone, 151.2ms\n",
            "Speed: 2.9ms preprocess, 151.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "439.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/450.jpg: 384x640 15 persons, 6 chairs, 1 tv, 9 laptops, 1 cell phone, 212.4ms\n",
            "Speed: 4.8ms preprocess, 212.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "450.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/455.jpg: 384x640 18 persons, 6 chairs, 1 tv, 7 laptops, 1 cell phone, 143.5ms\n",
            "Speed: 3.3ms preprocess, 143.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "455.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/458.jpg: 384x640 14 persons, 2 chairs, 1 tv, 11 laptops, 1 cell phone, 139.9ms\n",
            "Speed: 3.3ms preprocess, 139.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "458.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/469.jpg: 384x640 15 persons, 3 chairs, 2 tvs, 9 laptops, 1 cell phone, 133.8ms\n",
            "Speed: 2.9ms preprocess, 133.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "469.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/483.jpg: 384x640 15 persons, 1 tie, 5 chairs, 1 tv, 8 laptops, 1 cell phone, 141.1ms\n",
            "Speed: 3.2ms preprocess, 141.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "483.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/488.jpg: 384x640 14 persons, 4 chairs, 8 laptops, 1 mouse, 1 cell phone, 141.6ms\n",
            "Speed: 3.5ms preprocess, 141.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "488.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/492.jpg: 384x640 16 persons, 4 chairs, 3 tvs, 9 laptops, 1 cell phone, 180.9ms\n",
            "Speed: 2.9ms preprocess, 180.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "492.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/503.jpg: 384x640 8 persons, 4 tvs, 10 laptops, 3 mouses, 1 keyboard, 1 clock, 219.6ms\n",
            "Speed: 5.1ms preprocess, 219.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "503.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/512.jpg: 384x640 12 persons, 1 chair, 6 tvs, 5 laptops, 2 mouses, 1 clock, 164.3ms\n",
            "Speed: 5.0ms preprocess, 164.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "512.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/514.jpg: 384x640 9 persons, 1 chair, 4 tvs, 7 laptops, 2 mouses, 1 clock, 140.8ms\n",
            "Speed: 3.4ms preprocess, 140.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "514.jpg: 2 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/516.jpg: 384x640 9 persons, 2 chairs, 4 tvs, 7 laptops, 3 mouses, 1 clock, 139.9ms\n",
            "Speed: 3.4ms preprocess, 139.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "516.jpg: 3 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/519.jpg: 384x640 9 persons, 1 chair, 4 tvs, 8 laptops, 3 mouses, 1 keyboard, 1 clock, 152.2ms\n",
            "Speed: 3.5ms preprocess, 152.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "519.jpg: 6 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/521.jpg: 384x640 9 persons, 4 tvs, 7 laptops, 3 mouses, 1 clock, 152.4ms\n",
            "Speed: 3.0ms preprocess, 152.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "521.jpg: 3 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/524.jpg: 384x640 10 persons, 5 tvs, 7 laptops, 2 mouses, 1 clock, 140.2ms\n",
            "Speed: 2.9ms preprocess, 140.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "524.jpg: 3 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/534.jpg: 384x640 10 persons, 3 tvs, 5 laptops, 3 mouses, 1 clock, 148.2ms\n",
            "Speed: 3.4ms preprocess, 148.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "534.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/539.jpg: 384x640 10 persons, 4 tvs, 5 laptops, 1 mouse, 1 cell phone, 1 clock, 145.8ms\n",
            "Speed: 3.6ms preprocess, 145.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "539.jpg: 4 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/541.jpg: 384x640 11 persons, 3 tvs, 11 laptops, 1 mouse, 1 clock, 147.6ms\n",
            "Speed: 3.3ms preprocess, 147.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "541.jpg: 4 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/549.jpg: 384x640 9 persons, 1 chair, 3 tvs, 10 laptops, 3 mouses, 1 keyboard, 1 clock, 129.7ms\n",
            "Speed: 3.0ms preprocess, 129.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "549.jpg: 6 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/563.jpg: 384x640 7 persons, 4 tvs, 7 laptops, 3 mouses, 1 clock, 143.0ms\n",
            "Speed: 3.5ms preprocess, 143.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "563.jpg: 4 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/568.jpg: 384x640 9 persons, 1 chair, 1 dining table, 6 tvs, 8 laptops, 3 mouses, 1 cell phone, 1 clock, 142.7ms\n",
            "Speed: 3.4ms preprocess, 142.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "568.jpg: 7 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/572.jpg: 384x640 11 persons, 1 chair, 4 tvs, 12 laptops, 2 mouses, 1 clock, 205.7ms\n",
            "Speed: 4.4ms preprocess, 205.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "572.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/574.jpg: 384x640 12 persons, 1 chair, 4 tvs, 10 laptops, 2 mouses, 1 clock, 198.5ms\n",
            "Speed: 4.5ms preprocess, 198.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "574.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/580.jpg: 384x640 8 persons, 1 chair, 4 tvs, 9 laptops, 3 mouses, 1 cell phone, 1 clock, 260.9ms\n",
            "Speed: 5.3ms preprocess, 260.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "580.jpg: 6 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/582.jpg: 384x640 9 persons, 1 chair, 4 tvs, 11 laptops, 3 mouses, 1 keyboard, 1 clock, 138.1ms\n",
            "Speed: 3.6ms preprocess, 138.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "582.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/586.jpg: 384x640 9 persons, 1 chair, 4 tvs, 8 laptops, 3 mouses, 1 keyboard, 1 clock, 156.8ms\n",
            "Speed: 3.6ms preprocess, 156.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "586.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/589.jpg: 384x640 8 persons, 1 chair, 1 dining table, 4 tvs, 8 laptops, 3 mouses, 1 keyboard, 1 clock, 160.0ms\n",
            "Speed: 3.4ms preprocess, 160.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "589.jpg: 5 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/590.jpg: 384x640 8 persons, 1 chair, 4 tvs, 7 laptops, 3 mouses, 1 clock, 138.1ms\n",
            "Speed: 3.5ms preprocess, 138.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "590.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/600.jpg: 384x640 13 persons, 1 chair, 4 tvs, 11 laptops, 3 mouses, 1 keyboard, 1 clock, 130.8ms\n",
            "Speed: 3.8ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "600.jpg: 4 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/603.jpg: 384x640 10 persons, 4 chairs, 4 tvs, 9 laptops, 2 mouses, 1 clock, 125.5ms\n",
            "Speed: 2.9ms preprocess, 125.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "603.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/604.jpg: 384x640 12 persons, 1 chair, 4 tvs, 6 laptops, 2 mouses, 1 keyboard, 1 clock, 137.2ms\n",
            "Speed: 3.5ms preprocess, 137.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "604.jpg: 8 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/611.jpg: 384x640 12 persons, 1 chair, 5 tvs, 5 laptops, 3 mouses, 1 clock, 126.3ms\n",
            "Speed: 3.0ms preprocess, 126.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "611.jpg: 5 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/617.jpg: 384x640 19 persons, 3 bottles, 6 chairs, 1 dining table, 3 laptops, 138.2ms\n",
            "Speed: 3.4ms preprocess, 138.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "617.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/624.jpg: 384x640 20 persons, 2 bottles, 11 chairs, 1 dining table, 206.0ms\n",
            "Speed: 4.8ms preprocess, 206.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "624.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/637.jpg: 384x640 20 persons, 2 bottles, 4 chairs, 1 laptop, 131.8ms\n",
            "Speed: 3.0ms preprocess, 131.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "637.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/638.jpg: 384x640 20 persons, 1 bottle, 7 chairs, 1 laptop, 141.7ms\n",
            "Speed: 3.4ms preprocess, 141.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "638.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/647.jpg: 384x640 19 persons, 3 bottles, 7 chairs, 1 dining table, 160.3ms\n",
            "Speed: 3.6ms preprocess, 160.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "647.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/648.jpg: 384x640 18 persons, 2 bottles, 7 chairs, 141.5ms\n",
            "Speed: 3.5ms preprocess, 141.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "648.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/649.jpg: 384x640 21 persons, 2 bottles, 5 chairs, 3 laptops, 127.3ms\n",
            "Speed: 3.0ms preprocess, 127.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "649.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/650.jpg: 384x640 16 persons, 1 bottle, 5 chairs, 222.0ms\n",
            "Speed: 5.0ms preprocess, 222.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "650.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/655.jpg: 384x640 17 persons, 3 bottles, 6 chairs, 2 laptops, 143.0ms\n",
            "Speed: 3.5ms preprocess, 143.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "655.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/663.jpg: 384x640 18 persons, 3 bottles, 6 chairs, 2 laptops, 151.0ms\n",
            "Speed: 3.4ms preprocess, 151.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "663.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/665.jpg: 384x640 19 persons, 3 bottles, 7 chairs, 2 laptops, 136.7ms\n",
            "Speed: 4.5ms preprocess, 136.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "665.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/674.jpg: 384x640 15 persons, 3 bottles, 1 bowl, 7 chairs, 159.2ms\n",
            "Speed: 3.5ms preprocess, 159.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "674.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/682.jpg: 384x640 16 persons, 2 bottles, 5 chairs, 1 laptop, 129.4ms\n",
            "Speed: 3.2ms preprocess, 129.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "682.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/696.jpg: 384x640 17 persons, 1 handbag, 1 bottle, 1 cup, 8 chairs, 1 dining table, 1 laptop, 152.2ms\n",
            "Speed: 2.9ms preprocess, 152.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "696.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/697.jpg: 384x640 17 persons, 2 bottles, 1 cup, 7 chairs, 1 laptop, 214.9ms\n",
            "Speed: 5.4ms preprocess, 214.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "697.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/708.jpg: 384x640 19 persons, 2 bottles, 1 cup, 7 chairs, 144.8ms\n",
            "Speed: 3.3ms preprocess, 144.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "708.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/709.jpg: 384x640 19 persons, 1 bottle, 1 cup, 6 chairs, 148.0ms\n",
            "Speed: 3.2ms preprocess, 148.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "709.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/714.jpg: 384x640 18 persons, 3 bottles, 8 chairs, 140.0ms\n",
            "Speed: 3.5ms preprocess, 140.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "714.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/719.jpg: 384x640 17 persons, 2 bottles, 6 chairs, 1 dining table, 135.3ms\n",
            "Speed: 3.7ms preprocess, 135.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "719.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/732.jpg: 384x640 18 persons, 3 bottles, 9 chairs, 208.5ms\n",
            "Speed: 4.5ms preprocess, 208.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "732.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/733.jpg: 384x640 16 persons, 3 bottles, 7 chairs, 204.4ms\n",
            "Speed: 4.4ms preprocess, 204.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "733.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/746.jpg: 384x640 16 persons, 3 bottles, 6 chairs, 128.0ms\n",
            "Speed: 3.0ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "746.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/749.jpg: 384x640 20 persons, 2 bottles, 7 chairs, 1 laptop, 137.3ms\n",
            "Speed: 3.4ms preprocess, 137.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "749.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/758.jpg: 384x640 20 persons, 2 bottles, 7 chairs, 141.6ms\n",
            "Speed: 5.1ms preprocess, 141.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "758.jpg: 20 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/764.jpg: 384x640 16 persons, 3 bottles, 5 chairs, 128.7ms\n",
            "Speed: 3.1ms preprocess, 128.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "764.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/766.jpg: 384x640 17 persons, 2 bottles, 5 chairs, 1 laptop, 226.5ms\n",
            "Speed: 5.0ms preprocess, 226.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "766.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/770.jpg: 384x640 15 persons, 3 bottles, 9 chairs, 1 dining table, 232.3ms\n",
            "Speed: 5.7ms preprocess, 232.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "770.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/777.jpg: 384x640 19 persons, 3 bottles, 5 chairs, 1 dining table, 2 laptops, 141.1ms\n",
            "Speed: 3.6ms preprocess, 141.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "777.jpg: 17 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/779.jpg: 384x640 16 persons, 1 bottle, 6 chairs, 2 laptops, 137.8ms\n",
            "Speed: 3.1ms preprocess, 137.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "779.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/787.jpg: 384x640 17 persons, 4 bottles, 5 chairs, 4 laptops, 134.2ms\n",
            "Speed: 3.6ms preprocess, 134.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "787.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/790.jpg: 384x640 20 persons, 2 bottles, 2 chairs, 1 laptop, 128.6ms\n",
            "Speed: 3.7ms preprocess, 128.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "790.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/805.jpg: 384x640 17 persons, 3 bottles, 7 chairs, 3 laptops, 195.6ms\n",
            "Speed: 3.4ms preprocess, 195.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "805.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/806.jpg: 384x640 18 persons, 2 bottles, 8 chairs, 2 laptops, 230.4ms\n",
            "Speed: 4.8ms preprocess, 230.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "806.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/808.jpg: 384x640 21 persons, 3 bottles, 5 chairs, 1 laptop, 149.2ms\n",
            "Speed: 5.3ms preprocess, 149.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "808.jpg: 18 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/816.jpg: 384x640 17 persons, 2 bottles, 9 chairs, 1 dining table, 2 laptops, 135.4ms\n",
            "Speed: 3.4ms preprocess, 135.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "816.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/818.jpg: 384x640 17 persons, 2 bottles, 8 chairs, 1 dining table, 1 laptop, 130.9ms\n",
            "Speed: 3.0ms preprocess, 130.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "818.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/825.jpg: 384x640 14 persons, 2 bottles, 6 chairs, 1 laptop, 145.2ms\n",
            "Speed: 3.5ms preprocess, 145.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "825.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/836.jpg: 384x640 13 persons, 16 chairs, 3 dining tables, 133.7ms\n",
            "Speed: 3.0ms preprocess, 133.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "836.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/842.jpg: 384x640 15 persons, 13 chairs, 3 dining tables, 196.4ms\n",
            "Speed: 4.6ms preprocess, 196.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "842.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/846.jpg: 384x640 15 persons, 17 chairs, 3 dining tables, 211.6ms\n",
            "Speed: 4.9ms preprocess, 211.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "846.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/848.jpg: 384x640 14 persons, 16 chairs, 3 dining tables, 146.1ms\n",
            "Speed: 4.5ms preprocess, 146.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "848.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/854.jpg: 384x640 13 persons, 17 chairs, 3 dining tables, 154.2ms\n",
            "Speed: 3.4ms preprocess, 154.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "854.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/855.jpg: 384x640 14 persons, 18 chairs, 2 dining tables, 132.6ms\n",
            "Speed: 3.1ms preprocess, 132.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "855.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/868.jpg: 384x640 13 persons, 1 bottle, 11 chairs, 3 dining tables, 1 book, 126.7ms\n",
            "Speed: 3.7ms preprocess, 126.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "868.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/878.jpg: 384x640 13 persons, 13 chairs, 3 dining tables, 1 laptop, 142.2ms\n",
            "Speed: 3.5ms preprocess, 142.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "878.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/881.jpg: 384x640 16 persons, 16 chairs, 3 dining tables, 1 laptop, 139.9ms\n",
            "Speed: 3.5ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "881.jpg: 15 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/888.jpg: 384x640 11 persons, 10 chairs, 6 dining tables, 201.6ms\n",
            "Speed: 4.8ms preprocess, 201.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "888.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/889.jpg: 384x640 12 persons, 13 chairs, 3 dining tables, 1 laptop, 1 book, 143.6ms\n",
            "Speed: 3.1ms preprocess, 143.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "889.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/894.jpg: 384x640 12 persons, 16 chairs, 4 dining tables, 1 laptop, 1 book, 130.7ms\n",
            "Speed: 3.0ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "894.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/895.jpg: 384x640 16 persons, 16 chairs, 4 dining tables, 1 book, 151.8ms\n",
            "Speed: 2.8ms preprocess, 151.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "895.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/896.jpg: 384x640 14 persons, 14 chairs, 4 dining tables, 1 book, 255.7ms\n",
            "Speed: 7.9ms preprocess, 255.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "896.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/897.jpg: 384x640 11 persons, 14 chairs, 4 dining tables, 1 laptop, 1 book, 138.4ms\n",
            "Speed: 3.1ms preprocess, 138.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "897.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/904.jpg: 384x640 15 persons, 16 chairs, 5 dining tables, 1 laptop, 1 book, 142.7ms\n",
            "Speed: 3.5ms preprocess, 142.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "904.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/905.jpg: 384x640 14 persons, 13 chairs, 5 dining tables, 1 laptop, 1 book, 226.4ms\n",
            "Speed: 5.8ms preprocess, 226.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "905.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/909.jpg: 384x640 15 persons, 16 chairs, 4 dining tables, 2 laptops, 1 book, 165.1ms\n",
            "Speed: 4.9ms preprocess, 165.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "909.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/915.jpg: 384x640 16 persons, 13 chairs, 4 dining tables, 1 laptop, 142.6ms\n",
            "Speed: 3.3ms preprocess, 142.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "915.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/920.jpg: 384x640 15 persons, 16 chairs, 2 dining tables, 163.2ms\n",
            "Speed: 4.3ms preprocess, 163.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "920.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/921.jpg: 384x640 16 persons, 15 chairs, 2 dining tables, 1 book, 142.1ms\n",
            "Speed: 3.5ms preprocess, 142.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "921.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/932.jpg: 384x640 17 persons, 10 chairs, 2 dining tables, 3 laptops, 1 book, 133.9ms\n",
            "Speed: 3.1ms preprocess, 133.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "932.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/937.jpg: 384x640 15 persons, 12 chairs, 2 dining tables, 1 book, 230.6ms\n",
            "Speed: 4.7ms preprocess, 230.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "937.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/945.jpg: 384x640 12 persons, 14 chairs, 3 dining tables, 1 laptop, 1 book, 213.9ms\n",
            "Speed: 4.6ms preprocess, 213.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "945.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/950.jpg: 384x640 11 persons, 12 chairs, 4 dining tables, 1 book, 134.3ms\n",
            "Speed: 3.3ms preprocess, 134.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "950.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/962.jpg: 384x640 11 persons, 17 chairs, 4 dining tables, 1 laptop, 142.9ms\n",
            "Speed: 3.5ms preprocess, 142.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "962.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/966.jpg: 384x640 11 persons, 14 chairs, 6 dining tables, 1 laptop, 140.4ms\n",
            "Speed: 5.3ms preprocess, 140.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "966.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/972.jpg: 384x640 11 persons, 14 chairs, 4 dining tables, 1 laptop, 138.8ms\n",
            "Speed: 3.4ms preprocess, 138.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "972.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/976.jpg: 384x640 15 persons, 11 chairs, 4 dining tables, 1 book, 145.8ms\n",
            "Speed: 3.3ms preprocess, 145.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "976.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/982.jpg: 384x640 13 persons, 14 chairs, 7 dining tables, 132.3ms\n",
            "Speed: 3.3ms preprocess, 132.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "982.jpg: 9 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1016.jpg: 384x640 17 persons, 14 chairs, 2 dining tables, 151.5ms\n",
            "Speed: 3.4ms preprocess, 151.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1016.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1020.jpg: 384x640 13 persons, 14 chairs, 3 dining tables, 205.8ms\n",
            "Speed: 4.4ms preprocess, 205.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1020.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1022.jpg: 384x640 16 persons, 16 chairs, 3 dining tables, 1 laptop, 127.1ms\n",
            "Speed: 2.9ms preprocess, 127.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1022.jpg: 16 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1024.jpg: 384x640 14 persons, 17 chairs, 3 dining tables, 130.2ms\n",
            "Speed: 3.2ms preprocess, 130.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1024.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1025.jpg: 384x640 14 persons, 15 chairs, 3 dining tables, 138.3ms\n",
            "Speed: 3.3ms preprocess, 138.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1025.jpg: 14 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1030.jpg: 384x640 13 persons, 13 chairs, 3 dining tables, 1 laptop, 126.9ms\n",
            "Speed: 3.0ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1030.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1032.jpg: 384x640 12 persons, 13 chairs, 2 dining tables, 1 laptop, 142.2ms\n",
            "Speed: 3.3ms preprocess, 142.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1032.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1038.jpg: 384x640 13 persons, 17 chairs, 2 dining tables, 1 laptop, 1 book, 144.3ms\n",
            "Speed: 5.0ms preprocess, 144.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1038.jpg: 13 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/1040.jpg: 384x640 12 persons, 12 chairs, 3 dining tables, 1 laptop, 1 book, 216.6ms\n",
            "Speed: 4.9ms preprocess, 216.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1040.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/10.jpg: 384x640 10 persons, 8 chairs, 143.4ms\n",
            "Speed: 3.7ms preprocess, 143.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "10.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/14.jpg: 384x640 11 persons, 7 chairs, 143.4ms\n",
            "Speed: 3.5ms preprocess, 143.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "14.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/15.jpg: 384x640 12 persons, 8 chairs, 144.1ms\n",
            "Speed: 3.6ms preprocess, 144.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "15.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/16.jpg: 384x640 12 persons, 7 chairs, 150.9ms\n",
            "Speed: 3.1ms preprocess, 150.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "16.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/17.jpg: 384x640 11 persons, 7 chairs, 129.3ms\n",
            "Speed: 2.9ms preprocess, 129.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "17.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/23.jpg: 384x640 11 persons, 8 chairs, 156.7ms\n",
            "Speed: 5.4ms preprocess, 156.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "23.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/26.jpg: 384x640 10 persons, 10 chairs, 150.8ms\n",
            "Speed: 3.6ms preprocess, 150.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "26.jpg: 10 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/35.jpg: 384x640 13 persons, 4 chairs, 1 book, 216.0ms\n",
            "Speed: 5.6ms preprocess, 216.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "35.jpg: 12 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/39.jpg: 384x640 11 persons, 8 chairs, 1 book, 136.0ms\n",
            "Speed: 3.3ms preprocess, 136.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "39.jpg: 11 labels saved (Teacher direction: left)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Dataset/images/val/41.jpg: 384x640 12 persons, 7 chairs, 2 books, 132.4ms\n",
            "Speed: 3.0ms preprocess, 132.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "41.jpg: 12 labels saved (Teacher direction: left)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".....................................................\n",
        "\n",
        "FaceMesh 1st code"
      ],
      "metadata": {
        "id": "DyhUulNwuRaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from collections import Counter\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "\n",
        "# Paths\n",
        "image_folder = '/content/drive/MyDrive/Saif/img'\n",
        "label_folder = '/content/drive/MyDrive/Saif/labels'\n",
        "visualized_folder = '/content/drive/MyDrive/Saif/visual'\n",
        "\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "os.makedirs(visualized_folder, exist_ok=True)\n",
        "\n",
        "# Load YOLOv8 model for person detection\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Initialize MediaPipe FaceMesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
        "\n",
        "def estimate_head_direction(landmarks):\n",
        "    try:\n",
        "        left_eye = landmarks[33]\n",
        "        right_eye = landmarks[263]\n",
        "        dx = left_eye.x - right_eye.x\n",
        "        if dx > 0.04:\n",
        "            return 'left'\n",
        "        elif dx < -0.04:\n",
        "            return 'right'\n",
        "        else:\n",
        "            return 'front'\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "def classify_posture_binary(landmarks, teacher_dir):\n",
        "    direction = estimate_head_direction(landmarks)\n",
        "    return 0 if direction == teacher_dir else 1  # 0: Engaged, 1: Distracted\n",
        "\n",
        "# Process all images\n",
        "for file in os.listdir(image_folder):\n",
        "    if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(image_folder, file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    img_h, img_w = image.shape[:2]\n",
        "\n",
        "    results = model(image_path)[0]\n",
        "    boxes = results.boxes.data\n",
        "\n",
        "    all_directions = []\n",
        "    temp_landmarks = []\n",
        "    temp_boxes = []\n",
        "\n",
        "    for box in boxes:\n",
        "        cls = int(box[5])\n",
        "        if cls != 0:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, box[:4])\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(img_w, x2), min(img_h, y2)\n",
        "\n",
        "        person_crop = image[y1:y2, x1:x2]\n",
        "        if person_crop.size == 0:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB)\n",
        "            face_result = face_mesh.process(crop_rgb)\n",
        "        except:\n",
        "            face_result = None\n",
        "\n",
        "        if face_result and face_result.multi_face_landmarks:\n",
        "            landmarks = face_result.multi_face_landmarks[0].landmark\n",
        "            direction = estimate_head_direction(landmarks)\n",
        "            all_directions.append(direction)\n",
        "            temp_landmarks.append(landmarks)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "        else:\n",
        "            temp_landmarks.append(None)\n",
        "            temp_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    teacher_dir = 'front'\n",
        "    if all_directions:\n",
        "        teacher_dir = Counter(all_directions).most_common(1)[0][0]\n",
        "\n",
        "    label_lines = []\n",
        "\n",
        "    for i, landmarks in enumerate(temp_landmarks):\n",
        "        x1, y1, x2, y2 = temp_boxes[i]\n",
        "        box_color = (0, 255, 0)\n",
        "        label_text = 'unknown'\n",
        "\n",
        "        if landmarks:\n",
        "            posture_class = classify_posture_binary(landmarks, teacher_dir)\n",
        "            direction = estimate_head_direction(landmarks)\n",
        "            label_text = f\"{direction}, {'Engaged' if posture_class == 0 else 'Distracted'}\"\n",
        "            box_color = (0, 255, 0) if posture_class == 0 else (0, 0, 255)\n",
        "\n",
        "            x_center = ((x1 + x2) / 2) / img_w\n",
        "            y_center = ((y1 + y2) / 2) / img_h\n",
        "            w = (x2 - x1) / img_w\n",
        "            h = (y2 - y1) / img_h\n",
        "            label_line = f\"{posture_class} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\"\n",
        "            label_lines.append(label_line)\n",
        "\n",
        "            # Get landmarks in absolute coordinates\n",
        "            def to_abs(lm):\n",
        "                return (int(x1 + lm.x * (x2 - x1)), int(y1 + lm.y * (y2 - y1)))\n",
        "\n",
        "            left_eye = to_abs(landmarks[33])\n",
        "            right_eye = to_abs(landmarks[263])\n",
        "            nose = to_abs(landmarks[1])\n",
        "            chin = to_abs(landmarks[152])\n",
        "            forehead = to_abs(landmarks[10])  # Forehead landmark\n",
        "\n",
        "            # Calculate midpoints for reference\n",
        "            eye_mid = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
        "            head_mid = ((nose[0] + chin[0]) // 2, (nose[1] + chin[1]) // 2)\n",
        "\n",
        "            vx = head_mid[0] - eye_mid[0]\n",
        "            vy = head_mid[1] - eye_mid[1]\n",
        "\n",
        "            poi_dist = 150\n",
        "            norm = (vx ** 2 + vy ** 2) ** 0.5\n",
        "            if norm == 0:\n",
        "                norm = 1\n",
        "            vx_norm = vx / norm\n",
        "            vy_norm = vy / norm\n",
        "\n",
        "            poi_x = int(eye_mid[0] + vx_norm * poi_dist)\n",
        "            poi_y = int(eye_mid[1] + vy_norm * poi_dist)\n",
        "\n",
        "            # Draw bounding box and label\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), box_color, 2)\n",
        "            cv2.putText(image, label_text, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "            # Draw gaze lines from left_eye, right_eye, nose, chin, forehead to POI\n",
        "            for pt in [left_eye, right_eye, nose, chin, forehead]:\n",
        "                cv2.line(image, pt, (poi_x, poi_y), (0, 0, 255), 2)\n",
        "                cv2.circle(image, pt, 4, (0, 255, 255), -1)  # mark landmarks in yellow\n",
        "\n",
        "            # Draw POI\n",
        "            cv2.circle(image, (poi_x, poi_y), 6, (0, 0, 255), -1)\n",
        "\n",
        "        else:\n",
        "            label_text = \"No face\"\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (128, 128, 128), 2)\n",
        "            cv2.putText(image, label_text, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "    # Save labels\n",
        "    label_file = os.path.join(label_folder, file.rsplit('.', 1)[0] + '.txt')\n",
        "    with open(label_file, 'w') as f:\n",
        "        for line in label_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    # Save visualized image\n",
        "    out_path = os.path.join(visualized_folder, file)\n",
        "    cv2.imwrite(out_path, image)\n",
        "\n",
        "    print(f\"{file}: {len(label_lines)} labels saved (Teacher direction: {teacher_dir})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pq35YVwuQVY",
        "outputId": "be25038d-16fc-48d7-d67e-8cd400e96443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img4.JPG: 480x640 17 persons, 7 chairs, 164.2ms\n",
            "Speed: 3.9ms preprocess, 164.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img4.JPG: 13 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img7.JPG: 480x640 12 persons, 1 surfboard, 5 chairs, 231.8ms\n",
            "Speed: 5.5ms preprocess, 231.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img7.JPG: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img19.JPG: 480x640 9 persons, 5 chairs, 1 couch, 1 dining table, 2 tvs, 2 laptops, 225.6ms\n",
            "Speed: 5.3ms preprocess, 225.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img19.JPG: 7 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img26.JPG: 480x640 18 persons, 1 tie, 1 chair, 2 laptops, 3 books, 232.4ms\n",
            "Speed: 5.3ms preprocess, 232.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img26.JPG: 17 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img27.JPG: 480x640 16 persons, 2 ties, 6 chairs, 144.0ms\n",
            "Speed: 3.9ms preprocess, 144.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img27.JPG: 12 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img30.JPG: 480x640 16 persons, 10 chairs, 149.7ms\n",
            "Speed: 4.0ms preprocess, 149.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "img30.JPG: 13 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img49.jpg: 384x640 12 persons, 8 chairs, 3 dining tables, 1 clock, 126.4ms\n",
            "Speed: 2.8ms preprocess, 126.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img49.jpg: 6 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img50.jpg: 384x640 12 persons, 5 chairs, 1 dining table, 1 clock, 121.7ms\n",
            "Speed: 2.8ms preprocess, 121.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img50.jpg: 7 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img51.jpg: 384x640 15 persons, 5 chairs, 1 dining table, 1 clock, 119.7ms\n",
            "Speed: 2.8ms preprocess, 119.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img51.jpg: 10 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img60.jpg: 384x640 16 persons, 1 backpack, 2 books, 124.3ms\n",
            "Speed: 3.1ms preprocess, 124.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img60.jpg: 12 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img1.jpg: 384x640 23 persons, 2 bottles, 4 chairs, 4 laptops, 138.3ms\n",
            "Speed: 2.9ms preprocess, 138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img1.jpg: 18 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img2.jpg: 384x640 24 persons, 2 bottles, 1 cup, 3 chairs, 4 laptops, 119.9ms\n",
            "Speed: 2.8ms preprocess, 119.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img2.jpg: 18 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img3.jpg: 384x640 24 persons, 2 bottles, 1 cup, 2 chairs, 3 laptops, 121.6ms\n",
            "Speed: 2.8ms preprocess, 121.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img3.jpg: 18 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img4.jpg: 384x640 24 persons, 2 bottles, 1 cup, 2 chairs, 2 laptops, 122.4ms\n",
            "Speed: 3.3ms preprocess, 122.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img4.jpg: 16 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img5.jpg: 384x640 24 persons, 2 bottles, 2 chairs, 4 laptops, 156.4ms\n",
            "Speed: 5.5ms preprocess, 156.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img5.jpg: 17 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img6.jpg: 384x640 24 persons, 2 bottles, 1 cup, 4 chairs, 4 laptops, 144.1ms\n",
            "Speed: 4.8ms preprocess, 144.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img6.jpg: 18 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img7.jpg: 384x640 6 persons, 118.8ms\n",
            "Speed: 2.9ms preprocess, 118.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img7.jpg: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img8.jpg: 384x640 7 persons, 126.3ms\n",
            "Speed: 2.8ms preprocess, 126.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img8.jpg: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img9.jpg: 384x640 7 persons, 129.6ms\n",
            "Speed: 2.9ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img9.jpg: 6 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img10.jpg: 384x640 6 persons, 124.5ms\n",
            "Speed: 2.7ms preprocess, 124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img10.jpg: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img11.jpg: 384x640 6 persons, 118.8ms\n",
            "Speed: 2.8ms preprocess, 118.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img11.jpg: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img12.jpg: 384x640 6 persons, 126.9ms\n",
            "Speed: 2.9ms preprocess, 126.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img12.jpg: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img13.jpg: 384x640 6 persons, 121.7ms\n",
            "Speed: 2.8ms preprocess, 121.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img13.jpg: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img14.jpg: 384x640 6 persons, 122.9ms\n",
            "Speed: 2.8ms preprocess, 122.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img14.jpg: 5 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img15.jpg: 384x640 19 persons, 1 chair, 125.2ms\n",
            "Speed: 2.8ms preprocess, 125.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img15.jpg: 14 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/img16.jpg: 384x640 19 persons, 1 chair, 140.6ms\n",
            "Speed: 2.9ms preprocess, 140.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "img16.jpg: 14 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1366.jpg: 384x640 11 persons, 5 chairs, 120.1ms\n",
            "Speed: 2.8ms preprocess, 120.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1366.jpg: 10 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/239.jpg: 384x640 15 persons, 5 chairs, 12 laptops, 127.2ms\n",
            "Speed: 2.8ms preprocess, 127.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "239.jpg: 14 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/370.jpg: 384x640 20 persons, 4 chairs, 2 tvs, 8 laptops, 1 cell phone, 127.4ms\n",
            "Speed: 2.9ms preprocess, 127.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "370.jpg: 18 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/556.jpg: 384x640 9 persons, 1 chair, 4 tvs, 4 laptops, 2 mouses, 1 clock, 120.3ms\n",
            "Speed: 2.9ms preprocess, 120.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "556.jpg: 1 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/574.jpg: 384x640 12 persons, 1 chair, 4 tvs, 10 laptops, 2 mouses, 1 clock, 125.4ms\n",
            "Speed: 3.2ms preprocess, 125.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "574.jpg: 0 labels saved (Teacher direction: front)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/649.jpg: 384x640 21 persons, 2 bottles, 5 chairs, 3 laptops, 204.2ms\n",
            "Speed: 4.3ms preprocess, 204.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "649.jpg: 13 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/628.jpg: 384x640 21 persons, 3 bottles, 5 chairs, 1 laptop, 187.3ms\n",
            "Speed: 4.0ms preprocess, 187.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "628.jpg: 15 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/884.jpg: 384x640 15 persons, 11 chairs, 2 dining tables, 1 laptop, 193.1ms\n",
            "Speed: 4.1ms preprocess, 193.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "884.jpg: 14 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/830.jpg: 384x640 13 persons, 16 chairs, 3 dining tables, 188.2ms\n",
            "Speed: 4.0ms preprocess, 188.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "830.jpg: 10 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/882.jpg: 384x640 12 persons, 14 chairs, 2 dining tables, 1 laptop, 191.8ms\n",
            "Speed: 4.1ms preprocess, 191.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "882.jpg: 11 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/829.jpg: 384x640 16 persons, 14 chairs, 3 dining tables, 189.6ms\n",
            "Speed: 4.2ms preprocess, 189.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "829.jpg: 12 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1200.jpg: 384x640 13 persons, 2 chairs, 2 remotes, 195.4ms\n",
            "Speed: 4.1ms preprocess, 195.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1200.jpg: 10 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1104.jpg: 384x640 11 persons, 3 chairs, 205.3ms\n",
            "Speed: 4.1ms preprocess, 205.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1104.jpg: 6 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1058.jpg: 384x640 12 persons, 4 chairs, 125.1ms\n",
            "Speed: 3.1ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1058.jpg: 8 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1691.jpg: 384x640 15 persons, 14 chairs, 1 laptop, 127.3ms\n",
            "Speed: 2.8ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1691.jpg: 12 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1665.jpg: 384x640 11 persons, 15 chairs, 125.3ms\n",
            "Speed: 2.8ms preprocess, 125.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1665.jpg: 10 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1495.jpg: 384x640 17 persons, 6 chairs, 135.5ms\n",
            "Speed: 5.0ms preprocess, 135.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1495.jpg: 13 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1481.jpg: 384x640 23 persons, 1 suitcase, 4 chairs, 122.5ms\n",
            "Speed: 2.8ms preprocess, 122.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1481.jpg: 15 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1691 (1).jpg: 384x640 15 persons, 14 chairs, 1 laptop, 134.9ms\n",
            "Speed: 2.8ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1691 (1).jpg: 12 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1459.jpg: 384x640 11 persons, 2 chairs, 1 book, 127.3ms\n",
            "Speed: 3.1ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1459.jpg: 9 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1450.jpg: 384x640 12 persons, 1 chair, 123.1ms\n",
            "Speed: 2.8ms preprocess, 123.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1450.jpg: 8 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1440.jpg: 384x640 13 persons, 1 backpack, 1 suitcase, 1 chair, 126.2ms\n",
            "Speed: 2.7ms preprocess, 126.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1440.jpg: 10 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1886.jpg: 384x640 18 persons, 4 chairs, 262.5ms\n",
            "Speed: 3.2ms preprocess, 262.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1886.jpg: 9 labels saved (Teacher direction: right)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Saif/img/1855.jpg: 384x640 18 persons, 6 chairs, 124.8ms\n",
            "Speed: 2.8ms preprocess, 124.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1855.jpg: 14 labels saved (Teacher direction: right)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2nd version"
      ],
      "metadata": {
        "id": "OxAb6eXX71D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "# --- Paths ---\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "output_folder = '/content/drive/MyDrive/Saif/vvsual'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# --- Load YOLOv8 face detector ---\n",
        "model = YOLO('/content/drive/MyDrive/Saif/yolov8l-face-lindevs.pt')  # Make sure this path is correct!\n",
        "\n",
        "# --- Setup MediaPipe Face Mesh ---\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True,\n",
        "                                  max_num_faces=10,\n",
        "                                  refine_landmarks=True,\n",
        "                                  min_detection_confidence=0.5)\n",
        "\n",
        "# --- Helper function: convert normalized landmarks to image coords ---\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "# --- Process images ---\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "\n",
        "    # --- Detect faces ---\n",
        "    results = model(image)[0]\n",
        "    boxes = results.boxes.xyxy.cpu().numpy()  # (x1, y1, x2, y2)\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        # Add margin around face crop for better landmark detection\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "\n",
        "        # Convert BGR to RGB for MediaPipe\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # --- MediaPipe Face Mesh detection ---\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            continue\n",
        "        landmarks = mp_results.multi_face_landmarks[0]\n",
        "\n",
        "        # --- Map key landmarks ---\n",
        "        # Nose tip: 1\n",
        "        # Chin: 152\n",
        "        # Left eye left corner: 33\n",
        "        # Right eye right corner: 263\n",
        "        # Left forehead (approx): 10\n",
        "        # Mouth left corner: 61\n",
        "        # Mouth right corner: 291\n",
        "\n",
        "        points_ids = {\n",
        "            'nose_tip': 1,\n",
        "            'chin': 152,\n",
        "            'left_eye_outer': 33,\n",
        "            'right_eye_outer': 263,\n",
        "            'left_forehead': 10,\n",
        "            'mouth_left': 61,\n",
        "            'mouth_right': 291\n",
        "        }\n",
        "\n",
        "        pts = {}\n",
        "        for name, idx in points_ids.items():\n",
        "            pt = landmark_to_point(landmarks.landmark[idx], face_crop.shape)\n",
        "            pts[name] = (pt[0] + x1m, pt[1] + y1m)  # Map back to original image coords\n",
        "\n",
        "        # --- Draw face bounding box ---\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "        # --- Draw gaze lines ---\n",
        "        # For simplicity, draw lines from nose tip to forehead, chin, and eyes\n",
        "\n",
        "        # Nose tip point\n",
        "        p_nose = pts['nose_tip']\n",
        "\n",
        "        # Forehead\n",
        "        p_forehead = pts['left_forehead']\n",
        "        cv2.line(image, p_nose, p_forehead, (255, 0, 0), 2)\n",
        "\n",
        "        # Chin\n",
        "        p_chin = pts['chin']\n",
        "        cv2.line(image, p_nose, p_chin, (0, 255, 255), 2)\n",
        "\n",
        "        # Left eye\n",
        "        p_left_eye = pts['left_eye_outer']\n",
        "        cv2.line(image, p_nose, p_left_eye, (0, 0, 255), 2)\n",
        "\n",
        "        # Right eye\n",
        "        p_right_eye = pts['right_eye_outer']\n",
        "        cv2.line(image, p_nose, p_right_eye, (0, 0, 255), 2)\n",
        "\n",
        "        # Draw points for visibility\n",
        "        for p in pts.values():\n",
        "            cv2.circle(image, p, 3, (0,0,255), -1)\n",
        "\n",
        "    # --- Save result ---\n",
        "    cv2.imwrite(os.path.join(output_folder, filename), image)\n",
        "\n",
        "print(\"Done processing all images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_7esAh374OI",
        "outputId": "d8c713f0-aea8-4028-9074-54cb5e0eb28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 20 faces, 2077.6ms\n",
            "Speed: 5.8ms preprocess, 2077.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 faces, 1903.6ms\n",
            "Speed: 5.0ms preprocess, 1903.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 6 faces, 2002.6ms\n",
            "Speed: 4.8ms preprocess, 2002.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 20 faces, 3043.6ms\n",
            "Speed: 6.9ms preprocess, 3043.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 17 faces, 2339.9ms\n",
            "Speed: 5.0ms preprocess, 2339.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 faces, 1859.6ms\n",
            "Speed: 5.1ms preprocess, 1859.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 384x640 18 faces, 1517.8ms\n",
            "Speed: 4.2ms preprocess, 1517.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 faces, 1519.4ms\n",
            "Speed: 3.8ms preprocess, 1519.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 1743.0ms\n",
            "Speed: 4.0ms preprocess, 1743.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 2468.1ms\n",
            "Speed: 4.3ms preprocess, 2468.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 1711.3ms\n",
            "Speed: 5.0ms preprocess, 1711.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 1542.4ms\n",
            "Speed: 4.2ms preprocess, 1542.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 1505.1ms\n",
            "Speed: 3.7ms preprocess, 1505.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 1505.3ms\n",
            "Speed: 4.2ms preprocess, 1505.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 1578.9ms\n",
            "Speed: 5.5ms preprocess, 1578.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 1648.2ms\n",
            "Speed: 4.3ms preprocess, 1648.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 2443.3ms\n",
            "Speed: 3.9ms preprocess, 2443.3ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 1819.3ms\n",
            "Speed: 4.3ms preprocess, 1819.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 1519.5ms\n",
            "Speed: 4.0ms preprocess, 1519.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 1566.0ms\n",
            "Speed: 3.9ms preprocess, 1566.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 faces, 1539.8ms\n",
            "Speed: 3.6ms preprocess, 1539.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 1537.0ms\n",
            "Speed: 4.2ms preprocess, 1537.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 1537.6ms\n",
            "Speed: 4.1ms preprocess, 1537.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 2011.1ms\n",
            "Speed: 3.9ms preprocess, 2011.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 45 faces, 2455.3ms\n",
            "Speed: 4.0ms preprocess, 2455.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 40 faces, 1505.7ms\n",
            "Speed: 3.2ms preprocess, 1505.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 1561.2ms\n",
            "Speed: 4.9ms preprocess, 1561.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 1507.1ms\n",
            "Speed: 4.1ms preprocess, 1507.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 1511.4ms\n",
            "Speed: 4.4ms preprocess, 1511.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 faces, 1529.8ms\n",
            "Speed: 3.9ms preprocess, 1529.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 faces, 1768.8ms\n",
            "Speed: 4.0ms preprocess, 1768.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 2475.3ms\n",
            "Speed: 4.7ms preprocess, 2475.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 1723.3ms\n",
            "Speed: 4.2ms preprocess, 1723.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 1512.8ms\n",
            "Speed: 3.7ms preprocess, 1512.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 1506.2ms\n",
            "Speed: 4.4ms preprocess, 1506.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 1551.4ms\n",
            "Speed: 4.1ms preprocess, 1551.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 1559.5ms\n",
            "Speed: 3.9ms preprocess, 1559.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 1558.7ms\n",
            "Speed: 4.2ms preprocess, 1558.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 2374.9ms\n",
            "Speed: 4.2ms preprocess, 2374.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 2124.8ms\n",
            "Speed: 4.4ms preprocess, 2124.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 1536.9ms\n",
            "Speed: 4.4ms preprocess, 1536.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 1549.0ms\n",
            "Speed: 4.2ms preprocess, 1549.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 1547.1ms\n",
            "Speed: 4.0ms preprocess, 1547.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 faces, 1541.3ms\n",
            "Speed: 4.3ms preprocess, 1541.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 1528.2ms\n",
            "Speed: 4.0ms preprocess, 1528.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 2037.6ms\n",
            "Speed: 4.0ms preprocess, 2037.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 2437.6ms\n",
            "Speed: 5.6ms preprocess, 2437.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 1553.0ms\n",
            "Speed: 5.3ms preprocess, 1553.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 1530.8ms\n",
            "Speed: 3.9ms preprocess, 1530.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 1526.7ms\n",
            "Speed: 4.1ms preprocess, 1526.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Done processing all images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUll and final version"
      ],
      "metadata": {
        "id": "_DLZYhVnfErD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics mediapipe opencv-python"
      ],
      "metadata": {
        "id": "Yc83NS8DXh1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improved..............."
      ],
      "metadata": {
        "id": "cukw_wQmhnX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "# --- Paths ---\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "output_folder = '/content/drive/MyDrive/Saif/visuuualll'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# --- Load YOLOv8 face detector ---\n",
        "model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt')\n",
        "\n",
        "# --- Setup MediaPipe Face Mesh ---\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=10,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "# --- Helper: Convert landmark to image point ---\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "# --- Process each image ---\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    results = model(image)[0]\n",
        "    boxes = results.boxes.xyxy.cpu().numpy()\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                # Define landmark indices\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1,\n",
        "                    'chin': 152,\n",
        "                    'left_eye_outer': 33,\n",
        "                    'right_eye_outer': 263,\n",
        "                    'left_forehead': 10,\n",
        "                    'mouth_left': 61,\n",
        "                    'mouth_right': 291\n",
        "                }\n",
        "\n",
        "                # Get landmark coordinates\n",
        "                pts = {}\n",
        "                for name, idx in points_ids.items():\n",
        "                    pt = landmark_to_point(landmarks.landmark[idx], face_crop.shape)\n",
        "                    pts[name] = (pt[0] + x1m, pt[1] + y1m)\n",
        "\n",
        "                # Compute average direction to nose\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                if norm < 1e-6:\n",
        "                    continue\n",
        "                avg_dir /= norm\n",
        "\n",
        "                # Extended nose point\n",
        "                nose_extended = (p_nose + avg_dir * 190).astype(int) #############################################################################\n",
        "\n",
        "                # Define unique line colors per landmark\n",
        "                line_colors = {\n",
        "                    'left_forehead': (0, 255, 255),     # Yellow\n",
        "                    'chin': (255, 0, 0),              # Blue\n",
        "                    'left_eye_outer': (0, 0, 255),    # Red\n",
        "                    'right_eye_outer': (255, 255, 0), # Cyan\n",
        "                    'mouth_left': (255, 0, 255),      # Magenta\n",
        "                    'mouth_right': (0, 165, 255)      # Orange\n",
        "                }\n",
        "\n",
        "\n",
        "                # Draw colored gaze lines\n",
        "                for key, color in line_colors.items():\n",
        "                    cv2.line(image, pts[key], tuple(nose_extended), color, 2)\n",
        "\n",
        "                # Draw landmark points (without names)\n",
        "                for pt in pts.values():\n",
        "                    cv2.circle(image, pt, 3, (0, 0, 255), -1)\n",
        "\n",
        "                # Highlight extended nose point\n",
        "                cv2.circle(image, tuple(nose_extended), 4, (0, 0, 255), -1)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Error processing landmarks in {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Save processed image\n",
        "    output_path = os.path.join(output_folder, filename)\n",
        "    cv2.imwrite(output_path, image)\n",
        "\n",
        "print(\"âœ… Done. Keypoint labels removed and multicolor gaze lines applied.\")\n"
      ],
      "metadata": {
        "id": "_ZXqmk__Vv4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2D2D2D2D2D2D2D2D2D......................."
      ],
      "metadata": {
        "id": "9aIlEGZ305qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "output_folder = '/content/drive/MyDrive/Saif/yyy'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "face_model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt', verbose=False)\n",
        "body_model = YOLO('yolov8n-pose.pt', verbose=False)\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=30,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    if v1 is None or v2 is None:\n",
        "        return 0.0\n",
        "    dot = np.dot(v1, v2)\n",
        "    norm_prod = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "    return dot / norm_prod if norm_prod > 1e-6 else 0.0\n",
        "\n",
        "MIN_FACE_HEIGHT_FOR_DETAILED = 70\n",
        "MIN_FACE_WIDTH_FOR_DETAILED = 50\n",
        "SLEEPY_EYE_RATIO_THRESH = 0.01\n",
        "TALKING_MOUTH_RATIO_THRESH = 2.8\n",
        "GAZE_SIMILARITY_THRESH = 0.4\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    body_results = body_model(image)[0]\n",
        "    person_boxes = [b for b in body_results.boxes.data.cpu().numpy() if int(b[5]) == 0]\n",
        "\n",
        "    face_results = face_model(image)[0]\n",
        "    boxes = face_results.boxes.xyxy.cpu().numpy().astype(int)\n",
        "    face_data = []\n",
        "\n",
        "    for (x1, y1, x2, y2) in boxes:\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "        face_w, face_h = x2 - x1, y2 - y1\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1, 'chin': 152,\n",
        "                    'left_eye_outer': 33, 'right_eye_outer': 263,\n",
        "                    'left_forehead': 10, 'mouth_left': 61,\n",
        "                    'mouth_right': 291, 'left_eye_top': 159,\n",
        "                    'left_eye_bottom': 145, 'right_eye_top': 386,\n",
        "                    'right_eye_bottom': 374\n",
        "                }\n",
        "\n",
        "                pts = {\n",
        "                    name: (landmark_to_point(landmarks.landmark[idx], face_crop.shape)[0] + x1m,\n",
        "                           landmark_to_point(landmarks.landmark[idx], face_crop.shape)[1] + y1m)\n",
        "                    for name, idx in points_ids.items()\n",
        "                }\n",
        "\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in\n",
        "                                     ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                gaze_vec = avg_dir / norm if norm > 1e-6 else None\n",
        "                nose_extended = (p_nose + gaze_vec * 190).astype(int) if gaze_vec is not None else p_nose\n",
        "\n",
        "                for key, color in {\n",
        "                    'left_forehead': (0, 255, 255),\n",
        "                    'chin': (255, 0, 0),\n",
        "                    'left_eye_outer': (0, 0, 255),\n",
        "                    'right_eye_outer': (255, 255, 0),\n",
        "                    'mouth_left': (255, 0, 255),\n",
        "                    'mouth_right': (0, 165, 255)\n",
        "                }.items():\n",
        "                    if gaze_vec is not None:\n",
        "                        cv2.line(image, pts[key], tuple(nose_extended), color, 2)\n",
        "\n",
        "                def eye_ratio_calc():\n",
        "                    left_eye_h = np.linalg.norm(np.array(pts['left_eye_top']) - np.array(pts['left_eye_bottom']))\n",
        "                    left_eye_w = np.linalg.norm(np.array(pts['left_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    right_eye_h = np.linalg.norm(np.array(pts['right_eye_top']) - np.array(pts['right_eye_bottom']))\n",
        "                    right_eye_w = np.linalg.norm(np.array(pts['right_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    left_ratio = left_eye_h / left_eye_w if left_eye_w > 1e-6 else 0\n",
        "                    right_ratio = right_eye_h / right_eye_w if right_eye_w > 1e-6 else 0\n",
        "                    return (left_ratio + right_ratio) / 2\n",
        "\n",
        "                eye_ratio = eye_ratio_calc()\n",
        "                mouth_w = np.linalg.norm(np.array(pts['mouth_right']) - np.array(pts['mouth_left']))\n",
        "                mouth_h = np.linalg.norm(np.array(pts['chin']) - np.array(pts['nose_tip']))\n",
        "                mouth_ratio = mouth_h / mouth_w if mouth_w > 1e-6 else 0\n",
        "\n",
        "                face_data.append({\n",
        "                    'center': face_center, 'label': 'Unknown', 'gaze_vector': gaze_vec,\n",
        "                    'engagement_percent': None,\n",
        "                    'eye_ratio': eye_ratio, 'mouth_ratio': mouth_ratio,\n",
        "                    'face_w': face_w, 'face_h': face_h\n",
        "                })\n",
        "\n",
        "            except:\n",
        "                face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "                continue\n",
        "\n",
        "    valid_gaze_vectors = [f['gaze_vector'] for f in face_data if f['gaze_vector'] is not None]\n",
        "    if valid_gaze_vectors:\n",
        "        mean_gaze = np.mean(valid_gaze_vectors, axis=0)\n",
        "        mean_gaze /= np.linalg.norm(mean_gaze)\n",
        "\n",
        "        for f in face_data:\n",
        "            gv = f['gaze_vector']\n",
        "            if gv is not None:\n",
        "                similarity = cosine_similarity(gv, mean_gaze)\n",
        "                percent = int(similarity * 100)\n",
        "                f['engagement_percent'] = percent\n",
        "\n",
        "                if f['face_w'] < MIN_FACE_WIDTH_FOR_DETAILED or f['face_h'] < MIN_FACE_HEIGHT_FOR_DETAILED:\n",
        "                    f['label'] = 'Engaged' if similarity >= GAZE_SIMILARITY_THRESH else 'Distracted'\n",
        "                else:\n",
        "                    if f['eye_ratio'] < SLEEPY_EYE_RATIO_THRESH:\n",
        "                        f['label'] = 'Sleepy'\n",
        "                    elif f['mouth_ratio'] > TALKING_MOUTH_RATIO_THRESH:\n",
        "                        f['label'] = 'Talking'\n",
        "                    elif similarity < GAZE_SIMILARITY_THRESH:\n",
        "                        f['label'] = 'Distracted'\n",
        "                    else:\n",
        "                        f['label'] = 'Engaged'\n",
        "            else:\n",
        "                f['engagement_percent'] = None\n",
        "                f['label'] = 'Turned'\n",
        "    else:\n",
        "        for f in face_data:\n",
        "            f['engagement_percent'] = None\n",
        "            f['label'] = 'Turned'\n",
        "\n",
        "    for body in person_boxes:\n",
        "        x1, y1, x2, y2, _, _ = map(int, body[:6])\n",
        "        body_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "\n",
        "        closest_face = None\n",
        "        min_dist = float('inf')\n",
        "        for face in face_data:\n",
        "            fx, fy = face['center']\n",
        "            dist = np.linalg.norm(np.array([fx, fy]) - np.array(body_center))\n",
        "            if dist < min_dist and dist < 150:\n",
        "                min_dist = dist\n",
        "                closest_face = face\n",
        "\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (100, 200, 100), 2)\n",
        "\n",
        "        if closest_face:\n",
        "            label = closest_face['label']\n",
        "            percent = closest_face.get('engagement_percent', None)\n",
        "            text = f\"{label} {percent}%\" if percent is not None else label\n",
        "\n",
        "            if label.lower() == 'engaged':\n",
        "                color = (0, 255, 255)  # Yellow\n",
        "            elif label.lower() == 'distracted':\n",
        "                color = (0, 0, 255)    # Red\n",
        "            else:\n",
        "                color = (100, 200, 100)\n",
        "\n",
        "            cv2.putText(image, text, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "    # âœ… Save labeled image for this file\n",
        "    cv2.imwrite(os.path.join(output_folder, filename), image)\n",
        "\n",
        "print(\"âœ… All done. Check output folder for labeled images.\")\n"
      ],
      "metadata": {
        "id": "aLjU6FZNldmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245ad4ac-39c2-4b70-e038-dd5815b78d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 12 persons, 987.8ms\n",
            "Speed: 29.6ms preprocess, 987.8ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 19 faces, 971.9ms\n",
            "Speed: 16.6ms preprocess, 971.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 6 persons, 263.2ms\n",
            "Speed: 7.9ms preprocess, 263.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 7 faces, 592.5ms\n",
            "Speed: 10.8ms preprocess, 592.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 persons, 266.5ms\n",
            "Speed: 8.1ms preprocess, 266.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 21 faces, 543.6ms\n",
            "Speed: 9.4ms preprocess, 543.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 6 persons, 259.7ms\n",
            "Speed: 7.9ms preprocess, 259.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 faces, 592.2ms\n",
            "Speed: 9.3ms preprocess, 592.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 384x640 8 persons, 216.2ms\n",
            "Speed: 6.0ms preprocess, 216.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 faces, 488.7ms\n",
            "Speed: 6.0ms preprocess, 488.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 207.3ms\n",
            "Speed: 6.4ms preprocess, 207.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 faces, 486.6ms\n",
            "Speed: 5.9ms preprocess, 486.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 204.6ms\n",
            "Speed: 5.9ms preprocess, 204.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 487.4ms\n",
            "Speed: 6.5ms preprocess, 487.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 203.0ms\n",
            "Speed: 5.5ms preprocess, 203.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 475.2ms\n",
            "Speed: 6.0ms preprocess, 475.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 194.5ms\n",
            "Speed: 5.9ms preprocess, 194.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 474.4ms\n",
            "Speed: 5.7ms preprocess, 474.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 301.3ms\n",
            "Speed: 6.3ms preprocess, 301.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 788.0ms\n",
            "Speed: 6.2ms preprocess, 788.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 327.3ms\n",
            "Speed: 8.1ms preprocess, 327.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 731.9ms\n",
            "Speed: 10.5ms preprocess, 731.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 342.5ms\n",
            "Speed: 12.2ms preprocess, 342.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 724.2ms\n",
            "Speed: 8.7ms preprocess, 724.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 332.9ms\n",
            "Speed: 7.0ms preprocess, 332.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 657.9ms\n",
            "Speed: 5.9ms preprocess, 657.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 218.7ms\n",
            "Speed: 6.5ms preprocess, 218.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 491.0ms\n",
            "Speed: 6.5ms preprocess, 491.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 239.7ms\n",
            "Speed: 6.0ms preprocess, 239.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 487.3ms\n",
            "Speed: 6.1ms preprocess, 487.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 227.3ms\n",
            "Speed: 6.1ms preprocess, 227.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 509.8ms\n",
            "Speed: 6.7ms preprocess, 509.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 225.1ms\n",
            "Speed: 6.5ms preprocess, 225.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 509.2ms\n",
            "Speed: 6.4ms preprocess, 509.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 215.2ms\n",
            "Speed: 5.9ms preprocess, 215.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 511.1ms\n",
            "Speed: 6.0ms preprocess, 511.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 217.7ms\n",
            "Speed: 5.8ms preprocess, 217.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 491.2ms\n",
            "Speed: 5.6ms preprocess, 491.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 226.6ms\n",
            "Speed: 6.1ms preprocess, 226.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 488.5ms\n",
            "Speed: 5.1ms preprocess, 488.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 237.0ms\n",
            "Speed: 6.5ms preprocess, 237.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 477.9ms\n",
            "Speed: 6.4ms preprocess, 477.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 218.9ms\n",
            "Speed: 6.6ms preprocess, 218.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 42 faces, 475.4ms\n",
            "Speed: 5.9ms preprocess, 475.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 224.9ms\n",
            "Speed: 6.3ms preprocess, 224.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 faces, 487.7ms\n",
            "Speed: 9.7ms preprocess, 487.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 267.1ms\n",
            "Speed: 7.0ms preprocess, 267.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 685.4ms\n",
            "Speed: 7.7ms preprocess, 685.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 293.8ms\n",
            "Speed: 9.2ms preprocess, 293.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 691.2ms\n",
            "Speed: 10.5ms preprocess, 691.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 304.4ms\n",
            "Speed: 9.2ms preprocess, 304.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 722.2ms\n",
            "Speed: 9.6ms preprocess, 722.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 314.0ms\n",
            "Speed: 10.4ms preprocess, 314.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 783.9ms\n",
            "Speed: 6.2ms preprocess, 783.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 274.2ms\n",
            "Speed: 7.2ms preprocess, 274.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 490.1ms\n",
            "Speed: 7.5ms preprocess, 490.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 233.6ms\n",
            "Speed: 6.5ms preprocess, 233.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 501.0ms\n",
            "Speed: 6.1ms preprocess, 501.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 220.7ms\n",
            "Speed: 6.9ms preprocess, 220.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 493.4ms\n",
            "Speed: 6.0ms preprocess, 493.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 233.0ms\n",
            "Speed: 6.6ms preprocess, 233.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 516.5ms\n",
            "Speed: 6.7ms preprocess, 516.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 217.2ms\n",
            "Speed: 6.7ms preprocess, 217.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 515.6ms\n",
            "Speed: 6.0ms preprocess, 515.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 223.0ms\n",
            "Speed: 6.1ms preprocess, 223.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 507.4ms\n",
            "Speed: 6.2ms preprocess, 507.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 213.2ms\n",
            "Speed: 7.9ms preprocess, 213.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 497.1ms\n",
            "Speed: 8.3ms preprocess, 497.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 224.4ms\n",
            "Speed: 6.1ms preprocess, 224.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 510.2ms\n",
            "Speed: 7.4ms preprocess, 510.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 188.1ms\n",
            "Speed: 6.4ms preprocess, 188.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 481.1ms\n",
            "Speed: 6.7ms preprocess, 481.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 236.2ms\n",
            "Speed: 7.4ms preprocess, 236.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 627.4ms\n",
            "Speed: 6.3ms preprocess, 627.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 259.6ms\n",
            "Speed: 6.1ms preprocess, 259.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 728.6ms\n",
            "Speed: 7.1ms preprocess, 728.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 312.0ms\n",
            "Speed: 8.0ms preprocess, 312.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 753.5ms\n",
            "Speed: 6.6ms preprocess, 753.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 337.0ms\n",
            "Speed: 7.4ms preprocess, 337.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 737.1ms\n",
            "Speed: 9.0ms preprocess, 737.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 324.3ms\n",
            "Speed: 7.4ms preprocess, 324.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 737.8ms\n",
            "Speed: 9.5ms preprocess, 737.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 314.8ms\n",
            "Speed: 6.7ms preprocess, 314.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 507.2ms\n",
            "Speed: 6.5ms preprocess, 507.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 208.0ms\n",
            "Speed: 5.5ms preprocess, 208.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 493.9ms\n",
            "Speed: 6.4ms preprocess, 493.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 231.8ms\n",
            "Speed: 6.5ms preprocess, 231.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 500.4ms\n",
            "Speed: 6.5ms preprocess, 500.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 235.9ms\n",
            "Speed: 7.6ms preprocess, 235.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 511.2ms\n",
            "Speed: 5.7ms preprocess, 511.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 227.6ms\n",
            "Speed: 9.9ms preprocess, 227.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 493.6ms\n",
            "Speed: 6.0ms preprocess, 493.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 230.3ms\n",
            "Speed: 6.9ms preprocess, 230.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 488.6ms\n",
            "Speed: 5.6ms preprocess, 488.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 239.2ms\n",
            "Speed: 6.9ms preprocess, 239.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 490.4ms\n",
            "Speed: 7.2ms preprocess, 490.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 222.0ms\n",
            "Speed: 7.6ms preprocess, 222.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 490.0ms\n",
            "Speed: 6.6ms preprocess, 490.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 229.1ms\n",
            "Speed: 8.2ms preprocess, 229.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 492.0ms\n",
            "Speed: 6.6ms preprocess, 492.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 225.6ms\n",
            "Speed: 7.2ms preprocess, 225.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 502.7ms\n",
            "Speed: 6.7ms preprocess, 502.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 297.7ms\n",
            "Speed: 7.5ms preprocess, 297.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 765.9ms\n",
            "Speed: 9.0ms preprocess, 765.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 312.0ms\n",
            "Speed: 6.3ms preprocess, 312.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 732.7ms\n",
            "Speed: 11.9ms preprocess, 732.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 362.6ms\n",
            "Speed: 9.4ms preprocess, 362.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 743.0ms\n",
            "Speed: 6.3ms preprocess, 743.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 318.7ms\n",
            "Speed: 7.0ms preprocess, 318.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 745.5ms\n",
            "Speed: 7.0ms preprocess, 745.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 233.0ms\n",
            "Speed: 7.4ms preprocess, 233.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 faces, 499.4ms\n",
            "Speed: 7.0ms preprocess, 499.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 229.0ms\n",
            "Speed: 7.4ms preprocess, 229.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 509.1ms\n",
            "Speed: 6.0ms preprocess, 509.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 220.8ms\n",
            "Speed: 6.7ms preprocess, 220.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 511.3ms\n",
            "Speed: 6.5ms preprocess, 511.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 221.0ms\n",
            "Speed: 7.4ms preprocess, 221.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 497.5ms\n",
            "Speed: 5.8ms preprocess, 497.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 215.6ms\n",
            "Speed: 6.7ms preprocess, 215.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 496.1ms\n",
            "Speed: 7.3ms preprocess, 496.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 241.4ms\n",
            "Speed: 7.0ms preprocess, 241.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 493.9ms\n",
            "Speed: 6.5ms preprocess, 493.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 241.8ms\n",
            "Speed: 8.2ms preprocess, 241.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 502.4ms\n",
            "Speed: 7.0ms preprocess, 502.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 244.8ms\n",
            "Speed: 7.1ms preprocess, 244.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 495.8ms\n",
            "Speed: 6.5ms preprocess, 495.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 227.7ms\n",
            "Speed: 8.3ms preprocess, 227.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 501.9ms\n",
            "Speed: 6.1ms preprocess, 501.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 670.2ms\n",
            "Speed: 16.2ms preprocess, 670.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 763.2ms\n",
            "Speed: 8.7ms preprocess, 763.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 321.1ms\n",
            "Speed: 9.0ms preprocess, 321.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 768.8ms\n",
            "Speed: 6.3ms preprocess, 768.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 324.2ms\n",
            "Speed: 6.6ms preprocess, 324.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 763.7ms\n",
            "Speed: 6.9ms preprocess, 763.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 318.6ms\n",
            "Speed: 6.5ms preprocess, 318.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 721.7ms\n",
            "Speed: 8.2ms preprocess, 721.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "âœ… All done. Check output folder for labeled images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final version deadend"
      ],
      "metadata": {
        "id": "NGoTsejQ1CqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Saif/img'\n",
        "\n",
        "output_folder = '/content/drive/MyDrive/Saif/percenttt'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "face_model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt')\n",
        "body_model = YOLO('yolov8n-pose.pt')  # body detection model\n",
        "\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=30,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "def unit_vector(v):\n",
        "    norm = np.linalg.norm(v)\n",
        "    if norm < 1e-6:\n",
        "        return None\n",
        "    return v / norm\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    dot = np.dot(v1, v2)\n",
        "    norm_prod = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "    if norm_prod < 1e-6:\n",
        "        return 0.0\n",
        "    return dot / norm_prod\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "\n",
        "    # Detect bodies\n",
        "    body_results = body_model(image)[0]\n",
        "    person_boxes = [b for b in body_results.boxes.data.cpu().numpy() if int(b[5]) == 0]\n",
        "\n",
        "    # Detect faces\n",
        "    face_results = face_model(image)[0]\n",
        "    boxes = face_results.boxes.xyxy.cpu().numpy().astype(int)\n",
        "\n",
        "    face_data = []\n",
        "\n",
        "    for (x1, y1, x2, y2) in boxes:\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "            # If no face landmarks detected, mark as Turned\n",
        "            face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1,\n",
        "                    'chin': 152,\n",
        "                    'left_eye_outer': 33,\n",
        "                    'right_eye_outer': 263,\n",
        "                    'left_forehead': 10,\n",
        "                    'mouth_left': 61,\n",
        "                    'mouth_right': 291\n",
        "                }\n",
        "\n",
        "                pts = {\n",
        "                    name: (landmark_to_point(landmarks.landmark[idx], face_crop.shape)[0] + x1m,\n",
        "                           landmark_to_point(landmarks.landmark[idx], face_crop.shape)[1] + y1m)\n",
        "                    for name, idx in points_ids.items()\n",
        "                }\n",
        "\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                if norm < 1e-6:\n",
        "                    # Unable to calculate gaze vector - consider engaged by default\n",
        "                    gaze_vec = None\n",
        "                else:\n",
        "                    gaze_vec = avg_dir / norm\n",
        "\n",
        "                nose_extended = (p_nose + gaze_vec * 190).astype(int) if gaze_vec is not None else p_nose\n",
        "\n",
        "                line_colors = {\n",
        "                    'left_forehead': (0, 255, 255),\n",
        "                    'chin': (255, 0, 0),\n",
        "                    'left_eye_outer': (0, 0, 255),\n",
        "                    'right_eye_outer': (255, 255, 0),\n",
        "                    'mouth_left': (255, 0, 255),\n",
        "                    'mouth_right': (0, 165, 255)\n",
        "                }\n",
        "                for key, color in line_colors.items():\n",
        "                    if gaze_vec is not None:\n",
        "                        cv2.line(image, pts[key], tuple(nose_extended), color, 2)\n",
        "                for pt in pts.values():\n",
        "                    cv2.circle(image, pt, 3, (0, 0, 255), -1)\n",
        "                if gaze_vec is not None:\n",
        "                    cv2.circle(image, tuple(nose_extended), 4, (0, 0, 255), -1)\n",
        "\n",
        "                face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "                face_data.append({'center': face_center, 'label': 'Engaged', 'gaze_vector': gaze_vec, 'engagement_percent': None})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Error in {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Calculate consensus gaze vector using average of non-None gaze vectors\n",
        "    valid_gaze_vectors = [f['gaze_vector'] for f in face_data if f['gaze_vector'] is not None]\n",
        "\n",
        "    if valid_gaze_vectors:\n",
        "        # Calculate mean gaze vector\n",
        "        mean_gaze = np.mean(valid_gaze_vectors, axis=0)\n",
        "        mean_gaze /= np.linalg.norm(mean_gaze)\n",
        "\n",
        "        # Compute cosine similarity of each gaze to mean gaze\n",
        "        for f in face_data:\n",
        "            gv = f['gaze_vector']\n",
        "            if gv is not None:\n",
        "                similarity = cosine_similarity(gv, mean_gaze)\n",
        "                percent = int(similarity * 100)\n",
        "                f['engagement_percent'] = percent\n",
        "                # Threshold for engaged vs distracted\n",
        "                if similarity < 0.5:\n",
        "                    f['label'] = 'Distracted'\n",
        "                else:\n",
        "                    f['label'] = 'Engaged'\n",
        "            else:\n",
        "                f['engagement_percent'] = None\n",
        "    else:\n",
        "        # No valid gaze vectors: mark all as None\n",
        "        for f in face_data:\n",
        "            f['engagement_percent'] = None\n",
        "\n",
        "    # Draw body boxes and labels (only if label != 'Unknown')\n",
        "    for body in person_boxes:\n",
        "        x1, y1, x2, y2, _, _ = map(int, body[:6])\n",
        "        body_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "\n",
        "        closest_face = None\n",
        "        min_dist = float('inf')\n",
        "        for face in face_data:\n",
        "            fx, fy = face['center']\n",
        "            dist = np.linalg.norm(np.array([fx, fy]) - np.array(body_center))\n",
        "            if dist < min_dist and dist < 150:\n",
        "                min_dist = dist\n",
        "                closest_face = face\n",
        "\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (100, 200, 100), 2)\n",
        "\n",
        "        if closest_face is not None:\n",
        "            label = closest_face['label']\n",
        "            percent = closest_face.get('engagement_percent', None)\n",
        "            if percent is not None:\n",
        "                text = f\"{label}: {percent}%\"\n",
        "            else:\n",
        "                text = f\"{label}: .\"\n",
        "\n",
        "            if label != \"Unknown\":\n",
        "                cv2.putText(image, text, (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 200, 100), 2)\n",
        "\n",
        "    cv2.imwrite(os.path.join(output_folder, filename), image)\n",
        "\n",
        "print(\"âœ… Done. Improved gaze detection with cosine similarity, thresholding, and engagement percentages.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3FTLL401Gil",
        "outputId": "2374382f-2bd3-4d4e-c83c-ed6afc4cf6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 12 persons, 253.0ms\n",
            "Speed: 12.0ms preprocess, 253.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 19 faces, 512.6ms\n",
            "Speed: 5.4ms preprocess, 512.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 persons, 200.2ms\n",
            "Speed: 5.8ms preprocess, 200.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 14 faces, 471.1ms\n",
            "Speed: 5.4ms preprocess, 471.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 6 persons, 203.7ms\n",
            "Speed: 5.5ms preprocess, 203.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 7 faces, 478.3ms\n",
            "Speed: 5.9ms preprocess, 478.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 13 persons, 198.4ms\n",
            "Speed: 6.3ms preprocess, 198.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 21 faces, 500.1ms\n",
            "Speed: 4.9ms preprocess, 500.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 16 persons, 199.5ms\n",
            "Speed: 5.4ms preprocess, 199.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 18 faces, 491.4ms\n",
            "Speed: 7.1ms preprocess, 491.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 6 persons, 213.6ms\n",
            "Speed: 5.6ms preprocess, 213.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 15 faces, 542.6ms\n",
            "Speed: 4.8ms preprocess, 542.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 384x640 8 persons, 329.6ms\n",
            "Speed: 4.6ms preprocess, 329.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 faces, 665.0ms\n",
            "Speed: 4.8ms preprocess, 665.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 246.4ms\n",
            "Speed: 4.8ms preprocess, 246.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 faces, 635.8ms\n",
            "Speed: 4.2ms preprocess, 635.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 249.2ms\n",
            "Speed: 4.5ms preprocess, 249.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 636.7ms\n",
            "Speed: 7.5ms preprocess, 636.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 209.1ms\n",
            "Speed: 5.8ms preprocess, 209.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 393.1ms\n",
            "Speed: 4.3ms preprocess, 393.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 178.3ms\n",
            "Speed: 8.5ms preprocess, 178.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 388.2ms\n",
            "Speed: 4.4ms preprocess, 388.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 165.7ms\n",
            "Speed: 4.4ms preprocess, 165.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 489.2ms\n",
            "Speed: 4.6ms preprocess, 489.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 183.8ms\n",
            "Speed: 6.8ms preprocess, 183.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 402.7ms\n",
            "Speed: 4.6ms preprocess, 402.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 180.7ms\n",
            "Speed: 4.7ms preprocess, 180.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 414.6ms\n",
            "Speed: 4.4ms preprocess, 414.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 162.7ms\n",
            "Speed: 4.4ms preprocess, 162.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 408.4ms\n",
            "Speed: 4.4ms preprocess, 408.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 169.8ms\n",
            "Speed: 4.6ms preprocess, 169.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 422.8ms\n",
            "Speed: 4.9ms preprocess, 422.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 165.2ms\n",
            "Speed: 4.6ms preprocess, 165.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 391.8ms\n",
            "Speed: 4.1ms preprocess, 391.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 163.6ms\n",
            "Speed: 4.4ms preprocess, 163.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 394.1ms\n",
            "Speed: 4.5ms preprocess, 394.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 160.4ms\n",
            "Speed: 4.3ms preprocess, 160.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 417.1ms\n",
            "Speed: 5.6ms preprocess, 417.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 171.9ms\n",
            "Speed: 4.9ms preprocess, 171.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 394.9ms\n",
            "Speed: 5.4ms preprocess, 394.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 162.1ms\n",
            "Speed: 4.5ms preprocess, 162.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 403.9ms\n",
            "Speed: 5.5ms preprocess, 403.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 166.5ms\n",
            "Speed: 4.5ms preprocess, 166.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 570.1ms\n",
            "Speed: 4.4ms preprocess, 570.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 249.3ms\n",
            "Speed: 4.5ms preprocess, 249.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 634.5ms\n",
            "Speed: 8.3ms preprocess, 634.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 253.5ms\n",
            "Speed: 5.2ms preprocess, 253.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 614.8ms\n",
            "Speed: 4.3ms preprocess, 614.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 258.2ms\n",
            "Speed: 6.7ms preprocess, 258.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 42 faces, 627.5ms\n",
            "Speed: 4.3ms preprocess, 627.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 268.4ms\n",
            "Speed: 4.7ms preprocess, 268.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 faces, 450.9ms\n",
            "Speed: 5.4ms preprocess, 450.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 187.3ms\n",
            "Speed: 4.2ms preprocess, 187.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 402.7ms\n",
            "Speed: 4.1ms preprocess, 402.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 160.4ms\n",
            "Speed: 4.2ms preprocess, 160.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 422.2ms\n",
            "Speed: 4.4ms preprocess, 422.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 173.1ms\n",
            "Speed: 4.5ms preprocess, 173.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 392.3ms\n",
            "Speed: 4.7ms preprocess, 392.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 206.4ms\n",
            "Speed: 4.4ms preprocess, 206.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 397.2ms\n",
            "Speed: 4.7ms preprocess, 397.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 193.5ms\n",
            "Speed: 3.4ms preprocess, 193.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 395.0ms\n",
            "Speed: 4.5ms preprocess, 395.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 171.3ms\n",
            "Speed: 4.7ms preprocess, 171.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 412.7ms\n",
            "Speed: 4.4ms preprocess, 412.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 177.1ms\n",
            "Speed: 4.4ms preprocess, 177.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 415.3ms\n",
            "Speed: 5.2ms preprocess, 415.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 161.9ms\n",
            "Speed: 4.4ms preprocess, 161.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 395.4ms\n",
            "Speed: 4.3ms preprocess, 395.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 198.7ms\n",
            "Speed: 4.2ms preprocess, 198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 402.1ms\n",
            "Speed: 5.6ms preprocess, 402.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 169.9ms\n",
            "Speed: 4.3ms preprocess, 169.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 408.8ms\n",
            "Speed: 5.0ms preprocess, 408.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 176.0ms\n",
            "Speed: 4.7ms preprocess, 176.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 417.4ms\n",
            "Speed: 3.3ms preprocess, 417.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 169.9ms\n",
            "Speed: 4.6ms preprocess, 169.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 421.6ms\n",
            "Speed: 4.7ms preprocess, 421.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 278.4ms\n",
            "Speed: 5.8ms preprocess, 278.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 600.1ms\n",
            "Speed: 6.0ms preprocess, 600.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 264.6ms\n",
            "Speed: 4.4ms preprocess, 264.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 614.8ms\n",
            "Speed: 4.4ms preprocess, 614.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 258.5ms\n",
            "Speed: 4.3ms preprocess, 258.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 604.8ms\n",
            "Speed: 5.1ms preprocess, 604.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 284.4ms\n",
            "Speed: 4.5ms preprocess, 284.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 578.3ms\n",
            "Speed: 4.5ms preprocess, 578.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 168.7ms\n",
            "Speed: 4.4ms preprocess, 168.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 392.2ms\n",
            "Speed: 4.6ms preprocess, 392.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 160.7ms\n",
            "Speed: 4.7ms preprocess, 160.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 390.7ms\n",
            "Speed: 4.7ms preprocess, 390.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 163.2ms\n",
            "Speed: 4.6ms preprocess, 163.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 402.4ms\n",
            "Speed: 5.1ms preprocess, 402.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 162.9ms\n",
            "Speed: 4.3ms preprocess, 162.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 413.5ms\n",
            "Speed: 4.4ms preprocess, 413.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 163.7ms\n",
            "Speed: 4.6ms preprocess, 163.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 389.8ms\n",
            "Speed: 5.1ms preprocess, 389.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 165.2ms\n",
            "Speed: 5.3ms preprocess, 165.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 387.9ms\n",
            "Speed: 4.4ms preprocess, 387.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 166.4ms\n",
            "Speed: 4.4ms preprocess, 166.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 406.8ms\n",
            "Speed: 4.3ms preprocess, 406.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 165.8ms\n",
            "Speed: 4.7ms preprocess, 165.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 419.5ms\n",
            "Speed: 5.0ms preprocess, 419.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 164.9ms\n",
            "Speed: 4.6ms preprocess, 164.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 402.6ms\n",
            "Speed: 4.8ms preprocess, 402.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 176.5ms\n",
            "Speed: 4.3ms preprocess, 176.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 391.8ms\n",
            "Speed: 7.1ms preprocess, 391.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 160.1ms\n",
            "Speed: 4.3ms preprocess, 160.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 413.6ms\n",
            "Speed: 3.9ms preprocess, 413.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 165.4ms\n",
            "Speed: 4.4ms preprocess, 165.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 401.2ms\n",
            "Speed: 4.7ms preprocess, 401.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 178.5ms\n",
            "Speed: 4.9ms preprocess, 178.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 493.6ms\n",
            "Speed: 4.8ms preprocess, 493.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 255.0ms\n",
            "Speed: 4.4ms preprocess, 255.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 616.5ms\n",
            "Speed: 4.6ms preprocess, 616.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 262.1ms\n",
            "Speed: 4.4ms preprocess, 262.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 621.2ms\n",
            "Speed: 4.5ms preprocess, 621.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 248.3ms\n",
            "Speed: 4.4ms preprocess, 248.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 622.0ms\n",
            "Speed: 6.8ms preprocess, 622.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 260.2ms\n",
            "Speed: 5.9ms preprocess, 260.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 465.6ms\n",
            "Speed: 4.7ms preprocess, 465.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 164.3ms\n",
            "Speed: 4.6ms preprocess, 164.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 406.2ms\n",
            "Speed: 4.6ms preprocess, 406.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 203.9ms\n",
            "Speed: 5.8ms preprocess, 203.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 433.4ms\n",
            "Speed: 5.5ms preprocess, 433.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 164.2ms\n",
            "Speed: 5.7ms preprocess, 164.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 424.2ms\n",
            "Speed: 4.9ms preprocess, 424.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 175.3ms\n",
            "Speed: 6.1ms preprocess, 175.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 408.7ms\n",
            "Speed: 5.4ms preprocess, 408.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 190.4ms\n",
            "Speed: 5.0ms preprocess, 190.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 425.7ms\n",
            "Speed: 5.0ms preprocess, 425.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 172.5ms\n",
            "Speed: 5.2ms preprocess, 172.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 429.0ms\n",
            "Speed: 5.4ms preprocess, 429.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 178.0ms\n",
            "Speed: 5.1ms preprocess, 178.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 445.5ms\n",
            "Speed: 4.6ms preprocess, 445.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 280.4ms\n",
            "Speed: 4.6ms preprocess, 280.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 faces, 627.8ms\n",
            "Speed: 7.5ms preprocess, 627.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 276.9ms\n",
            "Speed: 5.4ms preprocess, 276.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 632.5ms\n",
            "Speed: 4.3ms preprocess, 632.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 276.4ms\n",
            "Speed: 5.0ms preprocess, 276.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 488.9ms\n",
            "Speed: 4.4ms preprocess, 488.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 169.4ms\n",
            "Speed: 4.8ms preprocess, 169.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 471.9ms\n",
            "Speed: 5.4ms preprocess, 471.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 177.1ms\n",
            "Speed: 5.1ms preprocess, 177.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 422.6ms\n",
            "Speed: 4.5ms preprocess, 422.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 166.6ms\n",
            "Speed: 5.6ms preprocess, 166.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 425.2ms\n",
            "Speed: 4.9ms preprocess, 425.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 175.8ms\n",
            "Speed: 4.5ms preprocess, 175.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 392.3ms\n",
            "Speed: 3.9ms preprocess, 392.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "âœ… Done. Improved gaze detection with cosine similarity, thresholding, and engagement percentages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This version with 5 class to label dataset 23 july morning"
      ],
      "metadata": {
        "id": "85OUfgL6jnuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "input_folder = '/content/drive/MyDrive/Dataset/images/val'\n",
        "output_folder = '/content/drive/MyDrive/Dataset/labels/val'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "face_model = YOLO('/content/drive/MyDrive/Saif/yolov8s-face-lindevs.pt', verbose=False)\n",
        "body_model = YOLO('yolov8n-pose.pt', verbose=False)\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=30,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5\n",
        ")\n",
        "\n",
        "def landmark_to_point(landmark, shape):\n",
        "    h, w = shape[:2]\n",
        "    return int(landmark.x * w), int(landmark.y * h)\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    if v1 is None or v2 is None:\n",
        "        return 0.0\n",
        "    dot = np.dot(v1, v2)\n",
        "    norm_prod = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "    return dot / norm_prod if norm_prod > 1e-6 else 0.0\n",
        "\n",
        "MIN_FACE_HEIGHT_FOR_DETAILED = 70\n",
        "MIN_FACE_WIDTH_FOR_DETAILED = 50\n",
        "SLEEPY_EYE_RATIO_THRESH = 0.01\n",
        "TALKING_MOUTH_RATIO_THRESH = 2.8\n",
        "GAZE_SIMILARITY_THRESH = 0.4\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_folder, filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    orig_h, orig_w = image.shape[:2]\n",
        "    body_results = body_model(image)[0]\n",
        "    person_boxes = [b for b in body_results.boxes.data.cpu().numpy() if int(b[5]) == 0]\n",
        "\n",
        "    face_results = face_model(image)[0]\n",
        "    boxes = face_results.boxes.xyxy.cpu().numpy().astype(int)\n",
        "    face_data = []\n",
        "\n",
        "    for (x1, y1, x2, y2) in boxes:\n",
        "        margin = 20\n",
        "        x1m = max(0, x1 - margin)\n",
        "        y1m = max(0, y1 - margin)\n",
        "        x2m = min(orig_w, x2 + margin)\n",
        "        y2m = min(orig_h, y2 + margin)\n",
        "\n",
        "        face_crop = image[y1m:y2m, x1m:x2m]\n",
        "        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
        "        mp_results = face_mesh.process(face_rgb)\n",
        "\n",
        "        face_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "        face_w, face_h = x2 - x1, y2 - y1\n",
        "\n",
        "        if not mp_results.multi_face_landmarks:\n",
        "            face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "            continue\n",
        "\n",
        "        for landmarks in mp_results.multi_face_landmarks:\n",
        "            try:\n",
        "                points_ids = {\n",
        "                    'nose_tip': 1, 'chin': 152,\n",
        "                    'left_eye_outer': 33, 'right_eye_outer': 263,\n",
        "                    'left_forehead': 10, 'mouth_left': 61,\n",
        "                    'mouth_right': 291, 'left_eye_top': 159,\n",
        "                    'left_eye_bottom': 145, 'right_eye_top': 386,\n",
        "                    'right_eye_bottom': 374\n",
        "                }\n",
        "\n",
        "                pts = {\n",
        "                    name: (landmark_to_point(landmarks.landmark[idx], face_crop.shape)[0] + x1m,\n",
        "                           landmark_to_point(landmarks.landmark[idx], face_crop.shape)[1] + y1m)\n",
        "                    for name, idx in points_ids.items()\n",
        "                }\n",
        "\n",
        "                p_nose = np.array(pts['nose_tip'])\n",
        "                direction_vectors = [p_nose - np.array(pts[key]) for key in\n",
        "                                     ['chin', 'left_eye_outer', 'right_eye_outer', 'mouth_left', 'mouth_right']]\n",
        "                avg_dir = np.mean(direction_vectors, axis=0)\n",
        "                norm = np.linalg.norm(avg_dir)\n",
        "                gaze_vec = avg_dir / norm if norm > 1e-6 else None\n",
        "\n",
        "                def eye_ratio_calc():\n",
        "                    left_eye_h = np.linalg.norm(np.array(pts['left_eye_top']) - np.array(pts['left_eye_bottom']))\n",
        "                    left_eye_w = np.linalg.norm(np.array(pts['left_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    right_eye_h = np.linalg.norm(np.array(pts['right_eye_top']) - np.array(pts['right_eye_bottom']))\n",
        "                    right_eye_w = np.linalg.norm(np.array(pts['right_eye_outer']) - np.array(pts['left_forehead']))\n",
        "                    left_ratio = left_eye_h / left_eye_w if left_eye_w > 1e-6 else 0\n",
        "                    right_ratio = right_eye_h / right_eye_w if right_eye_w > 1e-6 else 0\n",
        "                    return (left_ratio + right_ratio) / 2\n",
        "\n",
        "                eye_ratio = eye_ratio_calc()\n",
        "                mouth_w = np.linalg.norm(np.array(pts['mouth_right']) - np.array(pts['mouth_left']))\n",
        "                mouth_h = np.linalg.norm(np.array(pts['chin']) - np.array(pts['nose_tip']))\n",
        "                mouth_ratio = mouth_h / mouth_w if mouth_w > 1e-6 else 0\n",
        "\n",
        "                face_data.append({\n",
        "                    'center': face_center, 'label': 'Unknown', 'gaze_vector': gaze_vec,\n",
        "                    'engagement_percent': None,\n",
        "                    'eye_ratio': eye_ratio, 'mouth_ratio': mouth_ratio,\n",
        "                    'face_w': face_w, 'face_h': face_h\n",
        "                })\n",
        "\n",
        "            except:\n",
        "                face_data.append({'center': face_center, 'label': 'Turned', 'gaze_vector': None, 'engagement_percent': None})\n",
        "                continue\n",
        "\n",
        "    valid_gaze_vectors = [f['gaze_vector'] for f in face_data if f['gaze_vector'] is not None]\n",
        "    if valid_gaze_vectors:\n",
        "        mean_gaze = np.mean(valid_gaze_vectors, axis=0)\n",
        "        mean_gaze /= np.linalg.norm(mean_gaze)\n",
        "\n",
        "        for f in face_data:\n",
        "            gv = f['gaze_vector']\n",
        "            if gv is not None:\n",
        "                similarity = cosine_similarity(gv, mean_gaze)\n",
        "                percent = int(similarity * 100)\n",
        "                f['engagement_percent'] = percent\n",
        "\n",
        "                if f['face_w'] < MIN_FACE_WIDTH_FOR_DETAILED or f['face_h'] < MIN_FACE_HEIGHT_FOR_DETAILED:\n",
        "                    f['label'] = 'Engaged' if similarity >= GAZE_SIMILARITY_THRESH else 'Distracted'\n",
        "                else:\n",
        "                    if f['eye_ratio'] < SLEEPY_EYE_RATIO_THRESH:\n",
        "                        f['label'] = 'Sleepy'\n",
        "                    elif f['mouth_ratio'] > TALKING_MOUTH_RATIO_THRESH:\n",
        "                        f['label'] = 'Talking'\n",
        "                    elif similarity < GAZE_SIMILARITY_THRESH:\n",
        "                        f['label'] = 'Distracted'\n",
        "                    else:\n",
        "                        f['label'] = 'Engaged'\n",
        "            else:\n",
        "                f['engagement_percent'] = None\n",
        "                f['label'] = 'Turned'\n",
        "    else:\n",
        "        for f in face_data:\n",
        "            f['engagement_percent'] = None\n",
        "            f['label'] = 'Turned'\n",
        "\n",
        "    # Save YOLO label file\n",
        "    txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    txt_path = os.path.join(output_folder, txt_filename)\n",
        "    with open(txt_path, 'w') as f:\n",
        "        for body in person_boxes:\n",
        "            x1, y1, x2, y2, _, _ = map(int, body[:6])\n",
        "            body_center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "\n",
        "            closest_face = None\n",
        "            min_dist = float('inf')\n",
        "            for face in face_data:\n",
        "                fx, fy = face['center']\n",
        "                dist = np.linalg.norm(np.array([fx, fy]) - np.array(body_center))\n",
        "                if dist < min_dist and dist < 150:\n",
        "                    min_dist = dist\n",
        "                    closest_face = face\n",
        "\n",
        "            if closest_face:\n",
        "                label = closest_face['label']\n",
        "                class_id = {'Engaged': 0, 'Distracted': 1, 'Talking': 2, 'Sleepy': 3, 'Turned': 4}.get(label, 4)\n",
        "\n",
        "                xc = (x1 + x2) / 2 / orig_w\n",
        "                yc = (y1 + y2) / 2 / orig_h\n",
        "                w = (x2 - x1) / orig_w\n",
        "                h = (y2 - y1) / orig_h\n",
        "\n",
        "                f.write(f\"{class_id} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "print(\"âœ… Label .txt files saved for all images in output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mG7G444jwht",
        "outputId": "432907e0-ea75-4573-8bcb-a241b160c223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 351.5ms\n",
            "Speed: 10.5ms preprocess, 351.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 767.8ms\n",
            "Speed: 8.3ms preprocess, 767.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 311.8ms\n",
            "Speed: 7.3ms preprocess, 311.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 721.3ms\n",
            "Speed: 9.4ms preprocess, 721.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 232.0ms\n",
            "Speed: 6.8ms preprocess, 232.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 500.3ms\n",
            "Speed: 5.5ms preprocess, 500.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 215.0ms\n",
            "Speed: 6.0ms preprocess, 215.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 507.8ms\n",
            "Speed: 6.3ms preprocess, 507.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1598.2ms\n",
            "Speed: 9.0ms preprocess, 1598.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 2790.7ms\n",
            "Speed: 116.4ms preprocess, 2790.7ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 327.7ms\n",
            "Speed: 6.2ms preprocess, 327.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 769.4ms\n",
            "Speed: 8.9ms preprocess, 769.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 355.7ms\n",
            "Speed: 7.4ms preprocess, 355.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 725.0ms\n",
            "Speed: 8.7ms preprocess, 725.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 316.7ms\n",
            "Speed: 6.6ms preprocess, 316.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 665.0ms\n",
            "Speed: 6.0ms preprocess, 665.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 246.2ms\n",
            "Speed: 5.6ms preprocess, 246.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 496.8ms\n",
            "Speed: 6.2ms preprocess, 496.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 226.1ms\n",
            "Speed: 7.0ms preprocess, 226.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 485.2ms\n",
            "Speed: 6.0ms preprocess, 485.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 213.0ms\n",
            "Speed: 5.7ms preprocess, 213.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 499.4ms\n",
            "Speed: 7.4ms preprocess, 499.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 216.2ms\n",
            "Speed: 5.5ms preprocess, 216.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 481.2ms\n",
            "Speed: 6.6ms preprocess, 481.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 225.7ms\n",
            "Speed: 7.0ms preprocess, 225.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 488.9ms\n",
            "Speed: 7.3ms preprocess, 488.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 216.6ms\n",
            "Speed: 8.8ms preprocess, 216.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 588.4ms\n",
            "Speed: 6.2ms preprocess, 588.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 201.6ms\n",
            "Speed: 5.5ms preprocess, 201.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 486.8ms\n",
            "Speed: 6.7ms preprocess, 486.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 239.2ms\n",
            "Speed: 7.0ms preprocess, 239.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 480.3ms\n",
            "Speed: 6.9ms preprocess, 480.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 243.2ms\n",
            "Speed: 6.2ms preprocess, 243.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 487.7ms\n",
            "Speed: 7.7ms preprocess, 487.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 221.5ms\n",
            "Speed: 6.8ms preprocess, 221.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 500.3ms\n",
            "Speed: 7.0ms preprocess, 500.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 317.8ms\n",
            "Speed: 8.1ms preprocess, 317.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 737.5ms\n",
            "Speed: 11.6ms preprocess, 737.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 312.4ms\n",
            "Speed: 10.3ms preprocess, 312.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 735.1ms\n",
            "Speed: 6.1ms preprocess, 735.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 319.2ms\n",
            "Speed: 12.4ms preprocess, 319.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 754.6ms\n",
            "Speed: 9.0ms preprocess, 754.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 333.3ms\n",
            "Speed: 8.8ms preprocess, 333.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 706.5ms\n",
            "Speed: 7.2ms preprocess, 706.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 316.3ms\n",
            "Speed: 6.1ms preprocess, 316.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 740.5ms\n",
            "Speed: 10.3ms preprocess, 740.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 215.8ms\n",
            "Speed: 6.2ms preprocess, 215.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 471.1ms\n",
            "Speed: 6.7ms preprocess, 471.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 221.4ms\n",
            "Speed: 7.5ms preprocess, 221.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 480.8ms\n",
            "Speed: 6.3ms preprocess, 480.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 234.3ms\n",
            "Speed: 8.1ms preprocess, 234.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 484.7ms\n",
            "Speed: 6.6ms preprocess, 484.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 238.0ms\n",
            "Speed: 7.0ms preprocess, 238.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 496.0ms\n",
            "Speed: 6.1ms preprocess, 496.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 200.8ms\n",
            "Speed: 5.8ms preprocess, 200.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 506.1ms\n",
            "Speed: 5.7ms preprocess, 506.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 215.9ms\n",
            "Speed: 6.1ms preprocess, 215.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 507.6ms\n",
            "Speed: 6.1ms preprocess, 507.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 214.4ms\n",
            "Speed: 6.5ms preprocess, 214.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 513.5ms\n",
            "Speed: 5.6ms preprocess, 513.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 211.8ms\n",
            "Speed: 6.6ms preprocess, 211.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 499.3ms\n",
            "Speed: 6.2ms preprocess, 499.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 225.7ms\n",
            "Speed: 6.7ms preprocess, 225.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 492.5ms\n",
            "Speed: 10.4ms preprocess, 492.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 220.7ms\n",
            "Speed: 6.7ms preprocess, 220.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 484.3ms\n",
            "Speed: 5.9ms preprocess, 484.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 237.3ms\n",
            "Speed: 6.0ms preprocess, 237.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 496.9ms\n",
            "Speed: 7.2ms preprocess, 496.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 314.9ms\n",
            "Speed: 6.5ms preprocess, 314.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 708.5ms\n",
            "Speed: 10.8ms preprocess, 708.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 330.4ms\n",
            "Speed: 8.4ms preprocess, 330.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 737.9ms\n",
            "Speed: 5.9ms preprocess, 737.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 303.7ms\n",
            "Speed: 9.5ms preprocess, 303.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 728.3ms\n",
            "Speed: 9.6ms preprocess, 728.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 318.7ms\n",
            "Speed: 6.0ms preprocess, 318.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 711.4ms\n",
            "Speed: 6.3ms preprocess, 711.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 293.9ms\n",
            "Speed: 7.9ms preprocess, 293.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 697.7ms\n",
            "Speed: 6.0ms preprocess, 697.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 217.3ms\n",
            "Speed: 6.9ms preprocess, 217.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 486.7ms\n",
            "Speed: 7.2ms preprocess, 486.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 200.3ms\n",
            "Speed: 6.0ms preprocess, 200.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 478.8ms\n",
            "Speed: 5.9ms preprocess, 478.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 214.1ms\n",
            "Speed: 5.9ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 532.2ms\n",
            "Speed: 6.9ms preprocess, 532.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 192.8ms\n",
            "Speed: 6.6ms preprocess, 192.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 461.5ms\n",
            "Speed: 5.0ms preprocess, 461.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 211.4ms\n",
            "Speed: 6.6ms preprocess, 211.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 468.8ms\n",
            "Speed: 8.1ms preprocess, 468.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 246.0ms\n",
            "Speed: 6.7ms preprocess, 246.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 467.5ms\n",
            "Speed: 6.2ms preprocess, 467.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 188.2ms\n",
            "Speed: 6.3ms preprocess, 188.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 468.3ms\n",
            "Speed: 6.2ms preprocess, 468.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 218.8ms\n",
            "Speed: 6.4ms preprocess, 218.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 502.8ms\n",
            "Speed: 6.6ms preprocess, 502.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 216.9ms\n",
            "Speed: 6.6ms preprocess, 216.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 506.8ms\n",
            "Speed: 8.3ms preprocess, 506.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 216.3ms\n",
            "Speed: 8.0ms preprocess, 216.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 503.7ms\n",
            "Speed: 6.3ms preprocess, 503.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 215.2ms\n",
            "Speed: 6.8ms preprocess, 215.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 650.9ms\n",
            "Speed: 7.5ms preprocess, 650.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 322.6ms\n",
            "Speed: 6.4ms preprocess, 322.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 713.7ms\n",
            "Speed: 10.4ms preprocess, 713.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 301.5ms\n",
            "Speed: 8.1ms preprocess, 301.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 734.1ms\n",
            "Speed: 7.2ms preprocess, 734.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 319.0ms\n",
            "Speed: 6.4ms preprocess, 319.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 735.6ms\n",
            "Speed: 11.0ms preprocess, 735.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 352.0ms\n",
            "Speed: 6.4ms preprocess, 352.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 721.6ms\n",
            "Speed: 7.8ms preprocess, 721.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 238.6ms\n",
            "Speed: 7.1ms preprocess, 238.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 485.8ms\n",
            "Speed: 7.9ms preprocess, 485.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 225.7ms\n",
            "Speed: 6.5ms preprocess, 225.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 476.5ms\n",
            "Speed: 7.1ms preprocess, 476.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 229.7ms\n",
            "Speed: 6.5ms preprocess, 229.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 483.8ms\n",
            "Speed: 10.4ms preprocess, 483.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 205.8ms\n",
            "Speed: 6.8ms preprocess, 205.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 513.9ms\n",
            "Speed: 9.7ms preprocess, 513.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 212.4ms\n",
            "Speed: 6.4ms preprocess, 212.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 507.3ms\n",
            "Speed: 6.4ms preprocess, 507.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 219.4ms\n",
            "Speed: 7.1ms preprocess, 219.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 504.4ms\n",
            "Speed: 5.7ms preprocess, 504.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 226.5ms\n",
            "Speed: 7.5ms preprocess, 226.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 520.1ms\n",
            "Speed: 6.5ms preprocess, 520.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 240.4ms\n",
            "Speed: 7.4ms preprocess, 240.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 481.6ms\n",
            "Speed: 7.7ms preprocess, 481.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 219.9ms\n",
            "Speed: 6.4ms preprocess, 219.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 495.0ms\n",
            "Speed: 6.8ms preprocess, 495.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 223.2ms\n",
            "Speed: 6.5ms preprocess, 223.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 563.8ms\n",
            "Speed: 6.7ms preprocess, 563.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 328.5ms\n",
            "Speed: 14.8ms preprocess, 328.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 729.3ms\n",
            "Speed: 8.6ms preprocess, 729.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 300.7ms\n",
            "Speed: 9.2ms preprocess, 300.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 faces, 728.2ms\n",
            "Speed: 6.0ms preprocess, 728.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 305.3ms\n",
            "Speed: 6.5ms preprocess, 305.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 714.7ms\n",
            "Speed: 13.7ms preprocess, 714.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 316.2ms\n",
            "Speed: 7.1ms preprocess, 316.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 730.8ms\n",
            "Speed: 13.0ms preprocess, 730.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 242.9ms\n",
            "Speed: 6.3ms preprocess, 242.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 483.6ms\n",
            "Speed: 6.2ms preprocess, 483.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 217.4ms\n",
            "Speed: 6.6ms preprocess, 217.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 489.6ms\n",
            "Speed: 8.3ms preprocess, 489.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 232.4ms\n",
            "Speed: 8.5ms preprocess, 232.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 498.4ms\n",
            "Speed: 8.7ms preprocess, 498.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 212.7ms\n",
            "Speed: 6.3ms preprocess, 212.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 493.8ms\n",
            "Speed: 6.2ms preprocess, 493.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 208.9ms\n",
            "Speed: 6.9ms preprocess, 208.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 faces, 486.6ms\n",
            "Speed: 7.8ms preprocess, 486.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 213.3ms\n",
            "Speed: 7.0ms preprocess, 213.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 509.4ms\n",
            "Speed: 8.2ms preprocess, 509.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 214.2ms\n",
            "Speed: 6.8ms preprocess, 214.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 496.3ms\n",
            "Speed: 6.0ms preprocess, 496.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 219.7ms\n",
            "Speed: 7.8ms preprocess, 219.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 faces, 489.6ms\n",
            "Speed: 6.8ms preprocess, 489.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 214.8ms\n",
            "Speed: 7.1ms preprocess, 214.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 480.7ms\n",
            "Speed: 7.6ms preprocess, 480.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 223.8ms\n",
            "Speed: 5.9ms preprocess, 223.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 481.8ms\n",
            "Speed: 5.9ms preprocess, 481.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 228.3ms\n",
            "Speed: 7.3ms preprocess, 228.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 1421.7ms\n",
            "Speed: 6.8ms preprocess, 1421.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 340.8ms\n",
            "Speed: 9.8ms preprocess, 340.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 700.8ms\n",
            "Speed: 8.5ms preprocess, 700.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 306.9ms\n",
            "Speed: 6.9ms preprocess, 306.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 746.1ms\n",
            "Speed: 10.8ms preprocess, 746.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 311.0ms\n",
            "Speed: 6.3ms preprocess, 311.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 732.9ms\n",
            "Speed: 11.5ms preprocess, 732.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 265.9ms\n",
            "Speed: 7.4ms preprocess, 265.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 510.0ms\n",
            "Speed: 6.0ms preprocess, 510.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 217.0ms\n",
            "Speed: 6.3ms preprocess, 217.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 504.3ms\n",
            "Speed: 6.5ms preprocess, 504.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 214.9ms\n",
            "Speed: 7.0ms preprocess, 214.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 500.0ms\n",
            "Speed: 5.9ms preprocess, 500.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 210.8ms\n",
            "Speed: 7.4ms preprocess, 210.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 510.2ms\n",
            "Speed: 5.7ms preprocess, 510.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 217.6ms\n",
            "Speed: 6.5ms preprocess, 217.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 497.7ms\n",
            "Speed: 8.4ms preprocess, 497.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 222.2ms\n",
            "Speed: 6.4ms preprocess, 222.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 479.9ms\n",
            "Speed: 7.8ms preprocess, 479.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 199.5ms\n",
            "Speed: 6.2ms preprocess, 199.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 484.7ms\n",
            "Speed: 6.3ms preprocess, 484.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 222.7ms\n",
            "Speed: 6.5ms preprocess, 222.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 472.6ms\n",
            "Speed: 5.8ms preprocess, 472.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 238.8ms\n",
            "Speed: 6.7ms preprocess, 238.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 481.7ms\n",
            "Speed: 5.8ms preprocess, 481.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 235.2ms\n",
            "Speed: 6.5ms preprocess, 235.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 479.5ms\n",
            "Speed: 7.9ms preprocess, 479.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 232.9ms\n",
            "Speed: 7.6ms preprocess, 232.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 545.5ms\n",
            "Speed: 6.2ms preprocess, 545.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 327.9ms\n",
            "Speed: 6.3ms preprocess, 327.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 733.2ms\n",
            "Speed: 6.2ms preprocess, 733.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 324.0ms\n",
            "Speed: 6.4ms preprocess, 324.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 709.5ms\n",
            "Speed: 7.2ms preprocess, 709.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 306.7ms\n",
            "Speed: 6.2ms preprocess, 306.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 746.3ms\n",
            "Speed: 10.7ms preprocess, 746.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 317.0ms\n",
            "Speed: 9.4ms preprocess, 317.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 751.4ms\n",
            "Speed: 6.7ms preprocess, 751.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 319.4ms\n",
            "Speed: 7.0ms preprocess, 319.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 546.9ms\n",
            "Speed: 6.6ms preprocess, 546.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 257.3ms\n",
            "Speed: 8.1ms preprocess, 257.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 524.8ms\n",
            "Speed: 7.0ms preprocess, 524.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 201.9ms\n",
            "Speed: 6.4ms preprocess, 201.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 509.6ms\n",
            "Speed: 6.1ms preprocess, 509.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 219.0ms\n",
            "Speed: 7.2ms preprocess, 219.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 498.9ms\n",
            "Speed: 6.0ms preprocess, 498.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 219.6ms\n",
            "Speed: 7.0ms preprocess, 219.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 499.8ms\n",
            "Speed: 6.4ms preprocess, 499.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 223.5ms\n",
            "Speed: 8.0ms preprocess, 223.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 483.6ms\n",
            "Speed: 9.1ms preprocess, 483.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 229.4ms\n",
            "Speed: 7.1ms preprocess, 229.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 475.6ms\n",
            "Speed: 5.9ms preprocess, 475.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 223.2ms\n",
            "Speed: 8.7ms preprocess, 223.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 482.1ms\n",
            "Speed: 6.6ms preprocess, 482.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 231.2ms\n",
            "Speed: 6.2ms preprocess, 231.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 490.7ms\n",
            "Speed: 6.0ms preprocess, 490.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 208.0ms\n",
            "Speed: 7.2ms preprocess, 208.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 faces, 512.4ms\n",
            "Speed: 6.0ms preprocess, 512.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 240.7ms\n",
            "Speed: 6.2ms preprocess, 240.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 faces, 521.6ms\n",
            "Speed: 5.5ms preprocess, 521.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 292.9ms\n",
            "Speed: 7.1ms preprocess, 292.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 781.7ms\n",
            "Speed: 9.2ms preprocess, 781.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 303.3ms\n",
            "Speed: 8.5ms preprocess, 303.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 faces, 726.6ms\n",
            "Speed: 8.4ms preprocess, 726.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 326.3ms\n",
            "Speed: 8.5ms preprocess, 326.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 767.9ms\n",
            "Speed: 6.7ms preprocess, 767.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 312.3ms\n",
            "Speed: 6.6ms preprocess, 312.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 faces, 728.8ms\n",
            "Speed: 9.9ms preprocess, 728.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 320.8ms\n",
            "Speed: 6.3ms preprocess, 320.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 face, 712.1ms\n",
            "Speed: 6.2ms preprocess, 712.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 302.3ms\n",
            "Speed: 6.5ms preprocess, 302.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 faces, 498.9ms\n",
            "Speed: 10.1ms preprocess, 498.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 221.4ms\n",
            "Speed: 7.1ms preprocess, 221.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 faces, 515.0ms\n",
            "Speed: 6.8ms preprocess, 515.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 219.0ms\n",
            "Speed: 6.8ms preprocess, 219.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 500.9ms\n",
            "Speed: 6.3ms preprocess, 500.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 222.4ms\n",
            "Speed: 7.6ms preprocess, 222.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 463.5ms\n",
            "Speed: 4.6ms preprocess, 463.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 228.1ms\n",
            "Speed: 6.0ms preprocess, 228.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 474.7ms\n",
            "Speed: 6.0ms preprocess, 474.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 202.1ms\n",
            "Speed: 6.3ms preprocess, 202.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 faces, 493.9ms\n",
            "Speed: 6.4ms preprocess, 493.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 229.2ms\n",
            "Speed: 6.7ms preprocess, 229.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 495.9ms\n",
            "Speed: 8.5ms preprocess, 495.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 202.7ms\n",
            "Speed: 6.5ms preprocess, 202.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 faces, 458.9ms\n",
            "Speed: 5.6ms preprocess, 458.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 235.0ms\n",
            "Speed: 6.1ms preprocess, 235.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 484.7ms\n",
            "Speed: 6.1ms preprocess, 484.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 196.7ms\n",
            "Speed: 6.3ms preprocess, 196.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 faces, 492.0ms\n",
            "Speed: 6.6ms preprocess, 492.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 196.8ms\n",
            "Speed: 6.8ms preprocess, 196.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 faces, 477.2ms\n",
            "Speed: 7.9ms preprocess, 477.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 219.7ms\n",
            "Speed: 7.0ms preprocess, 219.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 faces, 481.3ms\n",
            "Speed: 6.5ms preprocess, 481.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 210.9ms\n",
            "Speed: 5.9ms preprocess, 210.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 faces, 636.9ms\n",
            "Speed: 8.9ms preprocess, 636.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 334.2ms\n",
            "Speed: 6.5ms preprocess, 334.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 739.1ms\n",
            "Speed: 11.8ms preprocess, 739.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 309.6ms\n",
            "Speed: 12.2ms preprocess, 309.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 faces, 737.5ms\n",
            "Speed: 10.9ms preprocess, 737.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 322.6ms\n",
            "Speed: 6.9ms preprocess, 322.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 faces, 732.4ms\n",
            "Speed: 14.6ms preprocess, 732.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 313.3ms\n",
            "Speed: 6.5ms preprocess, 313.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 faces, 716.7ms\n",
            "Speed: 5.9ms preprocess, 716.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 318.1ms\n",
            "Speed: 8.4ms preprocess, 318.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 faces, 647.3ms\n",
            "Speed: 7.1ms preprocess, 647.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 208.7ms\n",
            "Speed: 7.4ms preprocess, 208.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 505.1ms\n",
            "Speed: 5.9ms preprocess, 505.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 216.8ms\n",
            "Speed: 6.5ms preprocess, 216.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 506.9ms\n",
            "Speed: 6.5ms preprocess, 506.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 208.5ms\n",
            "Speed: 6.8ms preprocess, 208.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 486.3ms\n",
            "Speed: 7.7ms preprocess, 486.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 225.5ms\n",
            "Speed: 5.8ms preprocess, 225.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 493.4ms\n",
            "Speed: 6.2ms preprocess, 493.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 219.3ms\n",
            "Speed: 10.7ms preprocess, 219.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 497.2ms\n",
            "Speed: 8.6ms preprocess, 497.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 215.4ms\n",
            "Speed: 6.0ms preprocess, 215.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 491.4ms\n",
            "Speed: 7.3ms preprocess, 491.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 231.1ms\n",
            "Speed: 7.4ms preprocess, 231.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 501.0ms\n",
            "Speed: 6.6ms preprocess, 501.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 246.3ms\n",
            "Speed: 6.8ms preprocess, 246.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 494.0ms\n",
            "Speed: 8.0ms preprocess, 494.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 227.8ms\n",
            "Speed: 6.1ms preprocess, 227.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 488.8ms\n",
            "Speed: 6.2ms preprocess, 488.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 225.2ms\n",
            "Speed: 7.4ms preprocess, 225.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 624.8ms\n",
            "Speed: 6.7ms preprocess, 624.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 296.5ms\n",
            "Speed: 8.5ms preprocess, 296.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 746.8ms\n",
            "Speed: 7.3ms preprocess, 746.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 308.7ms\n",
            "Speed: 6.5ms preprocess, 308.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 732.6ms\n",
            "Speed: 10.4ms preprocess, 732.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 320.2ms\n",
            "Speed: 8.2ms preprocess, 320.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 719.5ms\n",
            "Speed: 6.5ms preprocess, 719.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 285.1ms\n",
            "Speed: 7.3ms preprocess, 285.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 506.9ms\n",
            "Speed: 6.2ms preprocess, 506.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 221.4ms\n",
            "Speed: 7.5ms preprocess, 221.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 498.1ms\n",
            "Speed: 8.1ms preprocess, 498.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 222.8ms\n",
            "Speed: 7.1ms preprocess, 222.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 510.9ms\n",
            "Speed: 6.8ms preprocess, 510.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 211.0ms\n",
            "Speed: 6.6ms preprocess, 211.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 512.3ms\n",
            "Speed: 6.3ms preprocess, 512.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 181.5ms\n",
            "Speed: 5.4ms preprocess, 181.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 502.2ms\n",
            "Speed: 6.7ms preprocess, 502.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 224.8ms\n",
            "Speed: 6.8ms preprocess, 224.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 495.8ms\n",
            "Speed: 8.1ms preprocess, 495.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 225.3ms\n",
            "Speed: 6.1ms preprocess, 225.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 496.1ms\n",
            "Speed: 6.2ms preprocess, 496.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 231.1ms\n",
            "Speed: 6.5ms preprocess, 231.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 485.2ms\n",
            "Speed: 6.1ms preprocess, 485.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 223.4ms\n",
            "Speed: 7.1ms preprocess, 223.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 497.6ms\n",
            "Speed: 7.1ms preprocess, 497.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 229.2ms\n",
            "Speed: 6.9ms preprocess, 229.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 494.1ms\n",
            "Speed: 6.3ms preprocess, 494.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 225.3ms\n",
            "Speed: 7.7ms preprocess, 225.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 711.4ms\n",
            "Speed: 6.8ms preprocess, 711.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 304.0ms\n",
            "Speed: 8.6ms preprocess, 304.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 763.2ms\n",
            "Speed: 13.3ms preprocess, 763.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 304.5ms\n",
            "Speed: 10.0ms preprocess, 304.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 752.2ms\n",
            "Speed: 9.5ms preprocess, 752.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 318.4ms\n",
            "Speed: 9.0ms preprocess, 318.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 725.5ms\n",
            "Speed: 10.7ms preprocess, 725.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 311.9ms\n",
            "Speed: 6.4ms preprocess, 311.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 609.4ms\n",
            "Speed: 10.4ms preprocess, 609.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 221.1ms\n",
            "Speed: 6.9ms preprocess, 221.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 488.5ms\n",
            "Speed: 7.1ms preprocess, 488.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 214.7ms\n",
            "Speed: 7.2ms preprocess, 214.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 481.1ms\n",
            "Speed: 5.6ms preprocess, 481.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 221.0ms\n",
            "Speed: 8.0ms preprocess, 221.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 493.5ms\n",
            "Speed: 6.2ms preprocess, 493.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 215.5ms\n",
            "Speed: 7.8ms preprocess, 215.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 487.3ms\n",
            "Speed: 5.7ms preprocess, 487.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 218.7ms\n",
            "Speed: 9.8ms preprocess, 218.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 490.4ms\n",
            "Speed: 6.0ms preprocess, 490.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 238.4ms\n",
            "Speed: 7.1ms preprocess, 238.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 495.6ms\n",
            "Speed: 5.2ms preprocess, 495.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 242.8ms\n",
            "Speed: 6.7ms preprocess, 242.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 491.0ms\n",
            "Speed: 6.5ms preprocess, 491.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 232.0ms\n",
            "Speed: 7.1ms preprocess, 232.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 485.7ms\n",
            "Speed: 7.2ms preprocess, 485.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 206.1ms\n",
            "Speed: 6.9ms preprocess, 206.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 486.5ms\n",
            "Speed: 7.9ms preprocess, 486.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 222.8ms\n",
            "Speed: 7.1ms preprocess, 222.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 544.0ms\n",
            "Speed: 6.2ms preprocess, 544.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 318.0ms\n",
            "Speed: 7.0ms preprocess, 318.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 762.7ms\n",
            "Speed: 8.9ms preprocess, 762.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 321.4ms\n",
            "Speed: 8.8ms preprocess, 321.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 738.7ms\n",
            "Speed: 9.4ms preprocess, 738.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 308.6ms\n",
            "Speed: 6.5ms preprocess, 308.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 726.0ms\n",
            "Speed: 6.3ms preprocess, 726.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 318.0ms\n",
            "Speed: 12.7ms preprocess, 318.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 721.1ms\n",
            "Speed: 6.0ms preprocess, 721.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 283.1ms\n",
            "Speed: 11.6ms preprocess, 283.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 500.8ms\n",
            "Speed: 10.3ms preprocess, 500.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 213.3ms\n",
            "Speed: 6.8ms preprocess, 213.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 510.4ms\n",
            "Speed: 7.1ms preprocess, 510.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 217.9ms\n",
            "Speed: 7.2ms preprocess, 217.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 503.2ms\n",
            "Speed: 8.4ms preprocess, 503.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 212.6ms\n",
            "Speed: 6.3ms preprocess, 212.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 476.5ms\n",
            "Speed: 6.7ms preprocess, 476.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 496.0ms\n",
            "Speed: 6.4ms preprocess, 496.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 601.9ms\n",
            "Speed: 10.0ms preprocess, 601.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 216.4ms\n",
            "Speed: 6.3ms preprocess, 216.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 515.4ms\n",
            "Speed: 6.6ms preprocess, 515.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 210.0ms\n",
            "Speed: 7.2ms preprocess, 210.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 493.8ms\n",
            "Speed: 8.1ms preprocess, 493.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 216.5ms\n",
            "Speed: 6.6ms preprocess, 216.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 539.2ms\n",
            "Speed: 12.1ms preprocess, 539.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 221.9ms\n",
            "Speed: 7.1ms preprocess, 221.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 486.8ms\n",
            "Speed: 8.5ms preprocess, 486.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 217.3ms\n",
            "Speed: 6.2ms preprocess, 217.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 480.6ms\n",
            "Speed: 6.2ms preprocess, 480.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 239.1ms\n",
            "Speed: 7.2ms preprocess, 239.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 709.4ms\n",
            "Speed: 8.8ms preprocess, 709.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 300.3ms\n",
            "Speed: 6.6ms preprocess, 300.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 729.8ms\n",
            "Speed: 6.0ms preprocess, 729.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 309.3ms\n",
            "Speed: 7.0ms preprocess, 309.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 763.2ms\n",
            "Speed: 9.8ms preprocess, 763.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 303.9ms\n",
            "Speed: 6.2ms preprocess, 303.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 734.4ms\n",
            "Speed: 9.4ms preprocess, 734.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 346.2ms\n",
            "Speed: 12.9ms preprocess, 346.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 681.5ms\n",
            "Speed: 11.3ms preprocess, 681.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 242.6ms\n",
            "Speed: 7.7ms preprocess, 242.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 490.8ms\n",
            "Speed: 6.2ms preprocess, 490.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 235.0ms\n",
            "Speed: 6.2ms preprocess, 235.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 497.9ms\n",
            "Speed: 8.9ms preprocess, 497.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 210.8ms\n",
            "Speed: 8.7ms preprocess, 210.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 494.8ms\n",
            "Speed: 7.2ms preprocess, 494.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 205.0ms\n",
            "Speed: 7.0ms preprocess, 205.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 503.7ms\n",
            "Speed: 7.0ms preprocess, 503.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 214.2ms\n",
            "Speed: 7.4ms preprocess, 214.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 514.2ms\n",
            "Speed: 7.0ms preprocess, 514.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 215.2ms\n",
            "Speed: 6.3ms preprocess, 215.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 508.8ms\n",
            "Speed: 6.4ms preprocess, 508.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 219.0ms\n",
            "Speed: 9.6ms preprocess, 219.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 487.9ms\n",
            "Speed: 6.5ms preprocess, 487.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 216.6ms\n",
            "Speed: 8.0ms preprocess, 216.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 496.8ms\n",
            "Speed: 8.3ms preprocess, 496.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 220.8ms\n",
            "Speed: 8.8ms preprocess, 220.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 482.2ms\n",
            "Speed: 7.0ms preprocess, 482.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 248.6ms\n",
            "Speed: 7.2ms preprocess, 248.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 494.8ms\n",
            "Speed: 8.8ms preprocess, 494.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 242.5ms\n",
            "Speed: 7.0ms preprocess, 242.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 705.3ms\n",
            "Speed: 6.4ms preprocess, 705.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 299.8ms\n",
            "Speed: 6.6ms preprocess, 299.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 719.8ms\n",
            "Speed: 10.5ms preprocess, 719.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 291.9ms\n",
            "Speed: 8.7ms preprocess, 291.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 723.0ms\n",
            "Speed: 7.0ms preprocess, 723.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 295.7ms\n",
            "Speed: 6.1ms preprocess, 295.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 750.8ms\n",
            "Speed: 6.0ms preprocess, 750.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 341.3ms\n",
            "Speed: 6.0ms preprocess, 341.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 567.0ms\n",
            "Speed: 7.6ms preprocess, 567.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 219.0ms\n",
            "Speed: 7.2ms preprocess, 219.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 465.9ms\n",
            "Speed: 6.8ms preprocess, 465.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 214.5ms\n",
            "Speed: 7.2ms preprocess, 214.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 487.1ms\n",
            "Speed: 6.4ms preprocess, 487.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 183.4ms\n",
            "Speed: 6.2ms preprocess, 183.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 466.7ms\n",
            "Speed: 5.4ms preprocess, 466.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 204.8ms\n",
            "Speed: 5.5ms preprocess, 204.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 489.5ms\n",
            "Speed: 5.5ms preprocess, 489.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 221.4ms\n",
            "Speed: 7.3ms preprocess, 221.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 487.1ms\n",
            "Speed: 7.6ms preprocess, 487.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 216.8ms\n",
            "Speed: 7.0ms preprocess, 216.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 525.8ms\n",
            "Speed: 10.9ms preprocess, 525.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 222.0ms\n",
            "Speed: 7.1ms preprocess, 222.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 514.6ms\n",
            "Speed: 5.9ms preprocess, 514.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 224.7ms\n",
            "Speed: 7.4ms preprocess, 224.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 512.5ms\n",
            "Speed: 8.5ms preprocess, 512.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 219.6ms\n",
            "Speed: 11.5ms preprocess, 219.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 485.4ms\n",
            "Speed: 7.9ms preprocess, 485.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 211.4ms\n",
            "Speed: 6.4ms preprocess, 211.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 504.3ms\n",
            "Speed: 6.9ms preprocess, 504.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 305.1ms\n",
            "Speed: 6.3ms preprocess, 305.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 732.9ms\n",
            "Speed: 7.1ms preprocess, 732.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 325.9ms\n",
            "Speed: 6.2ms preprocess, 325.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 738.8ms\n",
            "Speed: 8.9ms preprocess, 738.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 302.3ms\n",
            "Speed: 10.1ms preprocess, 302.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 739.7ms\n",
            "Speed: 9.9ms preprocess, 739.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 332.9ms\n",
            "Speed: 10.4ms preprocess, 332.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 734.2ms\n",
            "Speed: 7.7ms preprocess, 734.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 295.2ms\n",
            "Speed: 6.6ms preprocess, 295.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 550.9ms\n",
            "Speed: 5.4ms preprocess, 550.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 199.8ms\n",
            "Speed: 8.0ms preprocess, 199.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 506.6ms\n",
            "Speed: 7.0ms preprocess, 506.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 221.1ms\n",
            "Speed: 7.1ms preprocess, 221.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 485.1ms\n",
            "Speed: 7.0ms preprocess, 485.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 212.2ms\n",
            "Speed: 7.4ms preprocess, 212.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 490.1ms\n",
            "Speed: 6.1ms preprocess, 490.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 215.2ms\n",
            "Speed: 7.2ms preprocess, 215.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 489.4ms\n",
            "Speed: 10.0ms preprocess, 489.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 243.0ms\n",
            "Speed: 6.0ms preprocess, 243.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 488.5ms\n",
            "Speed: 7.0ms preprocess, 488.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 217.9ms\n",
            "Speed: 6.3ms preprocess, 217.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 521.2ms\n",
            "Speed: 6.8ms preprocess, 521.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 218.4ms\n",
            "Speed: 7.6ms preprocess, 218.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 513.2ms\n",
            "Speed: 6.2ms preprocess, 513.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 211.8ms\n",
            "Speed: 7.7ms preprocess, 211.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 523.1ms\n",
            "Speed: 7.6ms preprocess, 523.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 215.9ms\n",
            "Speed: 7.9ms preprocess, 215.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 501.0ms\n",
            "Speed: 6.6ms preprocess, 501.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 230.5ms\n",
            "Speed: 7.0ms preprocess, 230.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 489.4ms\n",
            "Speed: 8.4ms preprocess, 489.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 310.7ms\n",
            "Speed: 7.9ms preprocess, 310.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 778.4ms\n",
            "Speed: 8.3ms preprocess, 778.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 335.4ms\n",
            "Speed: 11.6ms preprocess, 335.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 751.8ms\n",
            "Speed: 7.6ms preprocess, 751.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 315.5ms\n",
            "Speed: 7.8ms preprocess, 315.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 740.6ms\n",
            "Speed: 6.6ms preprocess, 740.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 334.4ms\n",
            "Speed: 7.0ms preprocess, 334.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 716.0ms\n",
            "Speed: 9.4ms preprocess, 716.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 306.1ms\n",
            "Speed: 11.1ms preprocess, 306.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 517.1ms\n",
            "Speed: 8.7ms preprocess, 517.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 236.3ms\n",
            "Speed: 6.9ms preprocess, 236.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 488.1ms\n",
            "Speed: 5.8ms preprocess, 488.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 244.9ms\n",
            "Speed: 6.6ms preprocess, 244.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 486.6ms\n",
            "Speed: 7.4ms preprocess, 486.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 232.6ms\n",
            "Speed: 8.0ms preprocess, 232.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 539.0ms\n",
            "Speed: 6.6ms preprocess, 539.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 229.7ms\n",
            "Speed: 7.0ms preprocess, 229.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 513.4ms\n",
            "Speed: 6.4ms preprocess, 513.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 228.1ms\n",
            "Speed: 6.4ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 503.0ms\n",
            "Speed: 7.0ms preprocess, 503.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 210.8ms\n",
            "Speed: 7.4ms preprocess, 210.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 514.9ms\n",
            "Speed: 6.6ms preprocess, 514.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 216.5ms\n",
            "Speed: 5.2ms preprocess, 216.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 491.5ms\n",
            "Speed: 10.2ms preprocess, 491.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 216.0ms\n",
            "Speed: 7.8ms preprocess, 216.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 513.5ms\n",
            "Speed: 8.0ms preprocess, 513.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 221.9ms\n",
            "Speed: 6.2ms preprocess, 221.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 484.2ms\n",
            "Speed: 6.1ms preprocess, 484.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 221.8ms\n",
            "Speed: 7.3ms preprocess, 221.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 483.1ms\n",
            "Speed: 6.6ms preprocess, 483.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 319.0ms\n",
            "Speed: 8.2ms preprocess, 319.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 740.4ms\n",
            "Speed: 9.3ms preprocess, 740.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 329.7ms\n",
            "Speed: 6.9ms preprocess, 329.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 741.4ms\n",
            "Speed: 6.3ms preprocess, 741.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 320.2ms\n",
            "Speed: 10.0ms preprocess, 320.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 745.4ms\n",
            "Speed: 10.6ms preprocess, 745.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 316.8ms\n",
            "Speed: 6.4ms preprocess, 316.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 723.7ms\n",
            "Speed: 5.8ms preprocess, 723.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 339.5ms\n",
            "Speed: 7.2ms preprocess, 339.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 546.7ms\n",
            "Speed: 10.1ms preprocess, 546.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 258.1ms\n",
            "Speed: 6.9ms preprocess, 258.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 480.0ms\n",
            "Speed: 6.0ms preprocess, 480.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 242.3ms\n",
            "Speed: 8.2ms preprocess, 242.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 493.4ms\n",
            "Speed: 6.0ms preprocess, 493.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 214.3ms\n",
            "Speed: 6.6ms preprocess, 214.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 504.5ms\n",
            "Speed: 6.0ms preprocess, 504.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 216.3ms\n",
            "Speed: 7.4ms preprocess, 216.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 513.9ms\n",
            "Speed: 7.5ms preprocess, 513.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 194.6ms\n",
            "Speed: 6.4ms preprocess, 194.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 499.7ms\n",
            "Speed: 6.1ms preprocess, 499.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 200.5ms\n",
            "Speed: 6.3ms preprocess, 200.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 491.2ms\n",
            "Speed: 7.2ms preprocess, 491.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 217.4ms\n",
            "Speed: 8.0ms preprocess, 217.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 493.5ms\n",
            "Speed: 11.1ms preprocess, 493.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 222.0ms\n",
            "Speed: 9.0ms preprocess, 222.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 491.2ms\n",
            "Speed: 7.4ms preprocess, 491.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 228.1ms\n",
            "Speed: 9.0ms preprocess, 228.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 491.0ms\n",
            "Speed: 5.1ms preprocess, 491.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 237.5ms\n",
            "Speed: 7.5ms preprocess, 237.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 491.6ms\n",
            "Speed: 6.3ms preprocess, 491.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 276.2ms\n",
            "Speed: 5.9ms preprocess, 276.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 726.0ms\n",
            "Speed: 7.9ms preprocess, 726.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 376.7ms\n",
            "Speed: 16.9ms preprocess, 376.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 739.1ms\n",
            "Speed: 6.5ms preprocess, 739.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 313.2ms\n",
            "Speed: 6.8ms preprocess, 313.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 742.9ms\n",
            "Speed: 6.6ms preprocess, 742.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 314.1ms\n",
            "Speed: 7.7ms preprocess, 314.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 761.7ms\n",
            "Speed: 11.8ms preprocess, 761.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 329.5ms\n",
            "Speed: 7.3ms preprocess, 329.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 644.8ms\n",
            "Speed: 6.2ms preprocess, 644.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 246.5ms\n",
            "Speed: 7.4ms preprocess, 246.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 531.0ms\n",
            "Speed: 10.5ms preprocess, 531.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 223.8ms\n",
            "Speed: 7.7ms preprocess, 223.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 505.8ms\n",
            "Speed: 7.9ms preprocess, 505.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 215.4ms\n",
            "Speed: 6.7ms preprocess, 215.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 525.8ms\n",
            "Speed: 7.5ms preprocess, 525.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 251.2ms\n",
            "Speed: 15.2ms preprocess, 251.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 504.9ms\n",
            "Speed: 7.1ms preprocess, 504.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 218.9ms\n",
            "Speed: 7.8ms preprocess, 218.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 505.8ms\n",
            "Speed: 7.6ms preprocess, 505.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 217.1ms\n",
            "Speed: 9.9ms preprocess, 217.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 faces, 500.6ms\n",
            "Speed: 6.9ms preprocess, 500.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 223.4ms\n",
            "Speed: 6.4ms preprocess, 223.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 faces, 508.7ms\n",
            "Speed: 6.9ms preprocess, 508.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 214.3ms\n",
            "Speed: 8.2ms preprocess, 214.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 487.1ms\n",
            "Speed: 8.0ms preprocess, 487.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 223.1ms\n",
            "Speed: 7.1ms preprocess, 223.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 494.1ms\n",
            "Speed: 7.1ms preprocess, 494.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 241.3ms\n",
            "Speed: 9.2ms preprocess, 241.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 484.2ms\n",
            "Speed: 7.1ms preprocess, 484.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 342.7ms\n",
            "Speed: 5.7ms preprocess, 342.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 749.9ms\n",
            "Speed: 10.9ms preprocess, 749.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 321.2ms\n",
            "Speed: 7.4ms preprocess, 321.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 744.1ms\n",
            "Speed: 7.2ms preprocess, 744.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 322.8ms\n",
            "Speed: 6.7ms preprocess, 322.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 1479.1ms\n",
            "Speed: 7.7ms preprocess, 1479.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 314.9ms\n",
            "Speed: 6.6ms preprocess, 314.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 720.1ms\n",
            "Speed: 10.5ms preprocess, 720.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 207.0ms\n",
            "Speed: 8.0ms preprocess, 207.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 497.8ms\n",
            "Speed: 7.7ms preprocess, 497.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 209.1ms\n",
            "Speed: 7.8ms preprocess, 209.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 488.6ms\n",
            "Speed: 7.7ms preprocess, 488.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 226.2ms\n",
            "Speed: 10.8ms preprocess, 226.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 497.2ms\n",
            "Speed: 7.8ms preprocess, 497.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 215.7ms\n",
            "Speed: 8.6ms preprocess, 215.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 489.8ms\n",
            "Speed: 7.2ms preprocess, 489.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 234.5ms\n",
            "Speed: 8.7ms preprocess, 234.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 491.2ms\n",
            "Speed: 6.9ms preprocess, 491.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 229.4ms\n",
            "Speed: 7.1ms preprocess, 229.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 490.2ms\n",
            "Speed: 7.6ms preprocess, 490.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 217.4ms\n",
            "Speed: 6.9ms preprocess, 217.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 512.4ms\n",
            "Speed: 6.6ms preprocess, 512.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 227.8ms\n",
            "Speed: 6.6ms preprocess, 227.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 488.6ms\n",
            "Speed: 7.7ms preprocess, 488.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 220.9ms\n",
            "Speed: 7.5ms preprocess, 220.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 479.0ms\n",
            "Speed: 6.1ms preprocess, 479.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 224.1ms\n",
            "Speed: 10.5ms preprocess, 224.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 487.8ms\n",
            "Speed: 8.2ms preprocess, 487.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 225.6ms\n",
            "Speed: 7.0ms preprocess, 225.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 526.0ms\n",
            "Speed: 6.1ms preprocess, 526.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 314.9ms\n",
            "Speed: 8.1ms preprocess, 314.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 712.2ms\n",
            "Speed: 8.2ms preprocess, 712.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 299.3ms\n",
            "Speed: 9.1ms preprocess, 299.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 703.4ms\n",
            "Speed: 6.6ms preprocess, 703.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 290.6ms\n",
            "Speed: 9.7ms preprocess, 290.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 715.4ms\n",
            "Speed: 6.6ms preprocess, 715.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 331.9ms\n",
            "Speed: 7.7ms preprocess, 331.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 faces, 732.5ms\n",
            "Speed: 9.4ms preprocess, 732.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 338.3ms\n",
            "Speed: 9.5ms preprocess, 338.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 565.8ms\n",
            "Speed: 10.1ms preprocess, 565.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 240.5ms\n",
            "Speed: 9.9ms preprocess, 240.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 482.0ms\n",
            "Speed: 6.4ms preprocess, 482.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 216.9ms\n",
            "Speed: 7.0ms preprocess, 216.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 faces, 506.5ms\n",
            "Speed: 8.8ms preprocess, 506.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 228.3ms\n",
            "Speed: 6.3ms preprocess, 228.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 506.2ms\n",
            "Speed: 6.4ms preprocess, 506.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 202.2ms\n",
            "Speed: 5.9ms preprocess, 202.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 499.0ms\n",
            "Speed: 11.7ms preprocess, 499.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 223.5ms\n",
            "Speed: 6.0ms preprocess, 223.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 506.0ms\n",
            "Speed: 8.2ms preprocess, 506.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 231.4ms\n",
            "Speed: 6.7ms preprocess, 231.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 506.3ms\n",
            "Speed: 6.4ms preprocess, 506.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 231.6ms\n",
            "Speed: 8.7ms preprocess, 231.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 496.6ms\n",
            "Speed: 8.2ms preprocess, 496.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 225.4ms\n",
            "Speed: 8.1ms preprocess, 225.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 495.2ms\n",
            "Speed: 8.3ms preprocess, 495.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 233.2ms\n",
            "Speed: 7.7ms preprocess, 233.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 faces, 503.5ms\n",
            "Speed: 7.1ms preprocess, 503.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 333.7ms\n",
            "Speed: 7.5ms preprocess, 333.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 750.2ms\n",
            "Speed: 8.0ms preprocess, 750.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 311.7ms\n",
            "Speed: 7.1ms preprocess, 311.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 789.1ms\n",
            "Speed: 11.8ms preprocess, 789.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 329.2ms\n",
            "Speed: 10.2ms preprocess, 329.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 faces, 727.4ms\n",
            "Speed: 6.1ms preprocess, 727.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 305.6ms\n",
            "Speed: 11.1ms preprocess, 305.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 720.1ms\n",
            "Speed: 11.3ms preprocess, 720.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 237.2ms\n",
            "Speed: 7.7ms preprocess, 237.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 faces, 490.2ms\n",
            "Speed: 6.1ms preprocess, 490.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 240.1ms\n",
            "Speed: 6.1ms preprocess, 240.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 479.3ms\n",
            "Speed: 5.9ms preprocess, 479.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 238.7ms\n",
            "Speed: 7.7ms preprocess, 238.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 487.5ms\n",
            "Speed: 11.1ms preprocess, 487.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 227.2ms\n",
            "Speed: 8.8ms preprocess, 227.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 475.4ms\n",
            "Speed: 8.8ms preprocess, 475.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 233.7ms\n",
            "Speed: 12.8ms preprocess, 233.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 477.5ms\n",
            "Speed: 6.7ms preprocess, 477.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 236.9ms\n",
            "Speed: 7.1ms preprocess, 236.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 495.4ms\n",
            "Speed: 7.6ms preprocess, 495.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 238.0ms\n",
            "Speed: 6.7ms preprocess, 238.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 479.0ms\n",
            "Speed: 9.7ms preprocess, 479.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 223.9ms\n",
            "Speed: 6.3ms preprocess, 223.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 faces, 480.0ms\n",
            "Speed: 9.8ms preprocess, 480.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 232.3ms\n",
            "Speed: 9.9ms preprocess, 232.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 470.7ms\n",
            "Speed: 6.9ms preprocess, 470.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 535.8ms\n",
            "Speed: 7.5ms preprocess, 535.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 753.3ms\n",
            "Speed: 6.4ms preprocess, 753.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 298.0ms\n",
            "Speed: 4.9ms preprocess, 298.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 faces, 751.9ms\n",
            "Speed: 7.1ms preprocess, 751.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 326.3ms\n",
            "Speed: 10.0ms preprocess, 326.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 faces, 724.1ms\n",
            "Speed: 6.3ms preprocess, 724.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 323.6ms\n",
            "Speed: 11.3ms preprocess, 323.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 707.3ms\n",
            "Speed: 10.2ms preprocess, 707.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 225.9ms\n",
            "Speed: 6.7ms preprocess, 225.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 513.3ms\n",
            "Speed: 6.4ms preprocess, 513.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 222.5ms\n",
            "Speed: 9.0ms preprocess, 222.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 514.5ms\n",
            "Speed: 6.1ms preprocess, 514.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 198.3ms\n",
            "Speed: 6.4ms preprocess, 198.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 468.6ms\n",
            "Speed: 5.3ms preprocess, 468.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 191.3ms\n",
            "Speed: 8.0ms preprocess, 191.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 452.6ms\n",
            "Speed: 7.0ms preprocess, 452.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 215.9ms\n",
            "Speed: 7.4ms preprocess, 215.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 516.3ms\n",
            "Speed: 8.1ms preprocess, 516.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 223.3ms\n",
            "Speed: 5.6ms preprocess, 223.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 492.4ms\n",
            "Speed: 5.9ms preprocess, 492.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 217.0ms\n",
            "Speed: 6.7ms preprocess, 217.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 494.1ms\n",
            "Speed: 6.1ms preprocess, 494.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 217.5ms\n",
            "Speed: 8.6ms preprocess, 217.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 482.9ms\n",
            "Speed: 8.4ms preprocess, 482.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 217.3ms\n",
            "Speed: 6.6ms preprocess, 217.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 499.2ms\n",
            "Speed: 10.4ms preprocess, 499.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 219.9ms\n",
            "Speed: 8.6ms preprocess, 219.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 652.4ms\n",
            "Speed: 7.2ms preprocess, 652.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 317.3ms\n",
            "Speed: 6.8ms preprocess, 317.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 faces, 722.1ms\n",
            "Speed: 7.2ms preprocess, 722.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 311.9ms\n",
            "Speed: 8.4ms preprocess, 311.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 faces, 741.9ms\n",
            "Speed: 8.9ms preprocess, 741.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 329.0ms\n",
            "Speed: 6.8ms preprocess, 329.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 faces, 714.2ms\n",
            "Speed: 8.1ms preprocess, 714.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 289.5ms\n",
            "Speed: 7.9ms preprocess, 289.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 513.9ms\n",
            "Speed: 7.1ms preprocess, 513.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 240.0ms\n",
            "Speed: 7.8ms preprocess, 240.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 484.9ms\n",
            "Speed: 6.9ms preprocess, 484.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 243.9ms\n",
            "Speed: 6.5ms preprocess, 243.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 faces, 483.8ms\n",
            "Speed: 6.8ms preprocess, 483.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 234.9ms\n",
            "Speed: 7.5ms preprocess, 234.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 faces, 480.8ms\n",
            "Speed: 6.7ms preprocess, 480.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 230.7ms\n",
            "Speed: 11.7ms preprocess, 230.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 faces, 490.8ms\n",
            "Speed: 6.8ms preprocess, 490.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 257.4ms\n",
            "Speed: 6.0ms preprocess, 257.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 faces, 491.5ms\n",
            "Speed: 6.2ms preprocess, 491.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 212.7ms\n",
            "Speed: 6.5ms preprocess, 212.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 494.2ms\n",
            "Speed: 6.8ms preprocess, 494.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 221.7ms\n",
            "Speed: 8.3ms preprocess, 221.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 502.7ms\n",
            "Speed: 8.0ms preprocess, 502.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 214.2ms\n",
            "Speed: 8.5ms preprocess, 214.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 515.0ms\n",
            "Speed: 7.0ms preprocess, 515.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 215.8ms\n",
            "Speed: 6.6ms preprocess, 215.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 668.1ms\n",
            "Speed: 6.5ms preprocess, 668.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 431.5ms\n",
            "Speed: 6.6ms preprocess, 431.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 721.4ms\n",
            "Speed: 8.0ms preprocess, 721.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 326.3ms\n",
            "Speed: 6.1ms preprocess, 326.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 738.0ms\n",
            "Speed: 10.5ms preprocess, 738.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 313.6ms\n",
            "Speed: 9.1ms preprocess, 313.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 725.3ms\n",
            "Speed: 10.8ms preprocess, 725.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 336.0ms\n",
            "Speed: 11.8ms preprocess, 336.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 723.1ms\n",
            "Speed: 6.1ms preprocess, 723.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 267.5ms\n",
            "Speed: 9.9ms preprocess, 267.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 514.4ms\n",
            "Speed: 7.8ms preprocess, 514.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 213.3ms\n",
            "Speed: 5.9ms preprocess, 213.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 493.2ms\n",
            "Speed: 7.9ms preprocess, 493.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 232.0ms\n",
            "Speed: 8.4ms preprocess, 232.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 497.7ms\n",
            "Speed: 6.1ms preprocess, 497.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 207.2ms\n",
            "Speed: 8.9ms preprocess, 207.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 459.9ms\n",
            "Speed: 7.0ms preprocess, 459.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 219.6ms\n",
            "Speed: 6.0ms preprocess, 219.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 489.9ms\n",
            "Speed: 8.2ms preprocess, 489.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 233.9ms\n",
            "Speed: 7.5ms preprocess, 233.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 485.0ms\n",
            "Speed: 6.8ms preprocess, 485.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 229.9ms\n",
            "Speed: 8.8ms preprocess, 229.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 504.5ms\n",
            "Speed: 6.3ms preprocess, 504.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 220.2ms\n",
            "Speed: 6.5ms preprocess, 220.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 491.8ms\n",
            "Speed: 6.7ms preprocess, 491.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 214.9ms\n",
            "Speed: 7.8ms preprocess, 214.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 495.1ms\n",
            "Speed: 9.1ms preprocess, 495.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 232.9ms\n",
            "Speed: 8.5ms preprocess, 232.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 486.9ms\n",
            "Speed: 8.2ms preprocess, 486.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 233.5ms\n",
            "Speed: 6.6ms preprocess, 233.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 684.1ms\n",
            "Speed: 20.0ms preprocess, 684.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 328.0ms\n",
            "Speed: 6.9ms preprocess, 328.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 faces, 714.0ms\n",
            "Speed: 16.4ms preprocess, 714.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 323.1ms\n",
            "Speed: 6.1ms preprocess, 323.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 760.3ms\n",
            "Speed: 7.0ms preprocess, 760.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 319.4ms\n",
            "Speed: 8.0ms preprocess, 319.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 731.3ms\n",
            "Speed: 9.4ms preprocess, 731.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 321.0ms\n",
            "Speed: 6.6ms preprocess, 321.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 616.6ms\n",
            "Speed: 6.3ms preprocess, 616.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 228.0ms\n",
            "Speed: 8.4ms preprocess, 228.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 486.2ms\n",
            "Speed: 6.0ms preprocess, 486.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 255.7ms\n",
            "Speed: 9.3ms preprocess, 255.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 451.5ms\n",
            "Speed: 5.9ms preprocess, 451.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 235.5ms\n",
            "Speed: 5.9ms preprocess, 235.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 472.4ms\n",
            "Speed: 6.7ms preprocess, 472.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 187.7ms\n",
            "Speed: 8.4ms preprocess, 187.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 484.3ms\n",
            "Speed: 5.5ms preprocess, 484.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 200.3ms\n",
            "Speed: 7.3ms preprocess, 200.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 485.8ms\n",
            "Speed: 5.6ms preprocess, 485.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 227.2ms\n",
            "Speed: 8.3ms preprocess, 227.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 502.5ms\n",
            "Speed: 6.7ms preprocess, 502.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 210.2ms\n",
            "Speed: 7.3ms preprocess, 210.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 512.2ms\n",
            "Speed: 9.5ms preprocess, 512.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 212.7ms\n",
            "Speed: 11.6ms preprocess, 212.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 549.2ms\n",
            "Speed: 9.7ms preprocess, 549.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 228.5ms\n",
            "Speed: 9.2ms preprocess, 228.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 510.9ms\n",
            "Speed: 9.5ms preprocess, 510.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 220.8ms\n",
            "Speed: 7.7ms preprocess, 220.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 524.5ms\n",
            "Speed: 8.0ms preprocess, 524.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 293.9ms\n",
            "Speed: 10.0ms preprocess, 293.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 725.0ms\n",
            "Speed: 7.0ms preprocess, 725.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 297.0ms\n",
            "Speed: 10.0ms preprocess, 297.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 736.5ms\n",
            "Speed: 5.8ms preprocess, 736.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 318.6ms\n",
            "Speed: 23.7ms preprocess, 318.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 724.3ms\n",
            "Speed: 9.0ms preprocess, 724.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 322.9ms\n",
            "Speed: 6.2ms preprocess, 322.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 730.1ms\n",
            "Speed: 10.4ms preprocess, 730.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 215.8ms\n",
            "Speed: 8.7ms preprocess, 215.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 503.0ms\n",
            "Speed: 9.8ms preprocess, 503.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 197.7ms\n",
            "Speed: 7.6ms preprocess, 197.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 504.7ms\n",
            "Speed: 11.6ms preprocess, 504.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 229.0ms\n",
            "Speed: 7.9ms preprocess, 229.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 500.2ms\n",
            "Speed: 6.9ms preprocess, 500.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 225.7ms\n",
            "Speed: 8.4ms preprocess, 225.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 516.4ms\n",
            "Speed: 6.5ms preprocess, 516.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 217.8ms\n",
            "Speed: 8.1ms preprocess, 217.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 505.7ms\n",
            "Speed: 6.2ms preprocess, 505.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 213.2ms\n",
            "Speed: 8.4ms preprocess, 213.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 484.4ms\n",
            "Speed: 7.2ms preprocess, 484.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 209.4ms\n",
            "Speed: 6.2ms preprocess, 209.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 466.3ms\n",
            "Speed: 6.6ms preprocess, 466.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 195.6ms\n",
            "Speed: 6.3ms preprocess, 195.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 463.7ms\n",
            "Speed: 7.9ms preprocess, 463.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 221.8ms\n",
            "Speed: 7.2ms preprocess, 221.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 453.6ms\n",
            "Speed: 8.8ms preprocess, 453.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 198.2ms\n",
            "Speed: 5.8ms preprocess, 198.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 483.8ms\n",
            "Speed: 8.6ms preprocess, 483.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 206.5ms\n",
            "Speed: 7.8ms preprocess, 206.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 657.0ms\n",
            "Speed: 8.1ms preprocess, 657.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 353.8ms\n",
            "Speed: 6.7ms preprocess, 353.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 680.3ms\n",
            "Speed: 5.6ms preprocess, 680.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 335.7ms\n",
            "Speed: 12.8ms preprocess, 335.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 747.6ms\n",
            "Speed: 10.4ms preprocess, 747.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 296.6ms\n",
            "Speed: 7.9ms preprocess, 296.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 737.7ms\n",
            "Speed: 6.1ms preprocess, 737.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 289.2ms\n",
            "Speed: 8.2ms preprocess, 289.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 647.2ms\n",
            "Speed: 7.3ms preprocess, 647.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 207.3ms\n",
            "Speed: 8.2ms preprocess, 207.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 494.8ms\n",
            "Speed: 11.8ms preprocess, 494.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 207.0ms\n",
            "Speed: 8.2ms preprocess, 207.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 519.9ms\n",
            "Speed: 7.3ms preprocess, 519.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 220.5ms\n",
            "Speed: 7.8ms preprocess, 220.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 faces, 508.1ms\n",
            "Speed: 7.5ms preprocess, 508.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 217.2ms\n",
            "Speed: 8.3ms preprocess, 217.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 520.8ms\n",
            "Speed: 7.1ms preprocess, 520.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 223.1ms\n",
            "Speed: 6.8ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 faces, 513.8ms\n",
            "Speed: 6.2ms preprocess, 513.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 214.0ms\n",
            "Speed: 5.8ms preprocess, 214.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 502.7ms\n",
            "Speed: 6.1ms preprocess, 502.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 249.9ms\n",
            "Speed: 8.2ms preprocess, 249.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 faces, 497.3ms\n",
            "Speed: 6.3ms preprocess, 497.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 196.9ms\n",
            "Speed: 5.2ms preprocess, 196.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 faces, 484.0ms\n",
            "Speed: 6.4ms preprocess, 484.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 214.2ms\n",
            "Speed: 6.3ms preprocess, 214.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 faces, 470.4ms\n",
            "Speed: 6.3ms preprocess, 470.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 208.5ms\n",
            "Speed: 7.3ms preprocess, 208.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 faces, 464.1ms\n",
            "Speed: 6.7ms preprocess, 464.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "âœ… Label .txt files saved for all images in output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model"
      ],
      "metadata": {
        "id": "fozrqe6WuDJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "Hb9uH-V_uFUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a base model (you can use yolov8n.pt for fast training)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/Dataset/data.yml',\n",
        "    epochs=30,\n",
        "    imgsz=640,\n",
        "    batch=16\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYFJezZXwoAr",
        "outputId": "0667e32d-9a76-47df-e561-0e34b6fdd1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 103MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.169 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Dataset/data.yml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 22.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 99.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 1.2Â±0.5 MB/s, size: 513.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Dataset/labels/train.cache... 1500 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 1.1Â±0.3 MB/s, size: 514.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Dataset/labels/val.cache... 400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      2.17G      1.048        2.1      1.053        171        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [09:14<00:00,  5.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:08<00:00,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.791      0.155       0.27      0.203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      2.28G     0.9042       1.26     0.9977        147        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:42<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.616      0.403      0.391      0.307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30       2.3G     0.8733      1.168     0.9976        125        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.634      0.462      0.404      0.316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30       2.3G     0.8494      1.095      0.988        148        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:45<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.634      0.463      0.432       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30       2.3G     0.8292      1.037     0.9802        197        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.637      0.501      0.434      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30       2.3G     0.8028     0.9692     0.9716        132        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.605      0.516      0.433      0.344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30       2.3G     0.7869     0.9549     0.9639        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:08<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.621      0.499      0.443      0.355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30       2.3G     0.7893     0.9293     0.9665        197        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.632      0.484      0.465      0.376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      2.31G      0.768     0.9078     0.9582        130        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:44<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.646      0.515      0.478       0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      2.31G     0.7606     0.9018     0.9563        156        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.626      0.507      0.455      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      2.31G     0.7466     0.8742     0.9508        137        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.648      0.487      0.468      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      2.31G     0.7466     0.8643     0.9546        184        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:44<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.655      0.487      0.489      0.403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      2.31G     0.7343     0.8337     0.9508        164        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:44<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:06<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.642       0.52      0.526      0.436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      2.31G     0.7241     0.8262     0.9447        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.659      0.513      0.524      0.429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      2.31G     0.7191     0.8197     0.9441        151        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:42<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.687      0.516      0.511      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      2.31G     0.7023      0.794      0.936        155        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.678      0.493      0.496      0.414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      2.31G     0.6957     0.7952     0.9335        196        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.699       0.49      0.517      0.432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      2.31G     0.6954       0.79      0.934        165        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.365      0.602      0.508      0.422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      2.31G     0.6844     0.7734      0.931         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:44<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889       0.48      0.522       0.52      0.437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      2.32G     0.6848     0.7822     0.9293        188        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:42<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.556      0.578      0.541      0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      2.33G     0.6519     0.7434     0.9163        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:43<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.689      0.535       0.53      0.443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      2.33G     0.6385     0.7368     0.9119         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:42<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.717      0.518      0.547      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      2.35G     0.6356     0.7126     0.9132        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:41<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.527      0.619       0.58       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      2.35G     0.6274     0.7013     0.9042         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:41<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.502      0.699      0.596      0.508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      2.35G     0.6178     0.6915      0.906         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:41<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.681      0.642      0.624      0.528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      2.35G     0.6112     0.6836     0.8998         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:42<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.643      0.558      0.595      0.507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      2.35G     0.6009     0.6724     0.9003         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:41<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.604      0.576      0.588      0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      2.37G     0.5972     0.6659     0.8974         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:41<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889       0.69      0.548      0.584      0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      2.37G     0.5933     0.6591     0.8935         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:41<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.578      0.559      0.589      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      2.38G     0.5894     0.6464     0.8904         87        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:42<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:05<00:00,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.606      0.564      0.596      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.562 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.169 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:08<00:00,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        400       2889      0.681      0.641      0.624      0.528\n",
            "               Engaged        389       2182      0.763      0.904      0.912      0.789\n",
            "            Distracted        115        216      0.412      0.585      0.492      0.422\n",
            "               Talking         11         14          1      0.344      0.424      0.357\n",
            "                Turned        259        477      0.548       0.73      0.669      0.543\n",
            "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 4])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ef0878bb710>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.035589,    0.017794,           0],\n",
              "       [          1,           1,           1, ...,   0.0071005,   0.0035503,           0],\n",
              "       [          1,           1,           1, ...,    0.049123,    0.049123,           0],\n",
              "       [          1,           1,           1, ...,    0.011551,   0.0057754,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.40209,     0.40209,     0.50381, ...,           0,           0,           0],\n",
              "       [   0.093833,    0.093833,     0.11613, ...,           0,           0,           0],\n",
              "       [   0.021875,    0.021875,    0.036171, ...,           0,           0,           0],\n",
              "       [    0.15594,     0.15594,     0.19723, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.25255,     0.25255,     0.33853, ...,           1,           1,           1],\n",
              "       [    0.04926,     0.04926,    0.061716, ...,           1,           1,           1],\n",
              "       [   0.011058,    0.011058,    0.018419, ...,           1,           1,           1],\n",
              "       [   0.084669,    0.084669,     0.10958, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.98579,     0.98579,     0.98442, ...,           0,           0,           0],\n",
              "       [    0.98611,     0.98611,     0.98148, ...,           0,           0,           0],\n",
              "       [          1,           1,           1, ...,           0,           0,           0],\n",
              "       [    0.98532,     0.98532,     0.98532, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(0.5375512215200707)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.78949,     0.42199,     0.35682,     0.52792,     0.54337])\n",
              "names: {0: 'Engaged', 1: 'Distracted', 2: 'Talking', 3: 'Sleepy', 4: 'Turned'}\n",
              "nt_per_class: array([2182,  216,   14,    0,  477])\n",
              "nt_per_image: array([389, 115,  11,   0, 259])\n",
              "results_dict: {'metrics/precision(B)': np.float64(0.680896751914438), 'metrics/recall(B)': np.float64(0.6407523273315002), 'metrics/mAP50(B)': np.float64(0.6242457780469384), 'metrics/mAP50-95(B)': np.float64(0.5279184930170855), 'fitness': np.float64(0.5375512215200707)}\n",
              "save_dir: PosixPath('runs/detect/train')\n",
              "speed: {'preprocess': 0.17465269750005064, 'inference': 1.7807059575011408, 'loss': 0.0005190425008549937, 'postprocess': 4.064460560002772}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the trained model\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')  # Update path if needed\n",
        "\n",
        "# Run inference on an image or folder\n",
        "#results = model('/content/drive/MyDrive/Saif/test/1590.jpg', save=True)  # Single image\n",
        "\n",
        "# Or on a folder\n",
        "results = model('/content/drive/MyDrive/Saif/test', save=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8rqR3QMKPq_",
        "outputId": "d776f750-0974-4d81-e703-3746ce33114c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/142 /content/drive/MyDrive/Saif/test/1003.jpg: 384x640 11 Engageds, 1 Turned, 8.2ms\n",
            "image 2/142 /content/drive/MyDrive/Saif/test/1031.jpg: 384x640 11 Engageds, 2 Turneds, 7.5ms\n",
            "image 3/142 /content/drive/MyDrive/Saif/test/1039.jpg: 384x640 11 Engageds, 2 Turneds, 7.5ms\n",
            "image 4/142 /content/drive/MyDrive/Saif/test/1056.jpg: 384x640 11 Engageds, 1 Turned, 6.7ms\n",
            "image 5/142 /content/drive/MyDrive/Saif/test/1094.jpg: 384x640 4 Engageds, 1 Turned, 27.0ms\n",
            "image 6/142 /content/drive/MyDrive/Saif/test/1097.jpg: 384x640 6 Engageds, 1 Turned, 7.0ms\n",
            "image 7/142 /content/drive/MyDrive/Saif/test/1104.jpg: 384x640 5 Engageds, 3 Turneds, 6.7ms\n",
            "image 8/142 /content/drive/MyDrive/Saif/test/1108.jpg: 384x640 4 Engageds, 2 Turneds, 7.8ms\n",
            "image 9/142 /content/drive/MyDrive/Saif/test/1131.jpg: 384x640 5 Engageds, 1 Distracted, 2 Turneds, 6.7ms\n",
            "image 10/142 /content/drive/MyDrive/Saif/test/1136.jpg: 384x640 5 Engageds, 2 Turneds, 7.0ms\n",
            "image 11/142 /content/drive/MyDrive/Saif/test/1157.jpg: 384x640 6 Engageds, 1 Turned, 7.1ms\n",
            "image 12/142 /content/drive/MyDrive/Saif/test/1178.jpg: 384x640 3 Engageds, 1 Distracted, 4 Turneds, 7.3ms\n",
            "image 13/142 /content/drive/MyDrive/Saif/test/1185.jpg: 384x640 2 Engageds, 3 Turneds, 7.2ms\n",
            "image 14/142 /content/drive/MyDrive/Saif/test/1189.jpg: 384x640 6 Engageds, 1 Distracted, 4 Turneds, 6.9ms\n",
            "image 15/142 /content/drive/MyDrive/Saif/test/1204.jpg: 384x640 5 Engageds, 1 Turned, 7.2ms\n",
            "image 16/142 /content/drive/MyDrive/Saif/test/1206.jpg: 384x640 6 Engageds, 1 Turned, 7.2ms\n",
            "image 17/142 /content/drive/MyDrive/Saif/test/1221.jpg: 384x640 5 Engageds, 1 Turned, 8.1ms\n",
            "image 18/142 /content/drive/MyDrive/Saif/test/1232.jpg: 384x640 5 Engageds, 1 Turned, 49.0ms\n",
            "image 19/142 /content/drive/MyDrive/Saif/test/1234.jpg: 384x640 5 Engageds, 1 Turned, 11.9ms\n",
            "image 20/142 /content/drive/MyDrive/Saif/test/1241.jpg: 384x640 4 Engageds, 1 Turned, 7.2ms\n",
            "image 21/142 /content/drive/MyDrive/Saif/test/1249.jpg: 384x640 4 Engageds, 1 Turned, 6.8ms\n",
            "image 22/142 /content/drive/MyDrive/Saif/test/1252.jpg: 384x640 5 Engageds, 7.2ms\n",
            "image 23/142 /content/drive/MyDrive/Saif/test/1271.jpg: 384x640 5 Engageds, 1 Turned, 6.7ms\n",
            "image 24/142 /content/drive/MyDrive/Saif/test/1298.jpg: 384x640 5 Engageds, 6.8ms\n",
            "image 25/142 /content/drive/MyDrive/Saif/test/1328.jpg: 384x640 4 Engageds, 6.8ms\n",
            "image 26/142 /content/drive/MyDrive/Saif/test/136.jpg: 384x640 6 Engageds, 7.1ms\n",
            "image 27/142 /content/drive/MyDrive/Saif/test/1361.jpg: 384x640 7 Engageds, 1 Distracted, 7.1ms\n",
            "image 28/142 /content/drive/MyDrive/Saif/test/1370.jpg: 384x640 6 Engageds, 7.0ms\n",
            "image 29/142 /content/drive/MyDrive/Saif/test/1377.jpg: 384x640 5 Engageds, 6.9ms\n",
            "image 30/142 /content/drive/MyDrive/Saif/test/1378.jpg: 384x640 6 Engageds, 8.0ms\n",
            "image 31/142 /content/drive/MyDrive/Saif/test/1394.jpg: 384x640 6 Engageds, 7.0ms\n",
            "image 32/142 /content/drive/MyDrive/Saif/test/141.jpg: 384x640 3 Engageds, 7.0ms\n",
            "image 33/142 /content/drive/MyDrive/Saif/test/1437.jpg: 384x640 3 Engageds, 1 Distracted, 12.2ms\n",
            "image 34/142 /content/drive/MyDrive/Saif/test/1451.jpg: 384x640 4 Engageds, 2 Distracteds, 1 Turned, 10.0ms\n",
            "image 35/142 /content/drive/MyDrive/Saif/test/1473.jpg: 384x640 2 Engageds, 4 Distracteds, 1 Turned, 9.7ms\n",
            "image 36/142 /content/drive/MyDrive/Saif/test/1476.jpg: 384x640 3 Engageds, 4 Distracteds, 3 Turneds, 13.9ms\n",
            "image 37/142 /content/drive/MyDrive/Saif/test/1484.jpg: 384x640 3 Engageds, 3 Distracteds, 4 Turneds, 11.8ms\n",
            "image 38/142 /content/drive/MyDrive/Saif/test/1491.jpg: 384x640 2 Engageds, 5 Distracteds, 5 Turneds, 12.0ms\n",
            "image 39/142 /content/drive/MyDrive/Saif/test/1493.jpg: 384x640 4 Engageds, 2 Distracteds, 3 Turneds, 9.4ms\n",
            "image 40/142 /content/drive/MyDrive/Saif/test/1495.jpg: 384x640 4 Engageds, 2 Distracteds, 3 Turneds, 9.2ms\n",
            "image 41/142 /content/drive/MyDrive/Saif/test/1501.jpg: 384x640 6 Engageds, 2 Distracteds, 2 Turneds, 8.7ms\n",
            "image 42/142 /content/drive/MyDrive/Saif/test/1510.jpg: 384x640 4 Engageds, 1 Distracted, 2 Turneds, 9.6ms\n",
            "image 43/142 /content/drive/MyDrive/Saif/test/1513.jpg: 384x640 4 Engageds, 3 Distracteds, 3 Turneds, 8.8ms\n",
            "image 44/142 /content/drive/MyDrive/Saif/test/1520.jpg: 384x640 3 Engageds, 4 Distracteds, 3 Turneds, 8.2ms\n",
            "image 45/142 /content/drive/MyDrive/Saif/test/1545.jpg: 384x640 4 Engageds, 3 Distracteds, 2 Turneds, 9.3ms\n",
            "image 46/142 /content/drive/MyDrive/Saif/test/1585.jpg: 384x640 5 Engageds, 7 Distracteds, 2 Turneds, 8.4ms\n",
            "image 47/142 /content/drive/MyDrive/Saif/test/159.jpg: 384x640 5 Engageds, 8.3ms\n",
            "image 48/142 /content/drive/MyDrive/Saif/test/1590.jpg: 384x640 4 Engageds, 5 Distracteds, 3 Turneds, 11.7ms\n",
            "image 49/142 /content/drive/MyDrive/Saif/test/1592.jpg: 384x640 4 Engageds, 3 Distracteds, 3 Turneds, 12.5ms\n",
            "image 50/142 /content/drive/MyDrive/Saif/test/1596.jpg: 384x640 4 Engageds, 4 Distracteds, 3 Turneds, 9.0ms\n",
            "image 51/142 /content/drive/MyDrive/Saif/test/1607.jpg: 384x640 4 Engageds, 7 Distracteds, 11.8ms\n",
            "image 52/142 /content/drive/MyDrive/Saif/test/1613.jpg: 384x640 4 Engageds, 5 Distracteds, 1 Turned, 12.8ms\n",
            "image 53/142 /content/drive/MyDrive/Saif/test/1636.jpg: 384x640 4 Engageds, 6 Distracteds, 2 Turneds, 8.9ms\n",
            "image 54/142 /content/drive/MyDrive/Saif/test/1644.jpg: 384x640 5 Engageds, 7 Distracteds, 1 Turned, 11.1ms\n",
            "image 55/142 /content/drive/MyDrive/Saif/test/1690.jpg: 384x640 10 Engageds, 1 Turned, 11.4ms\n",
            "image 56/142 /content/drive/MyDrive/Saif/test/1708.jpg: 384x640 10 Engageds, 8.9ms\n",
            "image 57/142 /content/drive/MyDrive/Saif/test/173.jpg: 384x640 4 Engageds, 1 Distracted, 2 Turneds, 8.9ms\n",
            "image 58/142 /content/drive/MyDrive/Saif/test/1733.jpg: 384x640 11 Engageds, 1 Distracted, 8.8ms\n",
            "image 59/142 /content/drive/MyDrive/Saif/test/1740.jpg: 384x640 13 Engageds, 9.0ms\n",
            "image 60/142 /content/drive/MyDrive/Saif/test/1748.jpg: 384x640 11 Engageds, 1 Distracted, 8.7ms\n",
            "image 61/142 /content/drive/MyDrive/Saif/test/1771.jpg: 384x640 11 Engageds, 1 Distracted, 1 Turned, 8.7ms\n",
            "image 62/142 /content/drive/MyDrive/Saif/test/1779.jpg: 384x640 11 Engageds, 1 Distracted, 12.3ms\n",
            "image 63/142 /content/drive/MyDrive/Saif/test/1784.jpg: 384x640 12 Engageds, 1 Distracted, 8.7ms\n",
            "image 64/142 /content/drive/MyDrive/Saif/test/1791.jpg: 384x640 12 Engageds, 1 Turned, 8.4ms\n",
            "image 65/142 /content/drive/MyDrive/Saif/test/1802.jpg: 384x640 12 Engageds, 1 Turned, 8.1ms\n",
            "image 66/142 /content/drive/MyDrive/Saif/test/1819.jpg: 384x640 9 Engageds, 1 Turned, 8.5ms\n",
            "image 67/142 /content/drive/MyDrive/Saif/test/1821.jpg: 384x640 9 Engageds, 1 Turned, 11.6ms\n",
            "image 68/142 /content/drive/MyDrive/Saif/test/1822.jpg: 384x640 10 Engageds, 1 Distracted, 8.2ms\n",
            "image 69/142 /content/drive/MyDrive/Saif/test/183.jpg: 384x640 4 Engageds, 2 Turneds, 8.2ms\n",
            "image 70/142 /content/drive/MyDrive/Saif/test/1865.jpg: 384x640 8 Engageds, 1 Turned, 24.0ms\n",
            "image 71/142 /content/drive/MyDrive/Saif/test/1903.jpg: 384x640 6 Engageds, 1 Turned, 12.5ms\n",
            "image 72/142 /content/drive/MyDrive/Saif/test/1908.jpg: 384x640 7 Engageds, 1 Turned, 12.5ms\n",
            "image 73/142 /content/drive/MyDrive/Saif/test/1909.jpg: 384x640 7 Engageds, 2 Turneds, 9.7ms\n",
            "image 74/142 /content/drive/MyDrive/Saif/test/192.jpg: 384x640 6 Engageds, 1 Distracted, 1 Turned, 10.5ms\n",
            "image 75/142 /content/drive/MyDrive/Saif/test/1963.jpg: 384x640 7 Engageds, 11.9ms\n",
            "image 76/142 /content/drive/MyDrive/Saif/test/1972.jpg: 384x640 6 Engageds, 9.2ms\n",
            "image 77/142 /content/drive/MyDrive/Saif/test/1984.jpg: 384x640 7 Engageds, 10.5ms\n",
            "image 78/142 /content/drive/MyDrive/Saif/test/1990.jpg: 384x640 7 Engageds, 12.1ms\n",
            "image 79/142 /content/drive/MyDrive/Saif/test/204.jpg: 384x640 4 Engageds, 1 Distracted, 1 Turned, 11.8ms\n",
            "image 80/142 /content/drive/MyDrive/Saif/test/21.jpg: 384x640 6 Engageds, 2 Distracteds, 11.4ms\n",
            "image 81/142 /content/drive/MyDrive/Saif/test/225.jpg: 384x640 10 Engageds, 2 Turneds, 11.5ms\n",
            "image 82/142 /content/drive/MyDrive/Saif/test/249.jpg: 384x640 10 Engageds, 2 Turneds, 11.5ms\n",
            "image 83/142 /content/drive/MyDrive/Saif/test/25.jpg: 384x640 5 Engageds, 2 Distracteds, 12.7ms\n",
            "image 84/142 /content/drive/MyDrive/Saif/test/252.jpg: 384x640 10 Engageds, 3 Turneds, 13.2ms\n",
            "image 85/142 /content/drive/MyDrive/Saif/test/275.jpg: 384x640 9 Engageds, 4 Turneds, 14.4ms\n",
            "image 86/142 /content/drive/MyDrive/Saif/test/279.jpg: 384x640 12 Engageds, 2 Turneds, 6.7ms\n",
            "image 87/142 /content/drive/MyDrive/Saif/test/29.jpg: 384x640 4 Engageds, 2 Distracteds, 6.5ms\n",
            "image 88/142 /content/drive/MyDrive/Saif/test/290.jpg: 384x640 11 Engageds, 2 Turneds, 6.6ms\n",
            "image 89/142 /content/drive/MyDrive/Saif/test/309.jpg: 384x640 11 Engageds, 3 Turneds, 6.7ms\n",
            "image 90/142 /content/drive/MyDrive/Saif/test/33.jpg: 384x640 4 Engageds, 6.8ms\n",
            "image 91/142 /content/drive/MyDrive/Saif/test/330.jpg: 384x640 11 Engageds, 2 Turneds, 7.3ms\n",
            "image 92/142 /content/drive/MyDrive/Saif/test/343.jpg: 384x640 9 Engageds, 2 Turneds, 6.6ms\n",
            "image 93/142 /content/drive/MyDrive/Saif/test/344.jpg: 384x640 9 Engageds, 2 Turneds, 6.8ms\n",
            "image 94/142 /content/drive/MyDrive/Saif/test/352.jpg: 384x640 11 Engageds, 1 Turned, 6.9ms\n",
            "image 95/142 /content/drive/MyDrive/Saif/test/353.jpg: 384x640 11 Engageds, 2 Turneds, 6.7ms\n",
            "image 96/142 /content/drive/MyDrive/Saif/test/37.jpg: 384x640 4 Engageds, 1 Distracted, 6.7ms\n",
            "image 97/142 /content/drive/MyDrive/Saif/test/370.jpg: 384x640 10 Engageds, 3 Distracteds, 1 Turned, 6.7ms\n",
            "image 98/142 /content/drive/MyDrive/Saif/test/373.jpg: 384x640 8 Engageds, 3 Distracteds, 1 Turned, 7.3ms\n",
            "image 99/142 /content/drive/MyDrive/Saif/test/397.jpg: 384x640 7 Engageds, 2 Distracteds, 2 Turneds, 6.9ms\n",
            "image 100/142 /content/drive/MyDrive/Saif/test/415.jpg: 384x640 7 Engageds, 3 Turneds, 7.8ms\n",
            "image 101/142 /content/drive/MyDrive/Saif/test/428.jpg: 384x640 9 Engageds, 2 Distracteds, 1 Turned, 6.5ms\n",
            "image 102/142 /content/drive/MyDrive/Saif/test/442.jpg: 384x640 8 Engageds, 1 Turned, 7.8ms\n",
            "image 103/142 /content/drive/MyDrive/Saif/test/445.jpg: 384x640 8 Engageds, 7.4ms\n",
            "image 104/142 /content/drive/MyDrive/Saif/test/452.jpg: 384x640 8 Engageds, 1 Turned, 6.6ms\n",
            "image 105/142 /content/drive/MyDrive/Saif/test/472.jpg: 384x640 10 Engageds, 6.8ms\n",
            "image 106/142 /content/drive/MyDrive/Saif/test/479.jpg: 384x640 10 Engageds, 7.2ms\n",
            "image 107/142 /content/drive/MyDrive/Saif/test/480.jpg: 384x640 10 Engageds, 7.1ms\n",
            "image 108/142 /content/drive/MyDrive/Saif/test/485.jpg: 384x640 10 Engageds, 6.6ms\n",
            "image 109/142 /content/drive/MyDrive/Saif/test/509.jpg: 384x640 1 Engaged, 3 Turneds, 6.9ms\n",
            "image 110/142 /content/drive/MyDrive/Saif/test/513.jpg: 384x640 3 Turneds, 6.7ms\n",
            "image 111/142 /content/drive/MyDrive/Saif/test/536.jpg: 384x640 2 Engageds, 2 Turneds, 6.6ms\n",
            "image 112/142 /content/drive/MyDrive/Saif/test/537.jpg: 384x640 2 Engageds, 3 Turneds, 6.8ms\n",
            "image 113/142 /content/drive/MyDrive/Saif/test/551.jpg: 384x640 1 Engaged, 2 Turneds, 7.1ms\n",
            "image 114/142 /content/drive/MyDrive/Saif/test/559.jpg: 384x640 1 Engaged, 2 Turneds, 7.1ms\n",
            "image 115/142 /content/drive/MyDrive/Saif/test/561.jpg: 384x640 1 Engaged, 2 Turneds, 6.9ms\n",
            "image 116/142 /content/drive/MyDrive/Saif/test/597.jpg: 384x640 4 Turneds, 6.7ms\n",
            "image 117/142 /content/drive/MyDrive/Saif/test/606.jpg: 384x640 5 Turneds, 6.9ms\n",
            "image 118/142 /content/drive/MyDrive/Saif/test/616.jpg: 384x640 1 Engaged, 4 Turneds, 6.8ms\n",
            "image 119/142 /content/drive/MyDrive/Saif/test/626.jpg: 384x640 6 Engageds, 3 Turneds, 6.8ms\n",
            "image 120/142 /content/drive/MyDrive/Saif/test/632.jpg: 384x640 7 Engageds, 3 Turneds, 7.0ms\n",
            "image 121/142 /content/drive/MyDrive/Saif/test/691.jpg: 384x640 7 Engageds, 4 Turneds, 7.5ms\n",
            "image 122/142 /content/drive/MyDrive/Saif/test/693.jpg: 384x640 7 Engageds, 4 Turneds, 6.6ms\n",
            "image 123/142 /content/drive/MyDrive/Saif/test/695.jpg: 384x640 7 Engageds, 3 Turneds, 6.7ms\n",
            "image 124/142 /content/drive/MyDrive/Saif/test/7.jpg: 384x640 2 Engageds, 2 Turneds, 11.9ms\n",
            "image 125/142 /content/drive/MyDrive/Saif/test/700.jpg: 384x640 8 Engageds, 3 Turneds, 6.8ms\n",
            "image 126/142 /content/drive/MyDrive/Saif/test/726.jpg: 384x640 6 Engageds, 4 Turneds, 6.8ms\n",
            "image 127/142 /content/drive/MyDrive/Saif/test/741.jpg: 384x640 6 Engageds, 4 Turneds, 7.2ms\n",
            "image 128/142 /content/drive/MyDrive/Saif/test/751.jpg: 384x640 7 Engageds, 4 Turneds, 6.7ms\n",
            "image 129/142 /content/drive/MyDrive/Saif/test/769.jpg: 384x640 5 Engageds, 4 Turneds, 6.5ms\n",
            "image 130/142 /content/drive/MyDrive/Saif/test/77.jpg: 384x640 6 Engageds, 7.6ms\n",
            "image 131/142 /content/drive/MyDrive/Saif/test/778.jpg: 384x640 11 Engageds, 2 Turneds, 7.1ms\n",
            "image 132/142 /content/drive/MyDrive/Saif/test/794.jpg: 384x640 10 Engageds, 2 Turneds, 6.9ms\n",
            "image 133/142 /content/drive/MyDrive/Saif/test/807.jpg: 384x640 10 Engageds, 3 Turneds, 6.9ms\n",
            "image 134/142 /content/drive/MyDrive/Saif/test/817.jpg: 384x640 10 Engageds, 2 Turneds, 6.5ms\n",
            "image 135/142 /content/drive/MyDrive/Saif/test/823.jpg: 384x640 8 Engageds, 3 Turneds, 6.5ms\n",
            "image 136/142 /content/drive/MyDrive/Saif/test/837.jpg: 384x640 11 Engageds, 1 Turned, 6.6ms\n",
            "image 137/142 /content/drive/MyDrive/Saif/test/856.jpg: 384x640 11 Engageds, 1 Distracted, 2 Turneds, 6.5ms\n",
            "image 138/142 /content/drive/MyDrive/Saif/test/870.jpg: 384x640 10 Engageds, 2 Turneds, 6.5ms\n",
            "image 139/142 /content/drive/MyDrive/Saif/test/913.jpg: 384x640 11 Engageds, 6.9ms\n",
            "image 140/142 /content/drive/MyDrive/Saif/test/931.jpg: 384x640 11 Engageds, 1 Turned, 7.0ms\n",
            "image 141/142 /content/drive/MyDrive/Saif/test/938.jpg: 384x640 11 Engageds, 1 Turned, 6.9ms\n",
            "image 142/142 /content/drive/MyDrive/Saif/test/961.jpg: 384x640 12 Engageds, 2 Turneds, 6.5ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the folder (e.g., runs/detect/train)\n",
        "shutil.make_archive('detect_res', 'zip', '/content/runs/detect/predict')  # Change the path if needed\n",
        "\n",
        "# Download the zipped folder\n",
        "files.download('detect_res.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "V9iNNH0pNxYy",
        "outputId": "90333dbb-3d54-402e-9ef0-ffba265f3cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_77703f01-5d09-4a47-ab1a-c1f40f7faffa\", \"detect_res.zip\", 83158070)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OrbH9RGha4b9oUQ8DypRU1QEsPCuTaK-",
      "authorship_tag": "ABX9TyNp06vrOxMDks3oq5lJ0PJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}